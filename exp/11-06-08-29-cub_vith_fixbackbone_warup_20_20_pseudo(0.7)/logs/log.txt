2023-11-06 08:29:15,542 - INFO - Training cub_vith_fixbackbone_warup_20_20_pseudo(0.7) with the following settings:
2023-11-06 08:29:15,545 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cub_vith_fixbackbone_warup_20_20_pseudo(0.7)
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.7
 lambda_loss=0.2
 coteaching_epoch_t=20
 coteaching_epoch_i=20
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=exp/11-06-08-29-cub_vith_fixbackbone_warup_20_20_pseudo(0.7)/logs/log.txt
 model_path=exp/11-06-08-29-cub_vith_fixbackbone_warup_20_20_pseudo(0.7)/models/model.pth
 device=cuda
2023-11-06 08:29:15,580 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-06 08:29:16,561 - INFO - Loaded hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K model config.
2023-11-06 08:29:24,935 - INFO - Loading pretrained hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K weights (/home/zhun.zhong/.cache/huggingface/hub/models--laion--CLIP-ViT-H-14-laion2B-s32B-b79K/snapshots/94a64189c3535c1cb44acfcccd7b0908c1c8eb23/open_clip_pytorch_model.bin).
2023-11-06 08:30:47,727 - INFO - Building custom CLIP
2023-11-06 08:30:49,696 - INFO - Turning off gradients in both the image and the text encoder
2023-11-06 08:30:49,700 - INFO - Parameters that require gradients: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-06 08:30:49,702 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
