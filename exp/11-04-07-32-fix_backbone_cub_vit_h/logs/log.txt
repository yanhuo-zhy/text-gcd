2023-11-04 07:32:56,903 - INFO - Training fix_backbone_cub_vit_h with the following settings:
2023-11-04 07:32:56,903 - INFO - Command-line arguments: output_dir=exp
 experiment_name=fix_backbone_cub_vit_h
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=exp/11-04-07-32-fix_backbone_cub_vit_h/logs/log.txt
 model_path=exp/11-04-07-32-fix_backbone_cub_vit_h/models/model.pth
 device=cuda
2023-11-04 07:32:56,906 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-04 07:32:57,441 - INFO - Loaded hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K model config.
2023-11-04 07:33:03,216 - INFO - Loading pretrained hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K weights (/home/zhun.zhong/.cache/huggingface/hub/models--laion--CLIP-ViT-H-14-laion2B-s32B-b79K/snapshots/94a64189c3535c1cb44acfcccd7b0908c1c8eb23/open_clip_pytorch_model.bin).
2023-11-04 07:33:21,316 - INFO - Building custom CLIP
2023-11-04 07:33:22,416 - INFO - Turning off gradients in both the image and the text encoder
2023-11-04 07:33:22,419 - INFO - Parameters that require gradients: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-04 07:33:22,421 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-04 07:33:25,350 - INFO - len of train dataset: 5994
2023-11-04 07:33:25,350 - INFO - len of test dataset: 4494
2023-11-04 07:33:25,350 - INFO - Pseudo Nums: 13
2023-11-04 07:35:36,115 - INFO - len of image_to_class_map: 1552
2023-11-04 07:35:36,116 - INFO - len of image_to_class_map_i: 1797
2023-11-04 07:37:37,297 - INFO - Before Train Accuracies: All 0.0863 | Old 0.0707 | New 0.0942
2023-11-04 07:37:37,297 - INFO - Before Train Accuracies: All 0.0866 | Old 0.0593 | New 0.1002
2023-11-04 07:42:50,817 - INFO - Epoch 1/200, Total Loss: 11.5842, Cls Loss: 9.8485, Cluster Loss: 10.2439, New Loss: 0.0000, Clip tag Loss: 1.4194
2023-11-04 07:42:50,818 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-04 07:42:50,818 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-04 07:44:51,246 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.2597 | Old 0.2940 | New 0.2425
2023-11-04 07:44:51,246 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.2007 | Old 0.2687 | New 0.1667
2023-11-04 07:46:52,281 - INFO - Weighted Accuracies: All 0.2161 | Old 0.3260 | New 0.1610
2023-11-04 07:49:03,432 - INFO - len of image_to_class_map: 1983
2023-11-04 07:49:03,433 - INFO - len of image_to_class_map_i: 2147
2023-11-04 07:54:15,098 - INFO - Epoch 2/200, Total Loss: 10.3263, Cls Loss: 8.2533, Cluster Loss: 9.0614, New Loss: 0.0000, Clip tag Loss: 1.4266
2023-11-04 07:54:15,099 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-04 07:54:15,099 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-04 07:56:15,393 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.2911 | Old 0.3720 | New 0.2505
2023-11-04 07:56:15,393 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.2503 | Old 0.3707 | New 0.1900
2023-11-04 07:58:15,758 - INFO - Weighted Accuracies: All 0.2753 | Old 0.4180 | New 0.2037
2023-11-04 08:00:28,224 - INFO - len of image_to_class_map: 1755
2023-11-04 08:00:28,224 - INFO - len of image_to_class_map_i: 1853
2023-11-04 08:05:40,151 - INFO - Epoch 3/200, Total Loss: 8.4049, Cls Loss: 6.7795, Cluster Loss: 7.0362, New Loss: 0.0000, Clip tag Loss: 1.4200
2023-11-04 08:05:40,152 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-04 08:05:40,152 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-04 08:07:40,755 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3491 | Old 0.5100 | New 0.2685
2023-11-04 08:07:40,755 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.3071 | Old 0.5187 | New 0.2011
2023-11-04 08:09:41,194 - INFO - Weighted Accuracies: All 0.3218 | Old 0.5120 | New 0.2265
2023-11-04 08:11:53,305 - INFO - len of image_to_class_map: 1838
2023-11-04 08:11:53,306 - INFO - len of image_to_class_map_i: 1846
2023-11-04 08:17:04,881 - INFO - Epoch 4/200, Total Loss: 7.2541, Cls Loss: 5.8483, Cluster Loss: 5.8311, New Loss: 0.0000, Clip tag Loss: 1.4195
2023-11-04 08:17:04,881 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-04 08:17:04,881 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-04 08:19:05,364 - INFO - Text classifier Epoch 3 Train Accuracies: All 0.3554 | Old 0.5560 | New 0.2548
2023-11-04 08:19:05,365 - INFO - Image classifier Epoch 3 Train Accuracies: All 0.3416 | Old 0.5780 | New 0.2231
2023-11-04 08:21:05,790 - INFO - Weighted Accuracies: All 0.3696 | Old 0.5913 | New 0.2585
2023-11-04 08:23:17,302 - INFO - len of image_to_class_map: 1843
2023-11-04 08:23:17,302 - INFO - len of image_to_class_map_i: 1900
2023-11-04 08:28:28,944 - INFO - Epoch 5/200, Total Loss: 6.5940, Cls Loss: 5.3066, Cluster Loss: 5.1611, New Loss: 0.0000, Clip tag Loss: 1.4037
2023-11-04 08:28:28,945 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2023-11-04 08:28:28,945 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
