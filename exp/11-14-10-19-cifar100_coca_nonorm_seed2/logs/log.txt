2023-11-14 10:19:17,677 - INFO - Training cifar100_coca_nonorm_seed2 with the following settings:
2023-11-14 10:19:17,677 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_coca_nonorm_seed2
 seed_num=2
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 80)
 unlabeled_classes=range(80, 100)
 num_labeled_classes=80
 num_unlabeled_classes=20
 num_classes=100
 log_path=exp/11-14-10-19-cifar100_coca_nonorm_seed2/logs/log.txt
 model_path=exp/11-14-10-19-cifar100_coca_nonorm_seed2/models/model.pth
 device=cuda
2023-11-14 10:19:17,681 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-14 10:19:21,082 - INFO - Building custom CLIP
2023-11-14 10:19:26,834 - INFO - Turning off gradients in both the image and the text encoder
2023-11-14 10:19:26,836 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-14 10:19:26,838 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-14 10:19:31,003 - INFO - len of train dataset: 50000
2023-11-14 10:19:31,003 - INFO - len of test dataset: 30000
2023-11-14 10:19:31,004 - INFO - Pseudo Nums: 180
2023-11-14 10:21:13,932 - INFO - len of image_to_class_map: 11220
2023-11-14 10:21:13,933 - INFO - len of image_to_class_map_i: 10371
2023-11-14 10:22:55,650 - INFO - Before Train Accuracies: All 0.1207 | Old 0.0579 | New 0.2462
2023-11-14 10:22:55,650 - INFO - Before Train Accuracies: All 0.0737 | Old 0.0362 | New 0.1489
2023-11-14 10:29:13,554 - INFO - Epoch 1/200, Total Loss: 6.6152, Cls Loss: 5.3277, Cluster Loss: 4.9311, New Loss: 0.0000, Clip tag Loss: 1.6048
2023-11-14 10:29:13,555 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-14 10:29:13,555 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 10:30:55,051 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.6627 | Old 0.7274 | New 0.5334
2023-11-14 10:30:55,051 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.5669 | Old 0.6329 | New 0.4350
2023-11-14 10:32:35,743 - INFO - Weighted Accuracies: All 0.6226 | Old 0.7133 | New 0.4412
2023-11-14 10:34:17,183 - INFO - len of image_to_class_map: 17333
2023-11-14 10:34:17,183 - INFO - len of image_to_class_map_i: 17481
2023-11-14 10:40:32,649 - INFO - Epoch 2/200, Total Loss: 4.2254, Cls Loss: 2.9013, Cluster Loss: 2.6885, New Loss: 0.0000, Clip tag Loss: 1.4944
2023-11-14 10:40:32,650 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-14 10:40:32,650 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 10:42:13,342 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.7019 | Old 0.7933 | New 0.5193
2023-11-14 10:42:13,343 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.6291 | Old 0.7224 | New 0.4426
2023-11-14 10:43:53,329 - INFO - Weighted Accuracies: All 0.6380 | Old 0.7795 | New 0.3549
2023-11-14 10:45:34,121 - INFO - len of image_to_class_map: 17823
2023-11-14 10:45:34,122 - INFO - len of image_to_class_map_i: 17646
2023-11-14 10:51:48,850 - INFO - Epoch 3/200, Total Loss: 3.8911, Cls Loss: 2.4580, Cluster Loss: 2.4696, New Loss: 0.0000, Clip tag Loss: 1.4238
2023-11-14 10:51:48,851 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-14 10:51:48,852 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 10:53:29,790 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.6982 | Old 0.7853 | New 0.5238
2023-11-14 10:53:29,790 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.6340 | Old 0.7100 | New 0.4819
2023-11-14 10:55:10,156 - INFO - Weighted Accuracies: All 0.6355 | Old 0.7674 | New 0.3717
2023-11-14 10:56:51,294 - INFO - len of image_to_class_map: 17989
2023-11-14 10:56:51,295 - INFO - len of image_to_class_map_i: 17795
2023-11-14 11:03:06,982 - INFO - Epoch 4/200, Total Loss: 3.7323, Cls Loss: 2.2503, Cluster Loss: 2.3642, New Loss: 0.0000, Clip tag Loss: 1.3908
2023-11-14 11:03:06,983 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-14 11:03:06,983 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 11:04:46,641 - INFO - Text classifier Epoch 3 Train Accuracies: All 0.6950 | Old 0.7953 | New 0.4946
2023-11-14 11:04:46,642 - INFO - Image classifier Epoch 3 Train Accuracies: All 0.6446 | Old 0.7591 | New 0.4156
2023-11-14 11:06:26,794 - INFO - Weighted Accuracies: All 0.6237 | Old 0.7979 | New 0.2752
2023-11-14 11:08:08,432 - INFO - len of image_to_class_map: 17996
2023-11-14 11:08:08,433 - INFO - len of image_to_class_map_i: 17861
2023-11-14 11:14:24,326 - INFO - Epoch 5/200, Total Loss: 3.6278, Cls Loss: 2.1173, Cluster Loss: 2.3166, New Loss: 0.0000, Clip tag Loss: 1.3511
2023-11-14 11:14:24,327 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2023-11-14 11:14:24,327 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 11:16:05,132 - INFO - Text classifier Epoch 4 Train Accuracies: All 0.6958 | Old 0.7940 | New 0.4995
2023-11-14 11:16:05,133 - INFO - Image classifier Epoch 4 Train Accuracies: All 0.6595 | Old 0.7585 | New 0.4614
2023-11-14 11:17:45,486 - INFO - Weighted Accuracies: All 0.6226 | Old 0.8112 | New 0.2455
2023-11-14 11:19:26,862 - INFO - len of image_to_class_map: 18000
2023-11-14 11:19:26,863 - INFO - len of image_to_class_map_i: 17903
2023-11-14 11:25:42,308 - INFO - Epoch 6/200, Total Loss: 3.5755, Cls Loss: 2.0352, Cluster Loss: 2.2891, New Loss: 0.0000, Clip tag Loss: 1.3372
2023-11-14 11:25:42,308 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2023-11-14 11:25:42,308 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-14 11:27:22,695 - INFO - Text classifier Epoch 5 Train Accuracies: All 0.7024 | Old 0.8005 | New 0.5061
2023-11-14 11:27:22,696 - INFO - Image classifier Epoch 5 Train Accuracies: All 0.6514 | Old 0.7651 | New 0.4238
2023-11-14 11:29:02,907 - INFO - Weighted Accuracies: All 0.6473 | Old 0.8008 | New 0.3402
2023-11-14 11:30:44,037 - INFO - len of image_to_class_map: 17987
2023-11-14 11:30:44,038 - INFO - len of image_to_class_map_i: 17864
