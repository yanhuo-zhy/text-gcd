2023-11-02 05:14:50,771 - INFO - Training imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2) with the following settings:
2023-11-02 05:14:50,771 - INFO - Command-line arguments: output_dir=exp
 experiment_name=imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)
 seed_num=1
 evaluate=False
 dataset_name=imagenet_1k
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 500)
 unlabeled_classes=range(500, 1000)
 num_labeled_classes=500
 num_unlabeled_classes=500
 num_classes=1000
 log_path=exp/11-02-05-14-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)/logs/log.txt
 model_path=exp/11-02-05-14-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)/models/model.pth
 device=cuda
2023-11-02 05:14:50,776 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-02 05:14:52,672 - INFO - Building custom CLIP
2023-11-02 05:14:53,655 - INFO - Turning off gradients in both the image and the text encoder
2023-11-02 05:14:53,657 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-02 05:14:53,658 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-02 05:16:32,601 - INFO - len of train dataset: 1281167
2023-11-02 05:16:32,602 - INFO - len of test dataset: 960023
2023-11-02 05:16:32,602 - INFO - Pseudo Nums: 576
2023-11-02 06:00:17,300 - INFO - len of image_to_class_map: 304478
2023-11-02 06:00:17,303 - INFO - len of image_to_class_map_i: 379194
2023-11-02 06:43:48,478 - INFO - Before Train Accuracies: All 0.0586 | Old 0.0613 | New 0.0572
2023-11-02 06:43:48,504 - INFO - Before Train Accuracies: All 0.0473 | Old 0.0292 | New 0.0564
2023-11-02 09:01:06,842 - INFO - Epoch 1/200, Total Loss: 8.0906, Cls Loss: 6.5213, Cluster Loss: 7.3254, New Loss: 0.0000, Clip tag Loss: 0.9260
2023-11-02 09:01:06,863 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-02 09:01:06,863 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-02 09:44:40,497 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.4317 | Old 0.7277 | New 0.2829
2023-11-02 09:44:40,506 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.3482 | Old 0.7009 | New 0.1709
2023-11-02 10:28:14,421 - INFO - Weighted Accuracies: All 0.3498 | Old 0.6826 | New 0.1825
2023-11-02 11:12:23,518 - INFO - len of image_to_class_map: 540252
2023-11-02 11:12:23,546 - INFO - len of image_to_class_map_i: 536300
2023-11-02 13:29:49,545 - INFO - Epoch 2/200, Total Loss: 7.3486, Cls Loss: 5.5201, Cluster Loss: 6.7049, New Loss: 0.0000, Clip tag Loss: 0.8807
2023-11-02 13:29:49,545 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-02 13:29:49,545 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-02 14:13:19,358 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.3940 | Old 0.7393 | New 0.2204
2023-11-02 14:13:19,382 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.3382 | Old 0.7238 | New 0.1444
2023-11-02 14:56:51,531 - INFO - Weighted Accuracies: All 0.3498 | Old 0.6943 | New 0.1766
2023-11-02 15:40:39,471 - INFO - len of image_to_class_map: 531961
2023-11-02 15:40:39,473 - INFO - len of image_to_class_map_i: 526309
2023-11-02 17:57:45,941 - INFO - Epoch 3/200, Total Loss: 7.2522, Cls Loss: 5.3406, Cluster Loss: 6.6461, New Loss: 0.0000, Clip tag Loss: 0.8672
2023-11-02 17:57:45,965 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-02 17:57:45,965 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-02 18:41:19,539 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3932 | Old 0.7428 | New 0.2175
2023-11-02 18:41:19,547 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.3349 | Old 0.7230 | New 0.1398
2023-11-02 19:24:52,313 - INFO - Weighted Accuracies: All 0.3473 | Old 0.6953 | New 0.1723
2023-11-02 20:08:51,728 - INFO - len of image_to_class_map: 522313
2023-11-02 20:08:51,730 - INFO - len of image_to_class_map_i: 518358
2023-11-02 22:26:00,130 - INFO - Epoch 4/200, Total Loss: 7.1752, Cls Loss: 5.2381, Cluster Loss: 6.5851, New Loss: 0.0000, Clip tag Loss: 0.8595
2023-11-02 22:26:00,145 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-02 22:26:00,145 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-02 23:09:32,641 - INFO - Text classifier Epoch 3 Train Accuracies: All 0.3920 | Old 0.7344 | New 0.2199
2023-11-02 23:09:32,667 - INFO - Image classifier Epoch 3 Train Accuracies: All 0.3339 | Old 0.7215 | New 0.1390
2023-11-02 23:53:04,554 - INFO - Weighted Accuracies: All 0.3482 | Old 0.6965 | New 0.1731
2023-11-03 00:37:04,016 - INFO - len of image_to_class_map: 516192
2023-11-03 00:37:04,078 - INFO - len of image_to_class_map_i: 512661
2023-11-03 03:07:54,846 - INFO - Epoch 5/200, Total Loss: 7.1008, Cls Loss: 5.1588, Cluster Loss: 6.5198, New Loss: 0.0000, Clip tag Loss: 0.8532
2023-11-03 03:07:54,848 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2023-11-03 03:07:54,849 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-03 04:13:20,038 - INFO - Text classifier Epoch 4 Train Accuracies: All 0.3947 | Old 0.7365 | New 0.2228
2023-11-03 04:13:20,039 - INFO - Image classifier Epoch 4 Train Accuracies: All 0.3366 | Old 0.7276 | New 0.1400
2023-11-03 05:04:26,537 - INFO - Weighted Accuracies: All 0.3502 | Old 0.6972 | New 0.1757
2023-11-03 05:48:23,204 - INFO - len of image_to_class_map: 512912
2023-11-03 05:48:23,207 - INFO - len of image_to_class_map_i: 507652
2023-11-03 08:06:02,992 - INFO - Epoch 6/200, Total Loss: 7.0274, Cls Loss: 5.0887, Cluster Loss: 6.4508, New Loss: 0.0000, Clip tag Loss: 0.8490
2023-11-03 08:06:02,992 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2023-11-03 08:06:02,993 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-03 08:49:29,186 - INFO - Text classifier Epoch 5 Train Accuracies: All 0.4014 | Old 0.7371 | New 0.2326
2023-11-03 08:49:29,187 - INFO - Image classifier Epoch 5 Train Accuracies: All 0.3376 | Old 0.7266 | New 0.1421
2023-11-03 09:32:56,711 - INFO - Weighted Accuracies: All 0.3514 | Old 0.7050 | New 0.1737
2023-11-03 10:16:53,961 - INFO - len of image_to_class_map: 509865
2023-11-03 10:16:53,963 - INFO - len of image_to_class_map_i: 502872
