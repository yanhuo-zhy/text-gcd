2023-11-07 10:55:15,115 - INFO - Training imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_warmup1-5_sharpen with the following settings:
2023-11-07 10:55:15,116 - INFO - Command-line arguments: output_dir=exp
 experiment_name=imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_warmup1-5_sharpen
 seed_num=1
 evaluate=False
 dataset_name=imagenet_1k
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=1
 coteaching_epoch_i=5
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 500)
 unlabeled_classes=range(500, 1000)
 num_labeled_classes=500
 num_unlabeled_classes=500
 num_classes=1000
 log_path=exp/11-07-10-55-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_warmup1-5_sharpen/logs/log.txt
 model_path=exp/11-07-10-55-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_warmup1-5_sharpen/models/model.pth
 device=cuda
2023-11-07 10:55:15,120 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-07 10:55:19,073 - INFO - Building custom CLIP
2023-11-07 10:55:26,151 - INFO - Turning off gradients in both the image and the text encoder
2023-11-07 10:55:26,158 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-07 10:55:26,160 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-07 10:57:29,522 - INFO - len of train dataset: 1281167
2023-11-07 10:57:29,522 - INFO - len of test dataset: 960023
2023-11-07 10:57:29,522 - INFO - Pseudo Nums: 576
2023-11-07 11:45:21,590 - INFO - len of image_to_class_map: 304484
2023-11-07 11:45:21,593 - INFO - len of image_to_class_map_i: 379184
2023-11-07 12:31:23,051 - INFO - Before Train Accuracies: All 0.0586 | Old 0.0614 | New 0.0572
2023-11-07 12:31:23,052 - INFO - Before Train Accuracies: All 0.0473 | Old 0.0292 | New 0.0564
2023-11-07 14:38:28,807 - INFO - Epoch 1/200, Total Loss: 7.6242, Cls Loss: 5.9796, Cluster Loss: 6.9006, New Loss: 0.0000, Clip tag Loss: 0.9078
2023-11-07 14:38:28,807 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-07 14:38:28,808 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-07 15:24:47,237 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.3632 | Old 0.7073 | New 0.1902
2023-11-07 15:24:47,237 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.2999 | Old 0.6714 | New 0.1132
2023-11-07 16:12:08,883 - INFO - Weighted Accuracies: All 0.3378 | Old 0.6774 | New 0.1671
2023-11-07 16:59:18,228 - INFO - len of image_to_class_map: 507309
2023-11-07 16:59:18,231 - INFO - len of image_to_class_map_i: 504310
2023-11-07 18:56:29,457 - INFO - Epoch 2/200, Total Loss: 7.3197, Cls Loss: 5.4007, Cluster Loss: 6.7087, New Loss: 0.0000, Clip tag Loss: 0.8726
2023-11-07 18:56:29,457 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-07 18:56:29,457 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-07 19:38:06,535 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.3675 | Old 0.7276 | New 0.1865
2023-11-07 19:38:06,536 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.3092 | Old 0.7063 | New 0.1095
2023-11-07 20:19:43,493 - INFO - Weighted Accuracies: All 0.3410 | Old 0.7001 | New 0.1606
2023-11-07 21:01:56,458 - INFO - len of image_to_class_map: 500466
2023-11-07 21:01:56,462 - INFO - len of image_to_class_map_i: 498801
2023-11-07 23:01:30,783 - INFO - Epoch 3/200, Total Loss: 10.2532, Cls Loss: 4.4012, Cluster Loss: 6.7055, New Loss: 3.1221, Clip tag Loss: 0.8865
2023-11-07 23:01:30,783 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-07 23:01:30,783 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-07 23:49:44,467 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3814 | Old 0.7309 | New 0.2058
2023-11-07 23:49:44,468 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.3470 | Old 0.6253 | New 0.2070
2023-11-08 00:36:06,622 - INFO - Weighted Accuracies: All 0.3932 | Old 0.7324 | New 0.2226
2023-11-08 01:23:00,417 - INFO - len of image_to_class_map: 489372
2023-11-08 01:23:00,420 - INFO - len of image_to_class_map_i: 528696
