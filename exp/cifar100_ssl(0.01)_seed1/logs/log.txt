2024-05-13 15:51:08,703 - INFO - Training cifar100_ssl(0.01)_seed1 with the following settings:
2024-05-13 15:51:08,703 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_ssl(0.01)_seed1
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.01
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=[]
 num_labeled_classes=100
 num_unlabeled_classes=0
 num_classes=100
 log_path=exp/cifar100_ssl(0.01)_seed1/logs/log.txt
 model_path=exp/cifar100_ssl(0.01)_seed1/models/model.pth
 device=cuda
2024-05-13 15:51:08,708 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-13 15:51:12,586 - INFO - Building custom CLIP
2024-05-13 15:51:19,090 - INFO - Turning off gradients in both the image and the text encoder
2024-05-13 15:51:19,097 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 15:51:19,101 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 15:51:23,956 - INFO - len of train dataset: 50000
2024-05-13 15:51:23,956 - INFO - len of test dataset: 49500
2024-05-13 15:51:23,956 - INFO - Pseudo Nums: 297
2024-05-13 15:54:13,805 - INFO - len of image_to_class_map: 18354
2024-05-13 15:54:13,806 - INFO - len of image_to_class_map_i: 17742
2024-05-13 15:59:23,231 - INFO - Training cifar100_ssl(0.01)_seed1 with the following settings:
2024-05-13 15:59:23,231 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_ssl(0.01)_seed1
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.01
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.25
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=[]
 num_labeled_classes=100
 num_unlabeled_classes=0
 num_classes=100
 log_path=exp/cifar100_ssl(0.01)_seed1/logs/log.txt
 model_path=exp/cifar100_ssl(0.01)_seed1/models/model.pth
 device=cuda
2024-05-13 15:59:23,237 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-13 15:59:26,746 - INFO - Building custom CLIP
2024-05-13 15:59:33,258 - INFO - Turning off gradients in both the image and the text encoder
2024-05-13 15:59:33,262 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 15:59:33,263 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 15:59:37,975 - INFO - len of train dataset: 50000
2024-05-13 15:59:37,975 - INFO - len of test dataset: 49500
2024-05-13 15:59:37,975 - INFO - Pseudo Nums: 123
2024-05-13 16:02:28,042 - INFO - len of image_to_class_map: 9261
2024-05-13 16:02:28,043 - INFO - len of image_to_class_map_i: 9190
2024-05-13 16:26:14,759 - INFO - Training cifar100_ssl(0.01)_seed1 with the following settings:
2024-05-13 16:26:14,759 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_ssl(0.01)_seed1
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.01
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.25
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=[]
 num_labeled_classes=100
 num_unlabeled_classes=0
 num_classes=100
 log_path=exp/cifar100_ssl(0.01)_seed1/logs/log.txt
 model_path=exp/cifar100_ssl(0.01)_seed1/models/model.pth
 device=cuda
2024-05-13 16:26:14,765 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-13 16:26:18,604 - INFO - Building custom CLIP
2024-05-13 16:26:25,661 - INFO - Turning off gradients in both the image and the text encoder
2024-05-13 16:26:25,664 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 16:26:25,666 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 16:26:30,264 - INFO - len of train dataset: 50000
2024-05-13 16:26:30,264 - INFO - len of test dataset: 49500
2024-05-13 16:26:30,264 - INFO - Pseudo Nums: 123
2024-05-13 16:29:20,041 - INFO - len of image_to_class_map: 9261
2024-05-13 16:29:20,042 - INFO - len of image_to_class_map_i: 9190
2024-05-13 16:32:09,370 - INFO - Before Train Text Accuracies: Top-1 0.0101 | Top-5 0.0494
2024-05-13 16:32:09,371 - INFO - Before Train Image Accuracies: Top-1 0.0036 | Top-5 0.0327
2024-05-13 16:38:34,217 - INFO - Epoch 1/200, Total Loss: 6.1517, Cls Loss: 4.7002, Cluster Loss: 4.6051, New Loss: 0.0000, Clip tag Loss: 1.5276
2024-05-13 16:38:34,218 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-13 16:38:34,218 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 16:41:22,879 - INFO - Text classifier Epoch 0 Train Accuracies: Top-1 0.7539 | Top-5 0.9125
2024-05-13 16:41:22,880 - INFO - Image classifier Epoch 0 Train Accuracies: Top-1 0.5854 | Top-5 0.8515
2024-05-13 16:44:11,114 - INFO - Weighted Accuracies: Top-1 0.7702 | Top-5 0.9338
2024-05-13 16:46:59,083 - INFO - len of image_to_class_map: 12298
2024-05-13 16:46:59,084 - INFO - len of image_to_class_map_i: 12300
2024-05-13 16:53:21,052 - INFO - Epoch 2/200, Total Loss: 3.5642, Cls Loss: 1.7258, Cluster Loss: 2.3191, New Loss: 0.0000, Clip tag Loss: 1.3638
2024-05-13 16:53:21,054 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-13 16:53:21,054 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 16:56:09,103 - INFO - Text classifier Epoch 1 Train Accuracies: Top-1 0.7561 | Top-5 0.9194
2024-05-13 16:56:09,104 - INFO - Image classifier Epoch 1 Train Accuracies: Top-1 0.6004 | Top-5 0.8773
2024-05-13 17:00:04,805 - INFO - Training cifar100_ssl(0.01)_seed1 with the following settings:
2024-05-13 17:00:04,805 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_ssl(0.01)_seed1
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.01
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=[]
 num_labeled_classes=100
 num_unlabeled_classes=0
 num_classes=100
 log_path=exp/cifar100_ssl(0.01)_seed1/logs/log.txt
 model_path=exp/cifar100_ssl(0.01)_seed1/models/model.pth
 device=cuda
2024-05-13 17:00:04,808 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-13 17:00:08,368 - INFO - Building custom CLIP
2024-05-13 17:00:14,911 - INFO - Turning off gradients in both the image and the text encoder
2024-05-13 17:00:14,914 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 17:00:14,916 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-13 17:00:19,535 - INFO - len of train dataset: 50000
2024-05-13 17:00:19,536 - INFO - len of test dataset: 49500
2024-05-13 17:00:19,536 - INFO - Pseudo Nums: 297
2024-05-13 17:03:09,080 - INFO - len of image_to_class_map: 18354
2024-05-13 17:03:09,081 - INFO - len of image_to_class_map_i: 17742
2024-05-13 17:05:58,348 - INFO - Before Train Text Accuracies: Top-1 0.0101 | Top-5 0.0494
2024-05-13 17:05:58,348 - INFO - Before Train Image Accuracies: Top-1 0.0036 | Top-5 0.0327
2024-05-13 17:12:24,720 - INFO - Epoch 1/200, Total Loss: 6.1517, Cls Loss: 4.7002, Cluster Loss: 4.6051, New Loss: 0.0000, Clip tag Loss: 1.5276
2024-05-13 17:12:24,721 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-13 17:12:24,721 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 17:15:12,453 - INFO - Text classifier Epoch 0 Train Accuracies: Top-1 0.7539 | Top-5 0.9125
2024-05-13 17:15:12,454 - INFO - Image classifier Epoch 0 Train Accuracies: Top-1 0.5854 | Top-5 0.8515
2024-05-13 17:18:00,418 - INFO - Weighted Accuracies: Top-1 0.7702 | Top-5 0.9338
2024-05-13 17:20:48,485 - INFO - len of image_to_class_map: 29625
2024-05-13 17:20:48,486 - INFO - len of image_to_class_map_i: 29518
2024-05-13 17:27:09,850 - INFO - Epoch 2/200, Total Loss: 3.5642, Cls Loss: 1.7258, Cluster Loss: 2.3191, New Loss: 0.0000, Clip tag Loss: 1.3638
2024-05-13 17:27:09,851 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-13 17:27:09,851 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 17:29:57,011 - INFO - Text classifier Epoch 1 Train Accuracies: Top-1 0.7561 | Top-5 0.9194
2024-05-13 17:29:57,011 - INFO - Image classifier Epoch 1 Train Accuracies: Top-1 0.6004 | Top-5 0.8773
2024-05-13 17:32:44,352 - INFO - Weighted Accuracies: Top-1 0.7790 | Top-5 0.9417
2024-05-13 17:35:31,280 - INFO - len of image_to_class_map: 29690
2024-05-13 17:35:31,281 - INFO - len of image_to_class_map_i: 29640
2024-05-13 17:41:54,178 - INFO - Epoch 3/200, Total Loss: 3.3019, Cls Loss: 1.2705, Cluster Loss: 2.1964, New Loss: 0.0000, Clip tag Loss: 1.2907
2024-05-13 17:41:54,179 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-13 17:41:54,179 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 17:44:41,336 - INFO - Text classifier Epoch 2 Train Accuracies: Top-1 0.7360 | Top-5 0.9190
2024-05-13 17:44:41,336 - INFO - Image classifier Epoch 2 Train Accuracies: Top-1 0.5839 | Top-5 0.8771
2024-05-13 17:47:27,858 - INFO - Weighted Accuracies: Top-1 0.7669 | Top-5 0.9401
2024-05-13 17:50:14,734 - INFO - len of image_to_class_map: 29700
2024-05-13 17:50:14,735 - INFO - len of image_to_class_map_i: 29637
2024-05-13 17:56:34,871 - INFO - Epoch 4/200, Total Loss: 3.1756, Cls Loss: 1.0428, Cluster Loss: 2.1448, New Loss: 0.0000, Clip tag Loss: 1.2512
2024-05-13 17:56:34,871 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-13 17:56:34,871 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 17:59:22,720 - INFO - Text classifier Epoch 3 Train Accuracies: Top-1 0.7293 | Top-5 0.9162
2024-05-13 17:59:22,721 - INFO - Image classifier Epoch 3 Train Accuracies: Top-1 0.5670 | Top-5 0.8728
2024-05-13 18:02:10,083 - INFO - Weighted Accuracies: Top-1 0.7591 | Top-5 0.9391
2024-05-13 18:04:57,516 - INFO - len of image_to_class_map: 29667
2024-05-13 18:04:57,518 - INFO - len of image_to_class_map_i: 29549
2024-05-13 18:11:19,575 - INFO - Epoch 5/200, Total Loss: 3.1065, Cls Loss: 0.9168, Cluster Loss: 2.1222, New Loss: 0.0000, Clip tag Loss: 1.2254
2024-05-13 18:11:19,576 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-13 18:11:19,576 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 18:14:08,008 - INFO - Text classifier Epoch 4 Train Accuracies: Top-1 0.7378 | Top-5 0.9162
2024-05-13 18:14:08,009 - INFO - Image classifier Epoch 4 Train Accuracies: Top-1 0.5759 | Top-5 0.8736
2024-05-13 18:16:56,394 - INFO - Weighted Accuracies: Top-1 0.7592 | Top-5 0.9392
2024-05-13 18:19:44,233 - INFO - len of image_to_class_map: 29678
2024-05-13 18:19:44,234 - INFO - len of image_to_class_map_i: 29478
2024-05-13 18:26:05,995 - INFO - Epoch 6/200, Total Loss: 3.0366, Cls Loss: 0.8200, Cluster Loss: 2.0934, New Loss: 0.0000, Clip tag Loss: 1.1979
2024-05-13 18:26:05,995 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-13 18:26:05,996 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 18:28:52,352 - INFO - Text classifier Epoch 5 Train Accuracies: Top-1 0.7019 | Top-5 0.9151
2024-05-13 18:28:52,353 - INFO - Image classifier Epoch 5 Train Accuracies: Top-1 0.5683 | Top-5 0.8730
2024-05-13 18:31:37,872 - INFO - Weighted Accuracies: Top-1 0.7446 | Top-5 0.9384
2024-05-13 18:34:23,070 - INFO - len of image_to_class_map: 29676
2024-05-13 18:34:23,071 - INFO - len of image_to_class_map_i: 29529
2024-05-13 18:40:36,575 - INFO - Epoch 7/200, Total Loss: 2.9952, Cls Loss: 0.7691, Cluster Loss: 2.0817, New Loss: 0.0000, Clip tag Loss: 1.1760
2024-05-13 18:40:36,576 - INFO -    Param Group: classifier_head, Learning Rate: 0.0997
2024-05-13 18:40:36,576 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 18:43:22,729 - INFO - Text classifier Epoch 6 Train Accuracies: Top-1 0.7136 | Top-5 0.9149
2024-05-13 18:43:22,729 - INFO - Image classifier Epoch 6 Train Accuracies: Top-1 0.5645 | Top-5 0.8700
2024-05-13 18:46:07,737 - INFO - Weighted Accuracies: Top-1 0.7538 | Top-5 0.9377
2024-05-13 18:48:53,136 - INFO - len of image_to_class_map: 29670
2024-05-13 18:48:53,137 - INFO - len of image_to_class_map_i: 29600
2024-05-13 18:55:06,253 - INFO - Epoch 8/200, Total Loss: 2.9550, Cls Loss: 0.6925, Cluster Loss: 2.0641, New Loss: 0.0000, Clip tag Loss: 1.1652
2024-05-13 18:55:06,253 - INFO -    Param Group: classifier_head, Learning Rate: 0.0996
2024-05-13 18:55:06,253 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 18:57:51,259 - INFO - Text classifier Epoch 7 Train Accuracies: Top-1 0.7142 | Top-5 0.9152
2024-05-13 18:57:51,259 - INFO - Image classifier Epoch 7 Train Accuracies: Top-1 0.5561 | Top-5 0.8668
2024-05-13 19:00:36,068 - INFO - Weighted Accuracies: Top-1 0.7458 | Top-5 0.9376
2024-05-13 19:03:22,992 - INFO - len of image_to_class_map: 29673
2024-05-13 19:03:22,993 - INFO - len of image_to_class_map_i: 29565
2024-05-13 19:09:35,010 - INFO - Epoch 9/200, Total Loss: 2.9100, Cls Loss: 0.6474, Cluster Loss: 2.0499, New Loss: 0.0000, Clip tag Loss: 1.1406
2024-05-13 19:09:35,010 - INFO -    Param Group: classifier_head, Learning Rate: 0.0995
2024-05-13 19:09:35,010 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 19:12:21,094 - INFO - Text classifier Epoch 8 Train Accuracies: Top-1 0.7116 | Top-5 0.9118
2024-05-13 19:12:21,095 - INFO - Image classifier Epoch 8 Train Accuracies: Top-1 0.5657 | Top-5 0.8695
2024-05-13 19:15:06,454 - INFO - Weighted Accuracies: Top-1 0.7446 | Top-5 0.9366
2024-05-13 19:17:51,211 - INFO - len of image_to_class_map: 29674
2024-05-13 19:17:51,213 - INFO - len of image_to_class_map_i: 29615
2024-05-13 19:24:04,477 - INFO - Epoch 10/200, Total Loss: 2.8885, Cls Loss: 0.5955, Cluster Loss: 2.0425, New Loss: 0.0000, Clip tag Loss: 1.1354
2024-05-13 19:24:04,478 - INFO -    Param Group: classifier_head, Learning Rate: 0.0994
2024-05-13 19:24:04,479 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 19:26:49,550 - INFO - Text classifier Epoch 9 Train Accuracies: Top-1 0.7121 | Top-5 0.9135
2024-05-13 19:26:49,551 - INFO - Image classifier Epoch 9 Train Accuracies: Top-1 0.5497 | Top-5 0.8655
2024-05-13 19:29:34,313 - INFO - Weighted Accuracies: Top-1 0.7444 | Top-5 0.9349
2024-05-13 19:32:19,519 - INFO - len of image_to_class_map: 29698
2024-05-13 19:32:19,520 - INFO - len of image_to_class_map_i: 29501
2024-05-13 19:38:32,649 - INFO - Epoch 11/200, Total Loss: 2.8536, Cls Loss: 0.5686, Cluster Loss: 2.0201, New Loss: 0.0000, Clip tag Loss: 1.1238
2024-05-13 19:38:32,650 - INFO -    Param Group: classifier_head, Learning Rate: 0.0993
2024-05-13 19:38:32,650 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 19:41:17,737 - INFO - Text classifier Epoch 10 Train Accuracies: Top-1 0.6921 | Top-5 0.9142
2024-05-13 19:41:17,738 - INFO - Image classifier Epoch 10 Train Accuracies: Top-1 0.5404 | Top-5 0.8641
2024-05-13 19:44:02,636 - INFO - Weighted Accuracies: Top-1 0.7289 | Top-5 0.9348
2024-05-13 19:46:47,575 - INFO - len of image_to_class_map: 29669
2024-05-13 19:46:47,577 - INFO - len of image_to_class_map_i: 29456
2024-05-13 19:53:01,745 - INFO - Epoch 12/200, Total Loss: 3.8675, Cls Loss: 0.4952, Cluster Loss: 2.0073, New Loss: 1.0245, Clip tag Loss: 1.1380
2024-05-13 19:53:01,747 - INFO -    Param Group: classifier_head, Learning Rate: 0.0991
2024-05-13 19:53:01,747 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 19:55:46,606 - INFO - Text classifier Epoch 11 Train Accuracies: Top-1 0.7051 | Top-5 0.9148
2024-05-13 19:55:46,607 - INFO - Image classifier Epoch 11 Train Accuracies: Top-1 0.7319 | Top-5 0.9362
2024-05-13 19:58:31,807 - INFO - Weighted Accuracies: Top-1 0.7922 | Top-5 0.9517
2024-05-13 20:01:16,430 - INFO - len of image_to_class_map: 29678
2024-05-13 20:01:16,431 - INFO - len of image_to_class_map_i: 29696
2024-05-13 20:07:30,861 - INFO - Epoch 13/200, Total Loss: 3.6208, Cls Loss: 0.5160, Cluster Loss: 1.9918, New Loss: 0.7971, Clip tag Loss: 1.1270
2024-05-13 20:07:30,862 - INFO -    Param Group: classifier_head, Learning Rate: 0.0990
2024-05-13 20:07:30,863 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 20:10:16,597 - INFO - Text classifier Epoch 12 Train Accuracies: Top-1 0.7119 | Top-5 0.9139
2024-05-13 20:10:16,597 - INFO - Image classifier Epoch 12 Train Accuracies: Top-1 0.7481 | Top-5 0.9414
2024-05-13 20:13:01,854 - INFO - Weighted Accuracies: Top-1 0.7946 | Top-5 0.9537
2024-05-13 20:15:46,937 - INFO - len of image_to_class_map: 29696
2024-05-13 20:15:46,938 - INFO - len of image_to_class_map_i: 29699
2024-05-13 20:22:02,648 - INFO - Epoch 14/200, Total Loss: 3.5532, Cls Loss: 0.5250, Cluster Loss: 2.0100, New Loss: 0.7279, Clip tag Loss: 1.1123
2024-05-13 20:22:02,649 - INFO -    Param Group: classifier_head, Learning Rate: 0.0988
2024-05-13 20:22:02,650 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 20:24:48,212 - INFO - Text classifier Epoch 13 Train Accuracies: Top-1 0.7123 | Top-5 0.9135
2024-05-13 20:24:48,213 - INFO - Image classifier Epoch 13 Train Accuracies: Top-1 0.7435 | Top-5 0.9420
2024-05-13 20:27:33,602 - INFO - Weighted Accuracies: Top-1 0.7892 | Top-5 0.9543
2024-05-13 20:30:18,223 - INFO - len of image_to_class_map: 29628
2024-05-13 20:30:18,224 - INFO - len of image_to_class_map_i: 29700
2024-05-13 20:36:32,678 - INFO - Epoch 15/200, Total Loss: 3.4959, Cls Loss: 0.5117, Cluster Loss: 1.9848, New Loss: 0.6992, Clip tag Loss: 1.1065
2024-05-13 20:36:32,679 - INFO -    Param Group: classifier_head, Learning Rate: 0.0986
2024-05-13 20:36:32,679 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 20:39:18,221 - INFO - Text classifier Epoch 14 Train Accuracies: Top-1 0.6999 | Top-5 0.9135
2024-05-13 20:39:18,222 - INFO - Image classifier Epoch 14 Train Accuracies: Top-1 0.7465 | Top-5 0.9431
2024-05-13 20:42:03,556 - INFO - Weighted Accuracies: Top-1 0.7887 | Top-5 0.9544
2024-05-13 20:44:48,364 - INFO - len of image_to_class_map: 29685
2024-05-13 20:44:48,366 - INFO - len of image_to_class_map_i: 29700
2024-05-13 20:51:03,000 - INFO - Epoch 16/200, Total Loss: 3.5162, Cls Loss: 0.5029, Cluster Loss: 2.0074, New Loss: 0.7096, Clip tag Loss: 1.1001
2024-05-13 20:51:03,002 - INFO -    Param Group: classifier_head, Learning Rate: 0.0984
2024-05-13 20:51:03,002 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 20:53:48,829 - INFO - Text classifier Epoch 15 Train Accuracies: Top-1 0.6995 | Top-5 0.9126
2024-05-13 20:53:48,830 - INFO - Image classifier Epoch 15 Train Accuracies: Top-1 0.7496 | Top-5 0.9445
2024-05-13 20:56:34,129 - INFO - Weighted Accuracies: Top-1 0.7895 | Top-5 0.9549
2024-05-13 20:59:19,763 - INFO - len of image_to_class_map: 29685
2024-05-13 20:59:19,764 - INFO - len of image_to_class_map_i: 29700
2024-05-13 21:05:36,278 - INFO - Epoch 17/200, Total Loss: 4.0186, Cls Loss: 0.3853, Cluster Loss: 1.9777, New Loss: 1.2571, Clip tag Loss: 1.1022
2024-05-13 21:05:36,279 - INFO -    Param Group: classifier_head, Learning Rate: 0.0982
2024-05-13 21:05:36,279 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 21:08:22,172 - INFO - Text classifier Epoch 16 Train Accuracies: Top-1 0.7916 | Top-5 0.9339
2024-05-13 21:08:22,173 - INFO - Image classifier Epoch 16 Train Accuracies: Top-1 0.7466 | Top-5 0.9438
2024-05-13 21:11:07,333 - INFO - Weighted Accuracies: Top-1 0.8152 | Top-5 0.9595
2024-05-13 21:13:52,063 - INFO - len of image_to_class_map: 29700
2024-05-13 21:13:52,063 - INFO - len of image_to_class_map_i: 29699
2024-05-13 21:20:08,664 - INFO - Epoch 18/200, Total Loss: 3.8054, Cls Loss: 0.3668, Cluster Loss: 1.9977, New Loss: 1.0299, Clip tag Loss: 1.1039
2024-05-13 21:20:08,665 - INFO -    Param Group: classifier_head, Learning Rate: 0.0980
2024-05-13 21:20:08,665 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 21:22:53,929 - INFO - Text classifier Epoch 17 Train Accuracies: Top-1 0.7920 | Top-5 0.9360
2024-05-13 21:22:53,929 - INFO - Image classifier Epoch 17 Train Accuracies: Top-1 0.7703 | Top-5 0.9502
2024-05-13 21:25:39,679 - INFO - Weighted Accuracies: Top-1 0.8229 | Top-5 0.9620
2024-05-13 21:28:25,382 - INFO - len of image_to_class_map: 29700
2024-05-13 21:28:25,384 - INFO - len of image_to_class_map_i: 29700
2024-05-13 21:34:41,520 - INFO - Epoch 19/200, Total Loss: 3.6558, Cls Loss: 0.3591, Cluster Loss: 1.9934, New Loss: 0.8868, Clip tag Loss: 1.1025
2024-05-13 21:34:41,520 - INFO -    Param Group: classifier_head, Learning Rate: 0.0978
2024-05-13 21:34:41,520 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 21:37:26,938 - INFO - Text classifier Epoch 18 Train Accuracies: Top-1 0.8040 | Top-5 0.9396
2024-05-13 21:37:26,939 - INFO - Image classifier Epoch 18 Train Accuracies: Top-1 0.7750 | Top-5 0.9527
2024-05-13 21:40:12,704 - INFO - Weighted Accuracies: Top-1 0.8267 | Top-5 0.9639
2024-05-13 21:42:57,918 - INFO - len of image_to_class_map: 29700
2024-05-13 21:42:57,919 - INFO - len of image_to_class_map_i: 29700
2024-05-13 21:49:13,793 - INFO - Epoch 20/200, Total Loss: 3.6236, Cls Loss: 0.3397, Cluster Loss: 1.9830, New Loss: 0.8809, Clip tag Loss: 1.0884
2024-05-13 21:49:13,794 - INFO -    Param Group: classifier_head, Learning Rate: 0.0976
2024-05-13 21:49:13,794 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 21:51:58,946 - INFO - Text classifier Epoch 19 Train Accuracies: Top-1 0.8050 | Top-5 0.9405
2024-05-13 21:51:58,947 - INFO - Image classifier Epoch 19 Train Accuracies: Top-1 0.7773 | Top-5 0.9516
2024-05-13 21:54:44,592 - INFO - Weighted Accuracies: Top-1 0.8314 | Top-5 0.9645
2024-05-13 21:57:29,525 - INFO - len of image_to_class_map: 29700
2024-05-13 21:57:29,527 - INFO - len of image_to_class_map_i: 29700
2024-05-13 22:03:45,734 - INFO - Epoch 21/200, Total Loss: 3.5660, Cls Loss: 0.3471, Cluster Loss: 1.9843, New Loss: 0.8252, Clip tag Loss: 1.0840
2024-05-13 22:03:45,736 - INFO -    Param Group: classifier_head, Learning Rate: 0.0973
2024-05-13 22:03:45,736 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 22:06:30,945 - INFO - Text classifier Epoch 20 Train Accuracies: Top-1 0.8083 | Top-5 0.9404
2024-05-13 22:06:30,946 - INFO - Image classifier Epoch 20 Train Accuracies: Top-1 0.7783 | Top-5 0.9514
2024-05-13 22:09:16,541 - INFO - Weighted Accuracies: Top-1 0.8309 | Top-5 0.9641
2024-05-13 22:12:02,159 - INFO - len of image_to_class_map: 29700
2024-05-13 22:12:02,160 - INFO - len of image_to_class_map_i: 29700
2024-05-13 22:18:18,897 - INFO - Epoch 22/200, Total Loss: 3.5566, Cls Loss: 0.3347, Cluster Loss: 1.9882, New Loss: 0.8144, Clip tag Loss: 1.0847
2024-05-13 22:18:18,898 - INFO -    Param Group: classifier_head, Learning Rate: 0.0970
2024-05-13 22:18:18,898 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 22:21:04,170 - INFO - Text classifier Epoch 21 Train Accuracies: Top-1 0.8079 | Top-5 0.9415
2024-05-13 22:21:04,171 - INFO - Image classifier Epoch 21 Train Accuracies: Top-1 0.7842 | Top-5 0.9539
2024-05-13 22:23:49,914 - INFO - Weighted Accuracies: Top-1 0.8336 | Top-5 0.9658
2024-05-13 22:26:35,211 - INFO - len of image_to_class_map: 29700
2024-05-13 22:26:35,212 - INFO - len of image_to_class_map_i: 29700
2024-05-13 22:32:52,069 - INFO - Epoch 23/200, Total Loss: 3.5019, Cls Loss: 0.3305, Cluster Loss: 1.9877, New Loss: 0.7813, Clip tag Loss: 1.0643
2024-05-13 22:32:52,070 - INFO -    Param Group: classifier_head, Learning Rate: 0.0968
2024-05-13 22:32:52,070 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 22:35:37,078 - INFO - Text classifier Epoch 22 Train Accuracies: Top-1 0.8114 | Top-5 0.9420
2024-05-13 22:35:37,079 - INFO - Image classifier Epoch 22 Train Accuracies: Top-1 0.7821 | Top-5 0.9544
2024-05-13 22:38:21,734 - INFO - Weighted Accuracies: Top-1 0.8317 | Top-5 0.9655
2024-05-13 22:41:07,160 - INFO - len of image_to_class_map: 29700
2024-05-13 22:41:07,161 - INFO - len of image_to_class_map_i: 29700
2024-05-13 22:47:23,094 - INFO - Epoch 24/200, Total Loss: 3.4529, Cls Loss: 0.3221, Cluster Loss: 1.9664, New Loss: 0.7518, Clip tag Loss: 1.0636
2024-05-13 22:47:23,095 - INFO -    Param Group: classifier_head, Learning Rate: 0.0965
2024-05-13 22:47:23,095 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 22:50:09,454 - INFO - Text classifier Epoch 23 Train Accuracies: Top-1 0.8103 | Top-5 0.9429
2024-05-13 22:50:09,455 - INFO - Image classifier Epoch 23 Train Accuracies: Top-1 0.7881 | Top-5 0.9548
2024-05-13 22:52:54,565 - INFO - Weighted Accuracies: Top-1 0.8345 | Top-5 0.9669
2024-05-13 22:55:39,469 - INFO - len of image_to_class_map: 29700
2024-05-13 22:55:39,470 - INFO - len of image_to_class_map_i: 29700
2024-05-13 23:01:55,942 - INFO - Epoch 25/200, Total Loss: 3.4801, Cls Loss: 0.3251, Cluster Loss: 1.9849, New Loss: 0.7615, Clip tag Loss: 1.0657
2024-05-13 23:01:55,943 - INFO -    Param Group: classifier_head, Learning Rate: 0.0962
2024-05-13 23:01:55,944 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 23:04:40,829 - INFO - Text classifier Epoch 24 Train Accuracies: Top-1 0.8142 | Top-5 0.9452
2024-05-13 23:04:40,830 - INFO - Image classifier Epoch 24 Train Accuracies: Top-1 0.7863 | Top-5 0.9546
2024-05-13 23:07:24,517 - INFO - Weighted Accuracies: Top-1 0.8334 | Top-5 0.9680
2024-05-13 23:10:08,655 - INFO - len of image_to_class_map: 29700
2024-05-13 23:10:08,657 - INFO - len of image_to_class_map_i: 29700
2024-05-13 23:16:23,399 - INFO - Epoch 26/200, Total Loss: 3.4385, Cls Loss: 0.3111, Cluster Loss: 1.9790, New Loss: 0.7355, Clip tag Loss: 1.0575
2024-05-13 23:16:23,400 - INFO -    Param Group: classifier_head, Learning Rate: 0.0959
2024-05-13 23:16:23,400 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 23:19:08,198 - INFO - Text classifier Epoch 25 Train Accuracies: Top-1 0.8115 | Top-5 0.9440
2024-05-13 23:19:08,199 - INFO - Image classifier Epoch 25 Train Accuracies: Top-1 0.7911 | Top-5 0.9564
2024-05-13 23:21:52,224 - INFO - Weighted Accuracies: Top-1 0.8365 | Top-5 0.9687
2024-05-13 23:24:36,241 - INFO - len of image_to_class_map: 29700
2024-05-13 23:24:36,242 - INFO - len of image_to_class_map_i: 29700
2024-05-13 23:30:51,015 - INFO - Epoch 27/200, Total Loss: 3.4287, Cls Loss: 0.3097, Cluster Loss: 1.9760, New Loss: 0.7303, Clip tag Loss: 1.0556
2024-05-13 23:30:51,016 - INFO -    Param Group: classifier_head, Learning Rate: 0.0956
2024-05-13 23:30:51,016 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 23:33:36,245 - INFO - Text classifier Epoch 26 Train Accuracies: Top-1 0.8150 | Top-5 0.9441
2024-05-13 23:33:36,245 - INFO - Image classifier Epoch 26 Train Accuracies: Top-1 0.7902 | Top-5 0.9565
2024-05-13 23:36:20,997 - INFO - Weighted Accuracies: Top-1 0.8347 | Top-5 0.9674
2024-05-13 23:39:04,974 - INFO - len of image_to_class_map: 29700
2024-05-13 23:39:04,975 - INFO - len of image_to_class_map_i: 29700
2024-05-13 23:45:22,199 - INFO - Epoch 28/200, Total Loss: 3.3946, Cls Loss: 0.3054, Cluster Loss: 1.9684, New Loss: 0.7134, Clip tag Loss: 1.0454
2024-05-13 23:45:22,200 - INFO -    Param Group: classifier_head, Learning Rate: 0.0952
2024-05-13 23:45:22,200 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-13 23:48:08,090 - INFO - Text classifier Epoch 27 Train Accuracies: Top-1 0.8102 | Top-5 0.9469
2024-05-13 23:48:08,090 - INFO - Image classifier Epoch 27 Train Accuracies: Top-1 0.7941 | Top-5 0.9576
2024-05-13 23:50:53,399 - INFO - Weighted Accuracies: Top-1 0.8339 | Top-5 0.9687
2024-05-13 23:53:38,414 - INFO - len of image_to_class_map: 29700
2024-05-13 23:53:38,415 - INFO - len of image_to_class_map_i: 29700
2024-05-13 23:59:54,957 - INFO - Epoch 29/200, Total Loss: 3.3601, Cls Loss: 0.3009, Cluster Loss: 1.9613, New Loss: 0.6864, Clip tag Loss: 1.0445
2024-05-13 23:59:54,958 - INFO -    Param Group: classifier_head, Learning Rate: 0.0949
2024-05-13 23:59:54,958 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 00:02:40,097 - INFO - Text classifier Epoch 28 Train Accuracies: Top-1 0.8162 | Top-5 0.9439
2024-05-14 00:02:40,098 - INFO - Image classifier Epoch 28 Train Accuracies: Top-1 0.7898 | Top-5 0.9574
2024-05-14 00:05:25,290 - INFO - Weighted Accuracies: Top-1 0.8341 | Top-5 0.9668
2024-05-14 00:08:09,613 - INFO - len of image_to_class_map: 29700
2024-05-14 00:08:09,614 - INFO - len of image_to_class_map_i: 29700
2024-05-14 00:14:25,868 - INFO - Epoch 30/200, Total Loss: 3.3410, Cls Loss: 0.2954, Cluster Loss: 1.9574, New Loss: 0.6778, Clip tag Loss: 1.0382
2024-05-14 00:14:25,869 - INFO -    Param Group: classifier_head, Learning Rate: 0.0946
2024-05-14 00:14:25,869 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 00:17:11,634 - INFO - Text classifier Epoch 29 Train Accuracies: Top-1 0.8139 | Top-5 0.9454
2024-05-14 00:17:11,634 - INFO - Image classifier Epoch 29 Train Accuracies: Top-1 0.7949 | Top-5 0.9551
2024-05-14 00:19:56,708 - INFO - Weighted Accuracies: Top-1 0.8359 | Top-5 0.9667
2024-05-14 00:22:41,526 - INFO - len of image_to_class_map: 29700
2024-05-14 00:22:41,544 - INFO - len of image_to_class_map_i: 29700
2024-05-14 00:28:59,101 - INFO - Epoch 31/200, Total Loss: 3.3240, Cls Loss: 0.2870, Cluster Loss: 1.9522, New Loss: 0.6702, Clip tag Loss: 1.0347
2024-05-14 00:28:59,102 - INFO -    Param Group: classifier_head, Learning Rate: 0.0942
2024-05-14 00:28:59,102 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 00:31:44,759 - INFO - Text classifier Epoch 30 Train Accuracies: Top-1 0.8163 | Top-5 0.9459
2024-05-14 00:31:44,760 - INFO - Image classifier Epoch 30 Train Accuracies: Top-1 0.7903 | Top-5 0.9552
2024-05-14 00:34:29,577 - INFO - Weighted Accuracies: Top-1 0.8340 | Top-5 0.9670
2024-05-14 00:37:14,471 - INFO - len of image_to_class_map: 29700
2024-05-14 00:37:14,472 - INFO - len of image_to_class_map_i: 29700
2024-05-14 00:43:32,127 - INFO - Epoch 32/200, Total Loss: 3.3250, Cls Loss: 0.2685, Cluster Loss: 1.9684, New Loss: 0.6597, Clip tag Loss: 1.0369
2024-05-14 00:43:32,131 - INFO -    Param Group: classifier_head, Learning Rate: 0.0938
2024-05-14 00:43:32,131 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 00:46:17,675 - INFO - Text classifier Epoch 31 Train Accuracies: Top-1 0.8155 | Top-5 0.9449
2024-05-14 00:46:17,675 - INFO - Image classifier Epoch 31 Train Accuracies: Top-1 0.7921 | Top-5 0.9556
2024-05-14 00:49:02,876 - INFO - Weighted Accuracies: Top-1 0.8367 | Top-5 0.9667
2024-05-14 00:51:47,545 - INFO - len of image_to_class_map: 29700
2024-05-14 00:51:47,547 - INFO - len of image_to_class_map_i: 29700
2024-05-14 00:58:03,118 - INFO - Epoch 33/200, Total Loss: 3.3051, Cls Loss: 0.2676, Cluster Loss: 1.9687, New Loss: 0.6474, Clip tag Loss: 1.0292
2024-05-14 00:58:03,119 - INFO -    Param Group: classifier_head, Learning Rate: 0.0934
2024-05-14 00:58:03,120 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 01:00:48,418 - INFO - Text classifier Epoch 32 Train Accuracies: Top-1 0.8171 | Top-5 0.9449
2024-05-14 01:00:48,419 - INFO - Image classifier Epoch 32 Train Accuracies: Top-1 0.7893 | Top-5 0.9571
2024-05-14 01:03:33,284 - INFO - Weighted Accuracies: Top-1 0.8331 | Top-5 0.9679
2024-05-14 01:06:18,236 - INFO - len of image_to_class_map: 29700
2024-05-14 01:06:18,237 - INFO - len of image_to_class_map_i: 29700
2024-05-14 01:12:34,641 - INFO - Epoch 34/200, Total Loss: 3.2967, Cls Loss: 0.2644, Cluster Loss: 1.9664, New Loss: 0.6457, Clip tag Loss: 1.0249
2024-05-14 01:12:34,642 - INFO -    Param Group: classifier_head, Learning Rate: 0.0930
2024-05-14 01:12:34,642 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 01:15:19,968 - INFO - Text classifier Epoch 33 Train Accuracies: Top-1 0.8157 | Top-5 0.9478
2024-05-14 01:15:19,969 - INFO - Image classifier Epoch 33 Train Accuracies: Top-1 0.7909 | Top-5 0.9555
2024-05-14 01:18:05,822 - INFO - Weighted Accuracies: Top-1 0.8351 | Top-5 0.9687
2024-05-14 01:20:50,932 - INFO - len of image_to_class_map: 29700
2024-05-14 01:20:50,933 - INFO - len of image_to_class_map_i: 29700
2024-05-14 01:27:08,182 - INFO - Epoch 35/200, Total Loss: 3.2623, Cls Loss: 0.2653, Cluster Loss: 1.9661, New Loss: 0.6150, Clip tag Loss: 1.0213
2024-05-14 01:27:08,183 - INFO -    Param Group: classifier_head, Learning Rate: 0.0926
2024-05-14 01:27:08,183 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-14 01:29:53,279 - INFO - Text classifier Epoch 34 Train Accuracies: Top-1 0.8199 | Top-5 0.9478
2024-05-14 01:29:53,280 - INFO - Image classifier Epoch 34 Train Accuracies: Top-1 0.7869 | Top-5 0.9559
2024-05-14 01:32:38,237 - INFO - Weighted Accuracies: Top-1 0.8352 | Top-5 0.9684
2024-05-14 01:35:23,640 - INFO - len of image_to_class_map: 29700
2024-05-14 01:35:23,654 - INFO - len of image_to_class_map_i: 29700
2024-05-14 01:41:40,667 - INFO - Epoch 36/200, Total Loss: 3.2638, Cls Loss: 0.2570, Cluster Loss: 1.9658, New Loss: 0.6230, Clip tag Loss: 1.0168
2024-05-14 01:41:40,668 - INFO -    Param Group: classifier_head, Learning Rate: 0.0922
2024-05-14 01:41:40,668 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
