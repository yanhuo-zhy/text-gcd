2023-10-23 10:22:05,972 - INFO - Training cifar10_topk10_pseudo(10-15) with the following settings:
2023-10-23 10:22:05,973 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar10_topk10_pseudo(10-15)
 seed_num=1
 evaluate=False
 dataset_name=cifar10
 backbone_name=ViT-B/16
 epochs=50
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_num=10
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 train_classes=range(0, 5)
 unlabeled_classes=range(5, 10)
 num_labeled_classes=5
 num_unlabeled_classes=5
 num_classes=10
 log_path=exp/10-23-10-22-cifar10_topk10_pseudo(10-15)/logs/log.txt
 model_path=exp/10-23-10-22-cifar10_topk10_pseudo(10-15)/models/model.pth
 device=cuda
2023-10-23 10:22:05,977 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-10-23 10:22:11,936 - INFO - Building custom CLIP
2023-10-23 10:22:14,016 - INFO - Turning off gradients in both the image and the text encoder
2023-10-23 10:22:14,018 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-10-23 10:22:14,019 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-10-23 10:22:18,656 - INFO - len of train dataset: 50000
2023-10-23 10:22:18,656 - INFO - len of test dataset: 37500
2023-10-23 10:25:34,697 - INFO - len of image_to_class_map: 100
2023-10-23 10:25:34,697 - INFO - len of image_to_class_map_i: 100
2023-10-23 10:28:45,735 - INFO - Before Train Accuracies: All 0.2614 | Old 0.0067 | New 0.3888
2023-10-23 10:28:45,736 - INFO - Before Train Accuracies: All 0.2351 | Old 0.1058 | New 0.2998
2023-10-23 10:38:17,856 - INFO - Epoch 1/50, Total Loss: 5.3649, Cls Loss: 0.3429, Cluster Loss: 3.1247, New Loss: 0.0000, Clip tag Loss: 1.8972
2023-10-23 10:38:17,857 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-10-23 10:38:17,857 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-10-23 10:41:27,485 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.6555 | Old 0.0000 | New 0.9833
2023-10-23 10:41:27,486 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.6198 | Old 0.0000 | New 0.9298
2023-10-23 10:44:37,252 - INFO - Weighted Accuracies: All 0.6543 | Old 0.0000 | New 0.9814
2023-10-23 10:47:47,098 - INFO - len of image_to_class_map: 76
2023-10-23 10:47:47,099 - INFO - len of image_to_class_map_i: 76
