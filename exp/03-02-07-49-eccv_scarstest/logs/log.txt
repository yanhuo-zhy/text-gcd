2024-03-02 07:49:38,082 - INFO - Training eccv_scarstest with the following settings:
2024-03-02 07:49:38,082 - INFO - Command-line arguments: output_dir=exp
 experiment_name=eccv_scarstest
 seed_num=1
 evaluate=False
 dataset_name=scars
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 98)
 unlabeled_classes=range(98, 196)
 num_labeled_classes=98
 num_unlabeled_classes=98
 num_classes=196
 log_path=exp/03-02-07-49-eccv_scarstest/logs/log.txt
 model_path=exp/03-02-07-49-eccv_scarstest/models/model.pth
 device=cuda
2024-03-02 07:49:38,087 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-03-02 07:49:41,743 - INFO - Building custom CLIP
2024-03-02 07:49:49,622 - INFO - Turning off gradients in both the image and the text encoder
2024-03-02 07:49:49,628 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-03-02 07:49:49,632 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-03-02 07:49:50,376 - INFO - len of train dataset: 8144
2024-03-02 07:49:50,376 - INFO - len of test dataset: 6118
2024-03-02 07:49:50,376 - INFO - Pseudo Nums: 18
2024-03-02 07:50:25,126 - INFO - len of image_to_class_map: 2163
2024-03-02 07:50:25,127 - INFO - len of image_to_class_map_i: 2253
2024-03-02 07:50:59,112 - INFO - Before Train Accuracies: All 0.1183 | Old 0.0143 | New 0.1698
2024-03-02 07:50:59,113 - INFO - Before Train Accuracies: All 0.0708 | Old 0.0375 | New 0.0872
2024-03-02 07:52:16,073 - INFO - Epoch 1/200, Total Loss: 11.8957, Cls Loss: 9.8802, Cluster Loss: 10.0827, New Loss: 0.0000, Clip tag Loss: 1.8535
2024-03-02 07:52:16,074 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-03-02 07:52:16,074 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-03-02 07:52:47,319 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.3488 | Old 0.2769 | New 0.3844
2024-03-02 07:52:47,320 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.1798 | Old 0.1486 | New 0.1953
2024-03-02 07:53:18,624 - INFO - Weighted Accuracies: All 0.2411 | Old 0.2261 | New 0.2485
2024-03-02 07:53:48,653 - INFO - len of image_to_class_map: 2860
2024-03-02 07:53:48,654 - INFO - len of image_to_class_map_i: 2866
2024-03-02 07:55:02,191 - INFO - Epoch 2/200, Total Loss: 10.1270, Cls Loss: 8.0070, Cluster Loss: 8.5079, New Loss: 0.0000, Clip tag Loss: 1.7193
2024-03-02 07:55:02,192 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-03-02 07:55:02,192 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-03-02 07:55:34,906 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.4310 | Old 0.4329 | New 0.4301
2024-03-02 07:55:34,906 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.2484 | Old 0.2596 | New 0.2429
2024-03-02 07:56:06,343 - INFO - Weighted Accuracies: All 0.3153 | Old 0.3850 | New 0.2808
2024-03-02 07:56:40,622 - INFO - len of image_to_class_map: 2943
2024-03-02 07:56:40,622 - INFO - len of image_to_class_map_i: 2610
2024-03-02 07:57:51,404 - INFO - Epoch 3/200, Total Loss: 7.8248, Cls Loss: 6.1245, Cluster Loss: 6.1519, New Loss: 0.0000, Clip tag Loss: 1.6783
2024-03-02 07:57:51,405 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-03-02 07:57:51,405 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-03-02 07:58:22,633 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.4958 | Old 0.6466 | New 0.4211
2024-03-02 07:58:22,634 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.3132 | Old 0.3578 | New 0.2911
2024-03-02 07:58:53,363 - INFO - Weighted Accuracies: All 0.3962 | Old 0.5089 | New 0.3404
