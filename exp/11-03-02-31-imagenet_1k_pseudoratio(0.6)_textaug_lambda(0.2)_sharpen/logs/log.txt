2023-11-03 02:31:45,633 - INFO - Training imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_sharpen with the following settings:
2023-11-03 02:31:45,633 - INFO - Command-line arguments: output_dir=exp
 experiment_name=imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_sharpen
 seed_num=1
 evaluate=False
 dataset_name=imagenet_1k
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 500)
 unlabeled_classes=range(500, 1000)
 num_labeled_classes=500
 num_unlabeled_classes=500
 num_classes=1000
 log_path=exp/11-03-02-31-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_sharpen/logs/log.txt
 model_path=exp/11-03-02-31-imagenet_1k_pseudoratio(0.6)_textaug_lambda(0.2)_sharpen/models/model.pth
 device=cuda
2023-11-03 02:31:45,639 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-03 02:31:49,132 - INFO - Building custom CLIP
2023-11-03 02:31:49,509 - INFO - Turning off gradients in both the image and the text encoder
2023-11-03 02:31:49,511 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-03 02:31:49,512 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-03 02:44:34,303 - INFO - len of train dataset: 1281167
2023-11-03 02:44:34,303 - INFO - len of test dataset: 960023
2023-11-03 02:44:34,303 - INFO - Pseudo Nums: 576
2023-11-03 04:08:24,011 - INFO - len of image_to_class_map: 304478
2023-11-03 04:08:24,015 - INFO - len of image_to_class_map_i: 379194
2023-11-03 04:53:07,918 - INFO - Before Train Accuracies: All 0.0586 | Old 0.0613 | New 0.0572
2023-11-03 04:53:07,919 - INFO - Before Train Accuracies: All 0.0473 | Old 0.0292 | New 0.0564
2023-11-03 07:17:45,330 - INFO - Epoch 1/200, Total Loss: 10.7765, Cls Loss: 7.9116, Cluster Loss: 10.3664, New Loss: 0.0000, Clip tag Loss: 0.9011
2023-11-03 07:17:45,330 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-03 07:17:45,330 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-03 08:02:23,879 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.3273 | Old 0.6380 | New 0.1711
2023-11-03 08:02:23,880 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.2917 | Old 0.6668 | New 0.1031
2023-11-03 08:47:05,953 - INFO - Weighted Accuracies: All 0.3420 | Old 0.6964 | New 0.1638
2023-11-03 09:32:20,162 - INFO - len of image_to_class_map: 467176
2023-11-03 09:32:20,166 - INFO - len of image_to_class_map_i: 511259
2023-11-03 11:58:39,440 - INFO - Epoch 2/200, Total Loss: 10.6239, Cls Loss: 7.5673, Cluster Loss: 10.2975, New Loss: 0.0000, Clip tag Loss: 0.8725
2023-11-03 11:58:39,441 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-03 11:58:39,441 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-03 12:59:27,568 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.3241 | Old 0.6278 | New 0.1715
2023-11-03 12:59:27,569 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.3059 | Old 0.7066 | New 0.1044
2023-11-03 13:45:10,778 - INFO - Weighted Accuracies: All 0.3418 | Old 0.7170 | New 0.1532
2023-11-03 14:30:22,905 - INFO - len of image_to_class_map: 459180
2023-11-03 14:30:22,914 - INFO - len of image_to_class_map_i: 504486
2023-11-03 17:23:46,189 - INFO - Epoch 3/200, Total Loss: 10.5711, Cls Loss: 7.4973, Cluster Loss: 10.2610, New Loss: 0.0000, Clip tag Loss: 0.8629
2023-11-03 17:23:46,192 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-03 17:23:46,192 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-03 18:16:14,819 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3244 | Old 0.6316 | New 0.1700
2023-11-03 18:16:14,820 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.3129 | Old 0.7155 | New 0.1105
2023-11-03 19:03:27,693 - INFO - Weighted Accuracies: All 0.3438 | Old 0.7012 | New 0.1642
2023-11-03 19:48:41,713 - INFO - len of image_to_class_map: 455604
2023-11-03 19:48:44,105 - INFO - len of image_to_class_map_i: 500189
