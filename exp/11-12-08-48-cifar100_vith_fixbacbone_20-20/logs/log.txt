2023-11-12 08:48:12,074 - INFO - Training cifar100_vith_fixbacbone_20-20 with the following settings:
2023-11-12 08:48:12,074 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_vith_fixbacbone_20-20
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=110
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=20
 coteaching_epoch_i=20
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 80)
 unlabeled_classes=range(80, 100)
 num_labeled_classes=80
 num_unlabeled_classes=20
 num_classes=100
 log_path=exp/11-12-08-48-cifar100_vith_fixbacbone_20-20/logs/log.txt
 model_path=exp/11-12-08-48-cifar100_vith_fixbacbone_20-20/models/model.pth
 device=cuda
2023-11-12 08:48:12,078 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-12 08:48:12,464 - INFO - Loaded hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K model config.
2023-11-12 08:48:18,509 - INFO - Loading pretrained hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K weights (/home/zhun.zhong/.cache/huggingface/hub/models--laion--CLIP-ViT-H-14-laion2B-s32B-b79K/snapshots/94a64189c3535c1cb44acfcccd7b0908c1c8eb23/open_clip_pytorch_model.bin).
2023-11-12 08:48:42,482 - INFO - Building custom CLIP
2023-11-12 08:48:43,666 - INFO - Turning off gradients in both the image and the text encoder
2023-11-12 08:48:43,670 - INFO - Parameters that require gradients: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-12 08:48:43,672 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-12 08:48:47,235 - INFO - len of train dataset: 50000
2023-11-12 08:48:47,235 - INFO - len of test dataset: 30000
2023-11-12 08:48:47,235 - INFO - Pseudo Nums: 180
2023-11-12 09:02:13,157 - INFO - len of image_to_class_map: 12969
2023-11-12 09:02:13,157 - INFO - len of image_to_class_map_i: 13202
2023-11-12 09:15:25,536 - INFO - Before Train Accuracies: All 0.1586 | Old 0.0815 | New 0.3128
2023-11-12 09:15:25,536 - INFO - Before Train Accuracies: All 0.1052 | Old 0.0519 | New 0.2117
2023-11-12 09:59:19,725 - INFO - Epoch 1/200, Total Loss: 5.5212, Cls Loss: 4.5697, Cluster Loss: 4.2505, New Loss: 0.0000, Clip tag Loss: 1.2068
2023-11-12 09:59:19,725 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-12 09:59:19,725 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-12 10:12:31,259 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.7252 | Old 0.7789 | New 0.6178
2023-11-12 10:12:31,259 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.6621 | Old 0.7568 | New 0.4727
2023-11-12 10:25:42,626 - INFO - Weighted Accuracies: All 0.6751 | Old 0.7845 | New 0.4563
2023-11-12 10:38:53,767 - INFO - len of image_to_class_map: 17541
2023-11-12 10:38:53,768 - INFO - len of image_to_class_map_i: 16936
2023-11-12 11:22:46,774 - INFO - Epoch 2/200, Total Loss: 3.7862, Cls Loss: 2.5411, Cluster Loss: 2.5916, New Loss: 0.0000, Clip tag Loss: 1.2047
2023-11-12 11:22:46,775 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-12 11:22:46,775 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-12 11:35:57,759 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.7387 | Old 0.7940 | New 0.6281
2023-11-12 11:35:57,759 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.6959 | Old 0.8355 | New 0.4167
2023-11-12 11:49:09,695 - INFO - Weighted Accuracies: All 0.6545 | Old 0.7899 | New 0.3838
2023-11-12 12:02:21,540 - INFO - len of image_to_class_map: 17996
2023-11-12 12:02:21,541 - INFO - len of image_to_class_map_i: 17676
2023-11-12 12:46:13,717 - INFO - Epoch 3/200, Total Loss: 3.5976, Cls Loss: 2.1497, Cluster Loss: 2.4523, New Loss: 0.0000, Clip tag Loss: 1.2058
2023-11-12 12:46:13,717 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2023-11-12 12:46:13,717 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-12 12:59:24,772 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.7478 | Old 0.8177 | New 0.6081
2023-11-12 12:59:24,773 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.6989 | Old 0.8595 | New 0.3777
2023-11-12 13:12:36,236 - INFO - Weighted Accuracies: All 0.6521 | Old 0.8086 | New 0.3391
