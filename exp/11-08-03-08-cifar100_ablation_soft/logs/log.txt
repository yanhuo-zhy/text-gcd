2023-11-08 03:08:46,177 - INFO - Training cifar100_ablation_soft with the following settings:
2023-11-08 03:08:46,177 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_ablation_soft
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 80)
 unlabeled_classes=range(80, 100)
 num_labeled_classes=80
 num_unlabeled_classes=20
 num_classes=100
 log_path=exp/11-08-03-08-cifar100_ablation_soft/logs/log.txt
 model_path=exp/11-08-03-08-cifar100_ablation_soft/models/model.pth
 device=cuda
2023-11-08 03:08:46,181 - INFO - Loading CLIP (backbone: ViT-B/16)
2023-11-08 03:08:50,369 - INFO - Building custom CLIP
2023-11-08 03:08:57,450 - INFO - Turning off gradients in both the image and the text encoder
2023-11-08 03:08:57,453 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-08 03:08:57,455 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2023-11-08 03:09:04,118 - INFO - len of train dataset: 50000
2023-11-08 03:09:04,118 - INFO - len of test dataset: 30000
2023-11-08 03:09:04,118 - INFO - Pseudo Nums: 180
2023-11-08 03:12:41,277 - INFO - len of image_to_class_map: 10983
2023-11-08 03:12:41,278 - INFO - len of image_to_class_map_i: 10869
2023-11-08 03:16:41,943 - INFO - Before Train Accuracies: All 0.1205 | Old 0.0823 | New 0.1970
2023-11-08 03:16:41,944 - INFO - Before Train Accuracies: All 0.0724 | Old 0.0167 | New 0.1838
2023-11-08 03:31:23,985 - INFO - Epoch 1/200, Total Loss: 6.5108, Cls Loss: 5.1949, Cluster Loss: 4.8389, New Loss: 0.0000, Clip tag Loss: 1.6007
2023-11-08 03:31:23,987 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-08 03:31:23,987 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-08 03:35:32,452 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.6854 | Old 0.7531 | New 0.5499
2023-11-08 03:35:32,452 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.5592 | Old 0.6472 | New 0.3831
2023-11-08 03:39:42,169 - INFO - Weighted Accuracies: All 0.6641 | Old 0.7434 | New 0.5056
2023-11-08 03:43:46,072 - INFO - len of image_to_class_map: 17524
2023-11-08 03:43:46,073 - INFO - len of image_to_class_map_i: 17421
2023-11-08 03:58:31,644 - INFO - Epoch 2/200, Total Loss: 4.1408, Cls Loss: 2.7367, Cluster Loss: 2.6281, New Loss: 0.0000, Clip tag Loss: 1.4910
2023-11-08 03:58:31,645 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2023-11-08 03:58:31,645 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2023-11-08 04:02:36,525 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.7151 | Old 0.8079 | New 0.5295
2023-11-08 04:02:36,526 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.6089 | Old 0.6932 | New 0.4404
