2024-05-15 09:55:31,833 - INFO - Training cifar100_testontest with the following settings:
2024-05-15 09:55:31,833 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar100_testontest
 seed_num=1
 evaluate=False
 dataset_name=cifar100
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 80)
 unlabeled_classes=range(80, 100)
 num_labeled_classes=80
 num_unlabeled_classes=20
 num_classes=100
 log_path=exp/cifar100_testontest/logs/log.txt
 model_path=exp/cifar100_testontest/models/model.pth
 device=cuda
2024-05-15 09:55:31,837 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-15 09:55:35,299 - INFO - Building custom CLIP
2024-05-15 09:55:42,403 - INFO - Turning off gradients in both the image and the text encoder
2024-05-15 09:55:42,406 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-15 09:55:42,407 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-15 09:55:47,844 - INFO - len of train dataset: 50000
2024-05-15 09:55:47,844 - INFO - len of test dataset: 30000
2024-05-15 09:55:47,844 - INFO - Pseudo Nums: 180
2024-05-15 09:57:33,042 - INFO - len of image_to_class_map: 10982
2024-05-15 09:57:33,043 - INFO - len of image_to_class_map_i: 10862
2024-05-15 09:58:10,919 - INFO - Before Train Accuracies: All 0.0233 | Old 0.0240 | New 0.0205
2024-05-15 09:58:10,920 - INFO - Before Train Accuracies: All 0.0579 | Old 0.0520 | New 0.0815
2024-05-15 10:04:21,199 - INFO - Epoch 1/200, Total Loss: 6.5111, Cls Loss: 5.1951, Cluster Loss: 4.8391, New Loss: 0.0000, Clip tag Loss: 1.6008
2024-05-15 10:04:21,202 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-15 10:04:21,202 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:04:56,610 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.0393 | Old 0.0399 | New 0.0370
2024-05-15 10:04:56,611 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.6111 | Old 0.7183 | New 0.1825
2024-05-15 10:05:32,507 - INFO - Weighted Accuracies: All 0.2413 | Old 0.2746 | New 0.1080
2024-05-15 10:07:12,589 - INFO - len of image_to_class_map: 17523
2024-05-15 10:07:12,590 - INFO - len of image_to_class_map_i: 17427
2024-05-15 10:13:26,665 - INFO - Epoch 2/200, Total Loss: 4.1408, Cls Loss: 2.7367, Cluster Loss: 2.6281, New Loss: 0.0000, Clip tag Loss: 1.4909
2024-05-15 10:13:26,666 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-15 10:13:26,666 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:14:03,354 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.0400 | Old 0.0399 | New 0.0405
2024-05-15 10:14:03,357 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.6565 | Old 0.7479 | New 0.2910
2024-05-15 10:14:39,796 - INFO - Weighted Accuracies: All 0.2465 | Old 0.2804 | New 0.1110
2024-05-15 10:16:21,729 - INFO - len of image_to_class_map: 17947
2024-05-15 10:16:21,730 - INFO - len of image_to_class_map_i: 17778
2024-05-15 10:22:37,681 - INFO - Epoch 3/200, Total Loss: 3.8292, Cls Loss: 2.3308, Cluster Loss: 2.4275, New Loss: 0.0000, Clip tag Loss: 1.4210
2024-05-15 10:22:37,682 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-15 10:22:37,682 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:23:14,544 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.0397 | Old 0.0394 | New 0.0410
2024-05-15 10:23:14,545 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.6790 | Old 0.7628 | New 0.3440
2024-05-15 10:23:50,582 - INFO - Weighted Accuracies: All 0.2481 | Old 0.2886 | New 0.0860
2024-05-15 10:25:32,534 - INFO - len of image_to_class_map: 18000
2024-05-15 10:25:32,535 - INFO - len of image_to_class_map_i: 17948
2024-05-15 10:31:46,142 - INFO - Epoch 4/200, Total Loss: 3.6713, Cls Loss: 2.1253, Cluster Loss: 2.3363, New Loss: 0.0000, Clip tag Loss: 1.3771
2024-05-15 10:31:46,143 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-15 10:31:46,143 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:32:22,732 - INFO - Text classifier Epoch 3 Train Accuracies: All 0.0401 | Old 0.0405 | New 0.0385
2024-05-15 10:32:22,733 - INFO - Image classifier Epoch 3 Train Accuracies: All 0.6955 | Old 0.7681 | New 0.4050
2024-05-15 10:32:59,506 - INFO - Weighted Accuracies: All 0.2466 | Old 0.2819 | New 0.1055
2024-05-15 10:34:41,687 - INFO - len of image_to_class_map: 18000
2024-05-15 10:34:41,688 - INFO - len of image_to_class_map_i: 17946
2024-05-15 10:40:57,447 - INFO - Epoch 5/200, Total Loss: 3.5990, Cls Loss: 2.0328, Cluster Loss: 2.2990, New Loss: 0.0000, Clip tag Loss: 1.3532
2024-05-15 10:40:57,448 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-15 10:40:57,448 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:41:34,449 - INFO - Text classifier Epoch 4 Train Accuracies: All 0.0398 | Old 0.0398 | New 0.0400
2024-05-15 10:41:34,450 - INFO - Image classifier Epoch 4 Train Accuracies: All 0.7062 | Old 0.7735 | New 0.4370
2024-05-15 10:42:10,356 - INFO - Weighted Accuracies: All 0.2557 | Old 0.2930 | New 0.1065
2024-05-15 10:43:52,099 - INFO - len of image_to_class_map: 17997
2024-05-15 10:43:52,100 - INFO - len of image_to_class_map_i: 17958
2024-05-15 10:50:06,843 - INFO - Epoch 6/200, Total Loss: 3.5006, Cls Loss: 1.9205, Cluster Loss: 2.2443, New Loss: 0.0000, Clip tag Loss: 1.3211
2024-05-15 10:50:06,845 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-15 10:50:06,845 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-15 10:50:42,984 - INFO - Text classifier Epoch 5 Train Accuracies: All 0.0398 | Old 0.0405 | New 0.0370
2024-05-15 10:50:42,985 - INFO - Image classifier Epoch 5 Train Accuracies: All 0.7082 | Old 0.7751 | New 0.4405
2024-05-15 10:51:19,646 - INFO - Weighted Accuracies: All 0.2606 | Old 0.2984 | New 0.1095
