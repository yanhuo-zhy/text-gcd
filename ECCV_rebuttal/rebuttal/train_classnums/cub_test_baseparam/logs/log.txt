2024-05-12 01:21:15,350 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 01:21:15,644 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cpu
2024-05-12 01:21:15,679 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 01:21:44,258 - INFO - Building custom CLIP
2024-05-12 01:21:44,265 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 01:21:44,267 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:21:44,269 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:27:43,741 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 01:27:43,742 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cpu
2024-05-12 01:27:43,747 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 01:27:47,261 - INFO - Building custom CLIP
2024-05-12 01:27:47,267 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 01:27:47,270 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:27:47,271 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:27:55,505 - INFO - len of train dataset: 5994
2024-05-12 01:27:55,506 - INFO - len of test dataset: 4494
2024-05-12 01:27:55,506 - INFO - Pseudo Nums: 13
2024-05-12 01:36:45,746 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 01:36:45,768 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cuda
2024-05-12 01:36:46,023 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 01:36:49,490 - INFO - Building custom CLIP
2024-05-12 01:36:52,618 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 01:36:52,625 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:36:52,629 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:37:00,882 - INFO - len of train dataset: 5994
2024-05-12 01:37:00,883 - INFO - len of test dataset: 4494
2024-05-12 01:37:00,883 - INFO - Pseudo Nums: 13
2024-05-12 01:37:31,169 - INFO - len of image_to_class_map: 1415
2024-05-12 01:37:31,170 - INFO - len of image_to_class_map_i: 1677
2024-05-12 01:37:53,306 - INFO - Before Train Accuracies: All 0.0883 | Old 0.0607 | New 0.1022
2024-05-12 01:37:53,307 - INFO - Before Train Accuracies: All 0.0641 | Old 0.0187 | New 0.0868
2024-05-12 01:40:03,049 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 01:40:03,050 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cuda
2024-05-12 01:40:03,055 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 01:40:06,369 - INFO - Building custom CLIP
2024-05-12 01:40:09,657 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 01:40:09,664 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:40:09,668 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 01:40:16,818 - INFO - len of train dataset: 5994
2024-05-12 01:40:16,819 - INFO - len of test dataset: 4494
2024-05-12 01:40:16,820 - INFO - Pseudo Nums: 13
2024-05-12 01:40:41,212 - INFO - len of image_to_class_map: 1415
2024-05-12 01:40:41,213 - INFO - len of image_to_class_map_i: 1677
2024-05-12 01:41:03,189 - INFO - Before Train Accuracies: All 0.0883 | Old 0.0607 | New 0.1022
2024-05-12 01:41:03,190 - INFO - Before Train Accuracies: All 0.0641 | Old 0.0187 | New 0.0868
2024-05-12 01:42:03,665 - INFO - Epoch 1/200, Total Loss: 12.3238, Cls Loss: 10.1177, Cluster Loss: 10.2260, New Loss: 0.0000, Clip tag Loss: 2.1195
2024-05-12 01:42:03,666 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 01:42:03,667 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:42:25,658 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.2608 | Old 0.2700 | New 0.2562
2024-05-12 01:42:25,659 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.1647 | Old 0.1493 | New 0.1723
2024-05-12 01:42:47,573 - INFO - Weighted Accuracies: All 0.1934 | Old 0.2067 | New 0.1867
2024-05-12 01:43:09,647 - INFO - len of image_to_class_map: 1947
2024-05-12 01:43:09,648 - INFO - len of image_to_class_map_i: 2185
2024-05-12 01:44:08,561 - INFO - Epoch 2/200, Total Loss: 11.4569, Cls Loss: 8.9212, Cluster Loss: 9.5241, New Loss: 0.0000, Clip tag Loss: 2.0534
2024-05-12 01:44:08,563 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 01:44:08,563 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:44:30,557 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.2822 | Old 0.2720 | New 0.2872
2024-05-12 01:44:30,558 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.1938 | Old 0.2220 | New 0.1797
2024-05-12 01:44:52,696 - INFO - Weighted Accuracies: All 0.2303 | Old 0.2693 | New 0.2108
2024-05-12 01:45:14,717 - INFO - len of image_to_class_map: 1743
2024-05-12 01:45:14,718 - INFO - len of image_to_class_map_i: 2034
2024-05-12 01:46:14,128 - INFO - Epoch 3/200, Total Loss: 9.7490, Cls Loss: 7.5298, Cluster Loss: 7.7767, New Loss: 0.0000, Clip tag Loss: 2.0217
2024-05-12 01:46:14,129 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-12 01:46:14,129 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:46:36,176 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3022 | Old 0.3907 | New 0.2578
2024-05-12 01:46:36,177 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.2519 | Old 0.3740 | New 0.1907
2024-05-12 01:46:58,154 - INFO - Weighted Accuracies: All 0.2839 | Old 0.4180 | New 0.2168
2024-05-12 01:47:20,260 - INFO - len of image_to_class_map: 1685
2024-05-12 01:47:20,261 - INFO - len of image_to_class_map_i: 2005
2024-05-12 01:48:19,834 - INFO - Epoch 4/200, Total Loss: 8.3365, Cls Loss: 6.3913, Cluster Loss: 6.3666, New Loss: 0.0000, Clip tag Loss: 1.9650
2024-05-12 01:48:19,853 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-12 01:48:19,853 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:48:46,500 - INFO - Text classifier Epoch 3 Train Accuracies: All 0.3556 | Old 0.4613 | New 0.3026
2024-05-12 01:48:46,501 - INFO - Image classifier Epoch 3 Train Accuracies: All 0.2944 | Old 0.4667 | New 0.2081
2024-05-12 01:49:08,572 - INFO - Weighted Accuracies: All 0.3296 | Old 0.5160 | New 0.2361
2024-05-12 01:49:30,748 - INFO - len of image_to_class_map: 1828
2024-05-12 01:49:30,749 - INFO - len of image_to_class_map_i: 2042
2024-05-12 01:50:30,734 - INFO - Epoch 5/200, Total Loss: 7.4823, Cls Loss: 5.6512, Cluster Loss: 5.4916, New Loss: 0.0000, Clip tag Loss: 1.9588
2024-05-12 01:50:30,735 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-12 01:50:30,736 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:50:52,816 - INFO - Text classifier Epoch 4 Train Accuracies: All 0.3812 | Old 0.5320 | New 0.3056
2024-05-12 01:50:52,817 - INFO - Image classifier Epoch 4 Train Accuracies: All 0.3320 | Old 0.5667 | New 0.2144
2024-05-12 01:51:14,851 - INFO - Weighted Accuracies: All 0.3732 | Old 0.5760 | New 0.2715
2024-05-12 01:51:36,948 - INFO - len of image_to_class_map: 1856
2024-05-12 01:51:36,949 - INFO - len of image_to_class_map_i: 2148
2024-05-12 01:52:36,122 - INFO - Epoch 6/200, Total Loss: 6.9942, Cls Loss: 5.1919, Cluster Loss: 5.0090, New Loss: 0.0000, Clip tag Loss: 1.9486
2024-05-12 01:52:36,123 - INFO -    Param Group: classifier_head, Learning Rate: 0.0998
2024-05-12 01:52:36,124 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:52:58,283 - INFO - Text classifier Epoch 5 Train Accuracies: All 0.3870 | Old 0.5933 | New 0.2836
2024-05-12 01:52:58,284 - INFO - Image classifier Epoch 5 Train Accuracies: All 0.3623 | Old 0.5940 | New 0.2462
2024-05-12 01:53:20,371 - INFO - Weighted Accuracies: All 0.4001 | Old 0.6607 | New 0.2695
2024-05-12 01:53:42,473 - INFO - len of image_to_class_map: 1905
2024-05-12 01:53:42,474 - INFO - len of image_to_class_map_i: 2200
2024-05-12 01:54:42,720 - INFO - Epoch 7/200, Total Loss: 6.5930, Cls Loss: 4.8008, Cluster Loss: 4.6413, New Loss: 0.0000, Clip tag Loss: 1.9198
2024-05-12 01:54:42,720 - INFO -    Param Group: classifier_head, Learning Rate: 0.0997
2024-05-12 01:54:42,721 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:55:23,404 - INFO - Text classifier Epoch 6 Train Accuracies: All 0.4063 | Old 0.6000 | New 0.3093
2024-05-12 01:55:23,405 - INFO - Image classifier Epoch 6 Train Accuracies: All 0.3814 | Old 0.6073 | New 0.2682
2024-05-12 01:56:04,187 - INFO - Weighted Accuracies: All 0.4137 | Old 0.6967 | New 0.2719
2024-05-12 01:56:47,772 - INFO - len of image_to_class_map: 1923
2024-05-12 01:56:47,773 - INFO - len of image_to_class_map_i: 2248
2024-05-12 01:58:48,917 - INFO - Epoch 8/200, Total Loss: 6.3699, Cls Loss: 4.5353, Cluster Loss: 4.4828, New Loss: 0.0000, Clip tag Loss: 1.8767
2024-05-12 01:58:48,918 - INFO -    Param Group: classifier_head, Learning Rate: 0.0996
2024-05-12 01:58:48,918 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 01:59:31,088 - INFO - Text classifier Epoch 7 Train Accuracies: All 0.4161 | Old 0.5900 | New 0.3290
2024-05-12 01:59:31,089 - INFO - Image classifier Epoch 7 Train Accuracies: All 0.3879 | Old 0.6053 | New 0.2789
2024-05-12 02:00:13,152 - INFO - Weighted Accuracies: All 0.4114 | Old 0.6887 | New 0.2725
2024-05-12 02:00:56,945 - INFO - len of image_to_class_map: 1970
2024-05-12 02:00:56,945 - INFO - len of image_to_class_map_i: 2285
2024-05-12 02:02:57,688 - INFO - Epoch 9/200, Total Loss: 6.1399, Cls Loss: 4.3297, Cluster Loss: 4.2546, New Loss: 0.0000, Clip tag Loss: 1.8703
2024-05-12 02:02:57,757 - INFO -    Param Group: classifier_head, Learning Rate: 0.0995
2024-05-12 02:02:57,758 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:03:46,565 - INFO - Text classifier Epoch 8 Train Accuracies: All 0.4277 | Old 0.6193 | New 0.3317
2024-05-12 02:03:46,566 - INFO - Image classifier Epoch 8 Train Accuracies: All 0.4019 | Old 0.6513 | New 0.2769
2024-05-12 02:04:31,143 - INFO - Weighted Accuracies: All 0.4286 | Old 0.7173 | New 0.2839
2024-05-12 02:05:13,954 - INFO - len of image_to_class_map: 2073
2024-05-12 02:05:13,955 - INFO - len of image_to_class_map_i: 2341
2024-05-12 02:07:15,884 - INFO - Epoch 10/200, Total Loss: 6.0100, Cls Loss: 4.2097, Cluster Loss: 4.1379, New Loss: 0.0000, Clip tag Loss: 1.8577
2024-05-12 02:07:15,885 - INFO -    Param Group: classifier_head, Learning Rate: 0.0994
2024-05-12 02:07:15,886 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:07:57,997 - INFO - Text classifier Epoch 9 Train Accuracies: All 0.4350 | Old 0.6320 | New 0.3363
2024-05-12 02:07:57,998 - INFO - Image classifier Epoch 9 Train Accuracies: All 0.4239 | Old 0.6847 | New 0.2933
2024-05-12 02:08:39,992 - INFO - Weighted Accuracies: All 0.4241 | Old 0.7227 | New 0.2745
2024-05-12 02:09:23,061 - INFO - len of image_to_class_map: 2086
2024-05-12 02:09:23,062 - INFO - len of image_to_class_map_i: 2378
2024-05-12 02:11:24,573 - INFO - Epoch 11/200, Total Loss: 5.8103, Cls Loss: 3.9381, Cluster Loss: 3.9857, New Loss: 0.0000, Clip tag Loss: 1.8341
2024-05-12 02:11:24,575 - INFO -    Param Group: classifier_head, Learning Rate: 0.0993
2024-05-12 02:11:24,575 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:12:07,062 - INFO - Text classifier Epoch 10 Train Accuracies: All 0.4390 | Old 0.6473 | New 0.3347
2024-05-12 02:12:07,063 - INFO - Image classifier Epoch 10 Train Accuracies: All 0.4361 | Old 0.7073 | New 0.3003
2024-05-12 02:12:49,595 - INFO - Weighted Accuracies: All 0.4317 | Old 0.7080 | New 0.2933
2024-05-12 02:13:33,320 - INFO - len of image_to_class_map: 2146
2024-05-12 02:13:33,321 - INFO - len of image_to_class_map_i: 2431
2024-05-12 02:15:34,988 - INFO - Epoch 12/200, Total Loss: 8.8880, Cls Loss: 3.5438, Cluster Loss: 4.0138, New Loss: 3.1169, Clip tag Loss: 1.8513
2024-05-12 02:15:34,989 - INFO -    Param Group: classifier_head, Learning Rate: 0.0991
2024-05-12 02:15:34,990 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:16:17,640 - INFO - Text classifier Epoch 11 Train Accuracies: All 0.4613 | Old 0.6453 | New 0.3691
2024-05-12 02:16:17,641 - INFO - Image classifier Epoch 11 Train Accuracies: All 0.4348 | Old 0.6887 | New 0.3076
2024-05-12 02:17:00,302 - INFO - Weighted Accuracies: All 0.4820 | Old 0.7493 | New 0.3480
2024-05-12 02:17:44,106 - INFO - len of image_to_class_map: 2165
2024-05-12 02:17:44,107 - INFO - len of image_to_class_map_i: 2344
2024-05-12 02:19:40,956 - INFO - Epoch 13/200, Total Loss: 7.8435, Cls Loss: 3.2007, Cluster Loss: 3.8757, New Loss: 2.2410, Clip tag Loss: 1.8618
2024-05-12 02:19:40,966 - INFO -    Param Group: classifier_head, Learning Rate: 0.0990
2024-05-12 02:19:40,967 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:20:21,344 - INFO - Text classifier Epoch 12 Train Accuracies: All 0.4713 | Old 0.6520 | New 0.3808
2024-05-12 02:20:21,345 - INFO - Image classifier Epoch 12 Train Accuracies: All 0.5131 | Old 0.7227 | New 0.4081
2024-05-12 02:21:01,708 - INFO - Weighted Accuracies: All 0.5394 | Old 0.7573 | New 0.4302
2024-05-12 02:21:42,378 - INFO - len of image_to_class_map: 2185
2024-05-12 02:21:42,378 - INFO - len of image_to_class_map_i: 2453
2024-05-12 02:23:44,654 - INFO - Epoch 14/200, Total Loss: 7.3640, Cls Loss: 3.0174, Cluster Loss: 3.7318, New Loss: 1.9166, Clip tag Loss: 1.8585
2024-05-12 02:23:44,656 - INFO -    Param Group: classifier_head, Learning Rate: 0.0988
2024-05-12 02:23:44,656 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:24:25,605 - INFO - Text classifier Epoch 13 Train Accuracies: All 0.4691 | Old 0.6540 | New 0.3764
2024-05-12 02:24:25,606 - INFO - Image classifier Epoch 13 Train Accuracies: All 0.5314 | Old 0.7360 | New 0.4289
2024-05-12 02:25:05,737 - INFO - Weighted Accuracies: All 0.5656 | Old 0.7673 | New 0.4646
2024-05-12 02:25:46,331 - INFO - len of image_to_class_map: 2225
2024-05-12 02:25:46,332 - INFO - len of image_to_class_map_i: 2490
2024-05-12 02:27:49,325 - INFO - Epoch 15/200, Total Loss: 6.9949, Cls Loss: 2.9917, Cluster Loss: 3.6307, New Loss: 1.6843, Clip tag Loss: 1.8077
2024-05-12 02:27:49,326 - INFO -    Param Group: classifier_head, Learning Rate: 0.0986
2024-05-12 02:27:49,326 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:28:31,337 - INFO - Text classifier Epoch 14 Train Accuracies: All 0.4813 | Old 0.6500 | New 0.3968
2024-05-12 02:28:31,337 - INFO - Image classifier Epoch 14 Train Accuracies: All 0.5434 | Old 0.7360 | New 0.4469
2024-05-12 02:29:11,595 - INFO - Weighted Accuracies: All 0.5650 | Old 0.7593 | New 0.4676
2024-05-12 02:29:52,311 - INFO - len of image_to_class_map: 2265
2024-05-12 02:29:52,312 - INFO - len of image_to_class_map_i: 2497
2024-05-12 02:31:54,885 - INFO - Epoch 16/200, Total Loss: 6.7581, Cls Loss: 2.9014, Cluster Loss: 3.5998, New Loss: 1.4694, Clip tag Loss: 1.8285
2024-05-12 02:31:54,887 - INFO -    Param Group: classifier_head, Learning Rate: 0.0984
2024-05-12 02:31:54,887 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:32:35,352 - INFO - Text classifier Epoch 15 Train Accuracies: All 0.4764 | Old 0.6560 | New 0.3864
2024-05-12 02:32:35,353 - INFO - Image classifier Epoch 15 Train Accuracies: All 0.5628 | Old 0.7373 | New 0.4753
2024-05-12 02:33:16,655 - INFO - Weighted Accuracies: All 0.5834 | Old 0.7620 | New 0.4940
2024-05-12 02:34:05,084 - INFO - len of image_to_class_map: 2284
2024-05-12 02:34:05,085 - INFO - len of image_to_class_map_i: 2498
2024-05-12 02:36:08,185 - INFO - Epoch 17/200, Total Loss: 8.8140, Cls Loss: 2.5541, Cluster Loss: 3.5853, New Loss: 3.5932, Clip tag Loss: 1.8417
2024-05-12 02:36:08,186 - INFO -    Param Group: classifier_head, Learning Rate: 0.0982
2024-05-12 02:36:08,187 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:36:50,531 - INFO - Text classifier Epoch 16 Train Accuracies: All 0.5216 | Old 0.6613 | New 0.4516
2024-05-12 02:36:50,532 - INFO - Image classifier Epoch 16 Train Accuracies: All 0.5670 | Old 0.7620 | New 0.4693
2024-05-12 02:37:32,840 - INFO - Weighted Accuracies: All 0.5970 | Old 0.7720 | New 0.5094
2024-05-12 02:38:16,259 - INFO - len of image_to_class_map: 2306
2024-05-12 02:38:16,260 - INFO - len of image_to_class_map_i: 2513
2024-05-12 02:40:18,379 - INFO - Epoch 18/200, Total Loss: 8.1817, Cls Loss: 2.2955, Cluster Loss: 3.5098, New Loss: 3.0647, Clip tag Loss: 1.8500
2024-05-12 02:40:18,380 - INFO -    Param Group: classifier_head, Learning Rate: 0.0980
2024-05-12 02:40:18,381 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:41:01,176 - INFO - Text classifier Epoch 17 Train Accuracies: All 0.5452 | Old 0.6847 | New 0.4753
2024-05-12 02:41:01,177 - INFO - Image classifier Epoch 17 Train Accuracies: All 0.5946 | Old 0.7520 | New 0.5157
2024-05-12 02:41:44,709 - INFO - Weighted Accuracies: All 0.6188 | Old 0.7713 | New 0.5424
2024-05-12 02:42:27,700 - INFO - len of image_to_class_map: 2377
2024-05-12 02:42:27,701 - INFO - len of image_to_class_map_i: 2509
2024-05-12 02:44:29,656 - INFO - Epoch 19/200, Total Loss: 7.7262, Cls Loss: 2.1232, Cluster Loss: 3.4398, New Loss: 2.7300, Clip tag Loss: 1.8198
2024-05-12 02:44:29,658 - INFO -    Param Group: classifier_head, Learning Rate: 0.0978
2024-05-12 02:44:29,658 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:45:12,772 - INFO - Text classifier Epoch 18 Train Accuracies: All 0.5639 | Old 0.6927 | New 0.4993
2024-05-12 02:45:12,773 - INFO - Image classifier Epoch 18 Train Accuracies: All 0.6026 | Old 0.7620 | New 0.5227
2024-05-12 02:45:56,954 - INFO - Weighted Accuracies: All 0.6233 | Old 0.7693 | New 0.5501
2024-05-12 02:46:40,836 - INFO - len of image_to_class_map: 2427
2024-05-12 02:46:40,837 - INFO - len of image_to_class_map_i: 2534
2024-05-12 02:48:37,809 - INFO - Epoch 20/200, Total Loss: 7.4444, Cls Loss: 2.0330, Cluster Loss: 3.4180, New Loss: 2.4766, Clip tag Loss: 1.8268
2024-05-12 02:48:37,815 - INFO -    Param Group: classifier_head, Learning Rate: 0.0976
2024-05-12 02:48:37,816 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:49:19,324 - INFO - Text classifier Epoch 19 Train Accuracies: All 0.5899 | Old 0.7053 | New 0.5321
2024-05-12 02:49:19,325 - INFO - Image classifier Epoch 19 Train Accuracies: All 0.6202 | Old 0.7673 | New 0.5464
2024-05-12 02:50:01,019 - INFO - Weighted Accuracies: All 0.6331 | Old 0.7620 | New 0.5685
2024-05-12 02:50:41,143 - INFO - len of image_to_class_map: 2471
2024-05-12 02:50:41,144 - INFO - len of image_to_class_map_i: 2529
2024-05-12 02:52:44,672 - INFO - Epoch 21/200, Total Loss: 7.3433, Cls Loss: 1.9837, Cluster Loss: 3.4325, New Loss: 2.3801, Clip tag Loss: 1.8204
2024-05-12 02:52:44,672 - INFO -    Param Group: classifier_head, Learning Rate: 0.0973
2024-05-12 02:52:44,673 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:53:25,356 - INFO - Text classifier Epoch 20 Train Accuracies: All 0.5912 | Old 0.7120 | New 0.5307
2024-05-12 02:53:25,357 - INFO - Image classifier Epoch 20 Train Accuracies: All 0.6313 | Old 0.7793 | New 0.5571
2024-05-12 02:54:06,451 - INFO - Weighted Accuracies: All 0.6397 | Old 0.7647 | New 0.5772
2024-05-12 02:54:47,551 - INFO - len of image_to_class_map: 2456
2024-05-12 02:54:47,552 - INFO - len of image_to_class_map_i: 2533
2024-05-12 02:56:50,185 - INFO - Epoch 22/200, Total Loss: 6.9365, Cls Loss: 1.9072, Cluster Loss: 3.4111, New Loss: 2.0214, Clip tag Loss: 1.8048
2024-05-12 02:56:50,186 - INFO -    Param Group: classifier_head, Learning Rate: 0.0970
2024-05-12 02:56:50,187 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 02:57:30,525 - INFO - Text classifier Epoch 21 Train Accuracies: All 0.6086 | Old 0.6933 | New 0.5661
2024-05-12 02:57:30,526 - INFO - Image classifier Epoch 21 Train Accuracies: All 0.6413 | Old 0.7713 | New 0.5762
2024-05-12 02:58:10,773 - INFO - Weighted Accuracies: All 0.6553 | Old 0.7700 | New 0.5979
2024-05-12 02:58:51,131 - INFO - len of image_to_class_map: 2503
2024-05-12 02:58:51,132 - INFO - len of image_to_class_map_i: 2548
2024-05-12 03:00:54,636 - INFO - Epoch 23/200, Total Loss: 6.8258, Cls Loss: 1.9353, Cluster Loss: 3.3778, New Loss: 1.9740, Clip tag Loss: 1.7625
2024-05-12 03:00:54,638 - INFO -    Param Group: classifier_head, Learning Rate: 0.0968
2024-05-12 03:00:54,638 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 03:01:35,457 - INFO - Text classifier Epoch 22 Train Accuracies: All 0.6335 | Old 0.7160 | New 0.5922
2024-05-12 03:01:35,458 - INFO - Image classifier Epoch 22 Train Accuracies: All 0.6460 | Old 0.7800 | New 0.5788
2024-05-12 03:02:15,715 - INFO - Weighted Accuracies: All 0.6642 | Old 0.7773 | New 0.6075
2024-05-12 03:02:56,460 - INFO - len of image_to_class_map: 2519
2024-05-12 03:02:56,534 - INFO - len of image_to_class_map_i: 2541
2024-05-12 03:05:01,059 - INFO - Epoch 24/200, Total Loss: 6.6469, Cls Loss: 1.9125, Cluster Loss: 3.3981, New Loss: 1.7924, Clip tag Loss: 1.7536
2024-05-12 03:05:01,060 - INFO -    Param Group: classifier_head, Learning Rate: 0.0965
2024-05-12 03:05:01,061 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 03:14:47,649 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 03:14:47,651 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cuda
2024-05-12 03:14:47,712 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 03:14:51,445 - INFO - Building custom CLIP
2024-05-12 03:14:59,886 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 03:14:59,893 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 03:14:59,896 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 03:15:06,087 - INFO - len of train dataset: 5994
2024-05-12 03:15:06,087 - INFO - len of test dataset: 4494
2024-05-12 03:15:06,088 - INFO - Pseudo Nums: 13
2024-05-12 03:15:54,861 - INFO - len of image_to_class_map: 1415
2024-05-12 03:15:54,862 - INFO - len of image_to_class_map_i: 1677
2024-05-12 03:16:36,632 - INFO - Before Train Accuracies: All 0.0883 | Old 0.0607 | New 0.1022
2024-05-12 03:16:36,633 - INFO - Before Train Accuracies: All 0.0641 | Old 0.0187 | New 0.0868
2024-05-12 03:18:37,910 - INFO - Epoch 1/200, Total Loss: 12.3238, Cls Loss: 10.1177, Cluster Loss: 10.2260, New Loss: 0.0000, Clip tag Loss: 2.1195
2024-05-12 03:18:37,928 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 03:18:37,928 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 03:19:21,792 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.2608 | Old 0.2700 | New 0.2562
2024-05-12 03:19:21,792 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.1647 | Old 0.1493 | New 0.1723
2024-05-12 03:20:00,906 - INFO - Weighted Accuracies: All 0.1934 | Old 0.2067 | New 0.1867
2024-05-12 03:20:40,091 - INFO - len of image_to_class_map: 1947
2024-05-12 03:20:40,091 - INFO - len of image_to_class_map_i: 2185
2024-05-12 03:22:41,203 - INFO - Epoch 2/200, Total Loss: 11.4569, Cls Loss: 8.9212, Cluster Loss: 9.5241, New Loss: 0.0000, Clip tag Loss: 2.0534
2024-05-12 03:22:41,204 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 03:22:41,205 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 03:23:21,388 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.2822 | Old 0.2720 | New 0.2872
2024-05-12 03:23:21,389 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.1938 | Old 0.2220 | New 0.1797
2024-05-12 03:24:00,587 - INFO - Weighted Accuracies: All 0.2303 | Old 0.2693 | New 0.2108
2024-05-12 03:24:41,882 - INFO - len of image_to_class_map: 1743
2024-05-12 03:24:41,883 - INFO - len of image_to_class_map_i: 2034
2024-05-12 03:26:40,738 - INFO - Epoch 3/200, Total Loss: 9.7490, Cls Loss: 7.5298, Cluster Loss: 7.7767, New Loss: 0.0000, Clip tag Loss: 2.0217
2024-05-12 03:26:40,739 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-12 03:26:40,740 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 03:27:20,927 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.3022 | Old 0.3907 | New 0.2578
2024-05-12 03:27:20,928 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.2519 | Old 0.3740 | New 0.1907
2024-05-12 04:52:56,409 - INFO - Training cub_test_baseparam with the following settings:
2024-05-12 04:52:56,415 - INFO - Command-line arguments: output_dir=./rebuttal/train_classnums
 experiment_name=cub_test_baseparam
 seed_num=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 image_size=224
 crop_pct=0.875
 interpolation=3
 transform=imagenet
 alpha_sr=0
 alpha_ri=0.05
 alpha_rs=0.05
 alpha_rd=0.05
 pseudo_ratio=0.6
 lambda_loss=0.2
 coteaching_epoch_t=10
 coteaching_epoch_i=15
 max_kmeans_iter=10
 k_means_init=20
 interrupted_path=
 train_classes=range(0, 100)
 unlabeled_classes=range(100, 200)
 num_labeled_classes=100
 num_unlabeled_classes=100
 num_classes=200
 log_path=./rebuttal/train_classnums/cub_test_baseparam/logs/log.txt
 model_path=./rebuttal/train_classnums/cub_test_baseparam/models/model.pth
 device=cuda
2024-05-12 04:52:56,743 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-05-12 04:53:22,422 - INFO - Building custom CLIP
2024-05-12 04:53:27,889 - INFO - Turning off gradients in both the image and the text encoder
2024-05-12 04:53:27,892 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 04:53:27,895 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-05-12 04:53:34,857 - INFO - len of train dataset: 5994
2024-05-12 04:53:34,858 - INFO - len of test dataset: 4494
2024-05-12 04:53:34,858 - INFO - Pseudo Nums: 13
2024-05-12 04:54:06,794 - INFO - len of image_to_class_map: 1415
2024-05-12 04:54:06,795 - INFO - len of image_to_class_map_i: 1677
2024-05-12 04:54:29,539 - INFO - Before Train Accuracies: All 0.0883 | Old 0.0607 | New 0.1022
2024-05-12 04:54:29,540 - INFO - Before Train Accuracies: All 0.0641 | Old 0.0187 | New 0.0868
2024-05-12 04:55:32,484 - INFO - Epoch 1/200, Total Loss: 12.3238, Cls Loss: 10.1177, Cluster Loss: 10.2260, New Loss: 0.0000, Clip tag Loss: 2.1195
2024-05-12 04:55:32,485 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 04:55:32,485 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 04:56:15,257 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.2608 | Old 0.2700 | New 0.2562
2024-05-12 04:56:15,257 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.1647 | Old 0.1493 | New 0.1723
2024-05-12 04:56:57,734 - INFO - Weighted Accuracies: All 0.1934 | Old 0.2067 | New 0.1867
2024-05-12 04:57:41,446 - INFO - len of image_to_class_map: 1947
2024-05-12 04:57:41,447 - INFO - len of image_to_class_map_i: 2185
2024-05-12 04:59:43,488 - INFO - Epoch 2/200, Total Loss: 11.4569, Cls Loss: 8.9212, Cluster Loss: 9.5241, New Loss: 0.0000, Clip tag Loss: 2.0534
2024-05-12 04:59:43,489 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-05-12 04:59:43,489 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-05-12 05:00:28,288 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.2822 | Old 0.2720 | New 0.2872
2024-05-12 05:00:28,288 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.1938 | Old 0.2220 | New 0.1797
2024-05-12 05:01:11,209 - INFO - Weighted Accuracies: All 0.2303 | Old 0.2693 | New 0.2108
2024-05-12 05:01:56,864 - INFO - len of image_to_class_map: 1743
2024-05-12 05:01:56,865 - INFO - len of image_to_class_map_i: 2034
2024-05-12 05:03:57,337 - INFO - Epoch 3/200, Total Loss: 9.7490, Cls Loss: 7.5298, Cluster Loss: 7.7767, New Loss: 0.0000, Clip tag Loss: 2.0217
2024-05-12 05:03:57,351 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-05-12 05:03:57,352 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
