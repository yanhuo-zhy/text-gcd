2023-11-10 08:26:08.393 | INFO     | __main__:<module>:244 - Using evaluation function v2 to print results
2023-11-10 08:26:12.151 | INFO     | __main__:<module>:300 - model build
2023-11-10 08:26:27.111 | INFO     | __main__:train:108 - Epoch: [0][0/63]	 loss 9.40562	 cls_loss: 5.4165 cluster_loss: 5.2425 sup_con_loss: 2.0153 contrastive_loss: 5.2260 
2023-11-10 08:26:45.910 | INFO     | __main__:train:108 - Epoch: [0][10/63]	 loss 8.95216	 cls_loss: 4.2396 cluster_loss: 4.8244 sup_con_loss: 2.9992 contrastive_loss: 5.0503 
2023-11-10 08:27:04.782 | INFO     | __main__:train:108 - Epoch: [0][20/63]	 loss 8.08869	 cls_loss: 3.2686 cluster_loss: 4.2671 sup_con_loss: 2.9691 contrastive_loss: 4.8183 
2023-11-10 08:27:22.955 | INFO     | __main__:train:108 - Epoch: [0][30/63]	 loss 7.84601	 cls_loss: 3.2570 cluster_loss: 4.0861 sup_con_loss: 2.7199 contrastive_loss: 4.7664 
2023-11-10 08:27:41.185 | INFO     | __main__:train:108 - Epoch: [0][40/63]	 loss 7.23548	 cls_loss: 2.7366 cluster_loss: 3.8064 sup_con_loss: 2.0744 contrastive_loss: 4.7346 
2023-11-10 08:27:59.449 | INFO     | __main__:train:108 - Epoch: [0][50/63]	 loss 7.20637	 cls_loss: 2.6793 cluster_loss: 3.7295 sup_con_loss: 2.1692 contrastive_loss: 4.7465 
2023-11-10 08:28:17.488 | INFO     | __main__:train:108 - Epoch: [0][60/63]	 loss 7.17925	 cls_loss: 2.5901 cluster_loss: 3.6789 sup_con_loss: 2.2875 contrastive_loss: 4.7397 
2023-11-10 08:28:21.147 | INFO     | __main__:train:111 - Train Epoch: 0 Avg Loss: 7.8946 
2023-11-10 08:28:21.147 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:29:09.899 | INFO     | __main__:train:119 - Train Accuracies: All 0.2087 | Old 0.1925 | New 0.2168
2023-11-10 08:29:19.566 | INFO     | __main__:train:108 - Epoch: [1][0/63]	 loss 6.89573	 cls_loss: 2.3186 cluster_loss: 3.5776 sup_con_loss: 1.9550 contrastive_loss: 4.7300 
2023-11-10 08:29:38.009 | INFO     | __main__:train:108 - Epoch: [1][10/63]	 loss 7.00302	 cls_loss: 2.4305 cluster_loss: 3.5649 sup_con_loss: 2.1231 contrastive_loss: 4.7570 
2023-11-10 08:29:56.285 | INFO     | __main__:train:108 - Epoch: [1][20/63]	 loss 6.62796	 cls_loss: 2.1605 cluster_loss: 3.3578 sup_con_loss: 1.7593 contrastive_loss: 4.7284 
2023-11-10 08:30:14.595 | INFO     | __main__:train:108 - Epoch: [1][30/63]	 loss 6.52974	 cls_loss: 2.0920 cluster_loss: 3.3357 sup_con_loss: 1.6004 contrastive_loss: 4.7219 
2023-11-10 08:30:32.891 | INFO     | __main__:train:108 - Epoch: [1][40/63]	 loss 6.24532	 cls_loss: 1.8027 cluster_loss: 3.1008 sup_con_loss: 1.5609 contrastive_loss: 4.6962 
2023-11-10 08:30:51.178 | INFO     | __main__:train:108 - Epoch: [1][50/63]	 loss 6.17479	 cls_loss: 1.7713 cluster_loss: 3.1037 sup_con_loss: 1.4031 contrastive_loss: 4.6866 
2023-11-10 08:31:09.349 | INFO     | __main__:train:108 - Epoch: [1][60/63]	 loss 6.35377	 cls_loss: 1.7778 cluster_loss: 3.1936 sup_con_loss: 1.6682 contrastive_loss: 4.7260 
2023-11-10 08:31:13.031 | INFO     | __main__:train:111 - Train Epoch: 1 Avg Loss: 6.5614 
2023-11-10 08:31:13.031 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:32:01.643 | INFO     | __main__:train:119 - Train Accuracies: All 0.2648 | Old 0.3845 | New 0.2055
2023-11-10 08:32:09.997 | INFO     | __main__:train:108 - Epoch: [2][0/63]	 loss 6.36096	 cls_loss: 1.7130 cluster_loss: 3.1252 sup_con_loss: 1.9195 contrastive_loss: 4.7050 
2023-11-10 08:32:28.524 | INFO     | __main__:train:108 - Epoch: [2][10/63]	 loss 6.12752	 cls_loss: 1.6769 cluster_loss: 2.9990 sup_con_loss: 1.5362 contrastive_loss: 4.6978 
2023-11-10 08:32:46.862 | INFO     | __main__:train:108 - Epoch: [2][20/63]	 loss 6.07605	 cls_loss: 1.7121 cluster_loss: 2.9254 sup_con_loss: 1.5131 contrastive_loss: 4.6857 
2023-11-10 08:33:05.187 | INFO     | __main__:train:108 - Epoch: [2][30/63]	 loss 6.11549	 cls_loss: 1.7578 cluster_loss: 2.9381 sup_con_loss: 1.5484 contrastive_loss: 4.6901 
2023-11-10 08:33:23.517 | INFO     | __main__:train:108 - Epoch: [2][40/63]	 loss 5.98258	 cls_loss: 1.6485 cluster_loss: 2.8567 sup_con_loss: 1.4341 contrastive_loss: 4.6874 
2023-11-10 08:33:41.866 | INFO     | __main__:train:108 - Epoch: [2][50/63]	 loss 5.92675	 cls_loss: 1.5947 cluster_loss: 2.8696 sup_con_loss: 1.2785 contrastive_loss: 4.7014 
2023-11-10 08:34:00.056 | INFO     | __main__:train:108 - Epoch: [2][60/63]	 loss 6.00759	 cls_loss: 1.6041 cluster_loss: 2.8312 sup_con_loss: 1.6028 contrastive_loss: 4.6845 
2023-11-10 08:34:03.708 | INFO     | __main__:train:111 - Train Epoch: 2 Avg Loss: 6.0583 
2023-11-10 08:34:03.708 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:34:53.136 | INFO     | __main__:train:119 - Train Accuracies: All 0.3287 | Old 0.4437 | New 0.2717
2023-11-10 08:35:03.551 | INFO     | __main__:train:108 - Epoch: [3][0/63]	 loss 6.03737	 cls_loss: 1.4913 cluster_loss: 2.8403 sup_con_loss: 1.7441 contrastive_loss: 4.7058 
2023-11-10 08:35:22.246 | INFO     | __main__:train:108 - Epoch: [3][10/63]	 loss 5.78262	 cls_loss: 1.4238 cluster_loss: 2.7452 sup_con_loss: 1.2891 contrastive_loss: 4.6904 
2023-11-10 08:35:40.559 | INFO     | __main__:train:108 - Epoch: [3][20/63]	 loss 5.73824	 cls_loss: 1.4541 cluster_loss: 2.7831 sup_con_loss: 1.0637 contrastive_loss: 4.6892 
2023-11-10 08:35:58.859 | INFO     | __main__:train:108 - Epoch: [3][30/63]	 loss 5.84933	 cls_loss: 1.4297 cluster_loss: 2.7645 sup_con_loss: 1.4305 contrastive_loss: 4.6943 
2023-11-10 08:36:17.172 | INFO     | __main__:train:108 - Epoch: [3][40/63]	 loss 5.65724	 cls_loss: 1.2609 cluster_loss: 2.6655 sup_con_loss: 1.2314 contrastive_loss: 4.6960 
2023-11-10 08:36:35.459 | INFO     | __main__:train:108 - Epoch: [3][50/63]	 loss 5.79481	 cls_loss: 1.4767 cluster_loss: 2.6541 sup_con_loss: 1.4542 contrastive_loss: 4.6828 
2023-11-10 08:36:53.583 | INFO     | __main__:train:108 - Epoch: [3][60/63]	 loss 5.70905	 cls_loss: 1.3293 cluster_loss: 2.6077 sup_con_loss: 1.4421 contrastive_loss: 4.6832 
2023-11-10 08:36:57.309 | INFO     | __main__:train:111 - Train Epoch: 3 Avg Loss: 5.7849 
2023-11-10 08:36:57.309 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:37:46.853 | INFO     | __main__:train:119 - Train Accuracies: All 0.3434 | Old 0.4970 | New 0.2674
2023-11-10 08:37:57.213 | INFO     | __main__:train:108 - Epoch: [4][0/63]	 loss 5.66463	 cls_loss: 1.2756 cluster_loss: 2.5737 sup_con_loss: 1.4330 contrastive_loss: 4.6827 
2023-11-10 08:38:15.746 | INFO     | __main__:train:108 - Epoch: [4][10/63]	 loss 5.65852	 cls_loss: 1.2125 cluster_loss: 2.6789 sup_con_loss: 1.2647 contrastive_loss: 4.6926 
2023-11-10 08:38:34.074 | INFO     | __main__:train:108 - Epoch: [4][20/63]	 loss 5.50597	 cls_loss: 1.2172 cluster_loss: 2.5553 sup_con_loss: 1.0899 contrastive_loss: 4.6731 
2023-11-10 08:38:52.390 | INFO     | __main__:train:108 - Epoch: [4][30/63]	 loss 5.57603	 cls_loss: 1.2410 cluster_loss: 2.5315 sup_con_loss: 1.3045 contrastive_loss: 4.6763 
2023-11-10 08:39:10.747 | INFO     | __main__:train:108 - Epoch: [4][40/63]	 loss 5.64257	 cls_loss: 1.2451 cluster_loss: 2.6270 sup_con_loss: 1.3064 contrastive_loss: 4.6799 
2023-11-10 08:39:29.108 | INFO     | __main__:train:108 - Epoch: [4][50/63]	 loss 5.51398	 cls_loss: 1.1646 cluster_loss: 2.5560 sup_con_loss: 1.1279 contrastive_loss: 4.6926 
2023-11-10 08:39:47.298 | INFO     | __main__:train:108 - Epoch: [4][60/63]	 loss 5.42354	 cls_loss: 1.1270 cluster_loss: 2.4971 sup_con_loss: 1.0507 contrastive_loss: 4.6741 
2023-11-10 08:39:50.998 | INFO     | __main__:train:111 - Train Epoch: 4 Avg Loss: 5.5766 
2023-11-10 08:39:50.998 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:40:40.539 | INFO     | __main__:train:119 - Train Accuracies: All 0.3714 | Old 0.5257 | New 0.2950
2023-11-10 08:40:50.271 | INFO     | __main__:train:108 - Epoch: [5][0/63]	 loss 5.51956	 cls_loss: 1.1953 cluster_loss: 2.5185 sup_con_loss: 1.1960 contrastive_loss: 4.6855 
2023-11-10 08:41:09.057 | INFO     | __main__:train:108 - Epoch: [5][10/63]	 loss 5.62474	 cls_loss: 1.3650 cluster_loss: 2.5801 sup_con_loss: 1.1749 contrastive_loss: 4.7057 
2023-11-10 08:41:27.469 | INFO     | __main__:train:108 - Epoch: [5][20/63]	 loss 5.59965	 cls_loss: 1.1688 cluster_loss: 2.5371 sup_con_loss: 1.4138 contrastive_loss: 4.6871 
2023-11-10 08:41:45.893 | INFO     | __main__:train:108 - Epoch: [5][30/63]	 loss 5.45514	 cls_loss: 1.0446 cluster_loss: 2.5328 sup_con_loss: 1.1374 contrastive_loss: 4.6849 
2023-11-10 08:42:04.433 | INFO     | __main__:train:108 - Epoch: [5][40/63]	 loss 5.28496	 cls_loss: 0.9928 cluster_loss: 2.3883 sup_con_loss: 0.9994 contrastive_loss: 4.6697 
2023-11-10 08:42:22.904 | INFO     | __main__:train:108 - Epoch: [5][50/63]	 loss 5.42905	 cls_loss: 1.0763 cluster_loss: 2.5087 sup_con_loss: 1.0766 contrastive_loss: 4.6844 
2023-11-10 08:42:41.260 | INFO     | __main__:train:108 - Epoch: [5][60/63]	 loss 5.33482	 cls_loss: 1.1080 cluster_loss: 2.4373 sup_con_loss: 0.9215 contrastive_loss: 4.6772 
2023-11-10 08:42:44.964 | INFO     | __main__:train:111 - Train Epoch: 5 Avg Loss: 5.4392 
2023-11-10 08:42:44.965 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:43:34.541 | INFO     | __main__:train:119 - Train Accuracies: All 0.4078 | Old 0.6362 | New 0.2947
2023-11-10 08:43:43.527 | INFO     | __main__:train:108 - Epoch: [6][0/63]	 loss 5.38549	 cls_loss: 0.9269 cluster_loss: 2.3434 sup_con_loss: 1.4130 contrastive_loss: 4.6820 
2023-11-10 08:44:02.492 | INFO     | __main__:train:108 - Epoch: [6][10/63]	 loss 5.45637	 cls_loss: 1.1142 cluster_loss: 2.4693 sup_con_loss: 1.2182 contrastive_loss: 4.6692 
2023-11-10 08:44:20.976 | INFO     | __main__:train:108 - Epoch: [6][20/63]	 loss 5.32636	 cls_loss: 1.0237 cluster_loss: 2.4121 sup_con_loss: 1.0463 contrastive_loss: 4.6677 
2023-11-10 08:44:39.510 | INFO     | __main__:train:108 - Epoch: [6][30/63]	 loss 5.32244	 cls_loss: 0.9944 cluster_loss: 2.3639 sup_con_loss: 1.1417 contrastive_loss: 4.6742 
2023-11-10 08:44:58.049 | INFO     | __main__:train:108 - Epoch: [6][40/63]	 loss 5.41872	 cls_loss: 1.1442 cluster_loss: 2.3745 sup_con_loss: 1.2644 contrastive_loss: 4.6650 
2023-11-10 08:45:16.570 | INFO     | __main__:train:108 - Epoch: [6][50/63]	 loss 5.32684	 cls_loss: 0.9985 cluster_loss: 2.3439 sup_con_loss: 1.2023 contrastive_loss: 4.6662 
2023-11-10 08:45:34.976 | INFO     | __main__:train:108 - Epoch: [6][60/63]	 loss 5.20204	 cls_loss: 0.9164 cluster_loss: 2.3171 sup_con_loss: 0.9560 contrastive_loss: 4.6778 
2023-11-10 08:45:38.672 | INFO     | __main__:train:111 - Train Epoch: 6 Avg Loss: 5.3474 
2023-11-10 08:45:38.672 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:46:28.498 | INFO     | __main__:train:119 - Train Accuracies: All 0.4323 | Old 0.6505 | New 0.3243
2023-11-10 08:46:38.597 | INFO     | __main__:train:108 - Epoch: [7][0/63]	 loss 5.58023	 cls_loss: 1.2334 cluster_loss: 2.4669 sup_con_loss: 1.4419 contrastive_loss: 4.6775 
2023-11-10 08:46:57.316 | INFO     | __main__:train:108 - Epoch: [7][10/63]	 loss 5.31878	 cls_loss: 0.9315 cluster_loss: 2.2923 sup_con_loss: 1.3243 contrastive_loss: 4.6758 
2023-11-10 08:47:15.759 | INFO     | __main__:train:108 - Epoch: [7][20/63]	 loss 5.31513	 cls_loss: 1.0316 cluster_loss: 2.4661 sup_con_loss: 0.8596 contrastive_loss: 4.6926 
2023-11-10 08:47:34.384 | INFO     | __main__:train:108 - Epoch: [7][30/63]	 loss 5.23599	 cls_loss: 0.9118 cluster_loss: 2.2580 sup_con_loss: 1.1786 contrastive_loss: 4.6717 
2023-11-10 08:47:52.936 | INFO     | __main__:train:108 - Epoch: [7][40/63]	 loss 5.40060	 cls_loss: 1.0206 cluster_loss: 2.3320 sup_con_loss: 1.3950 contrastive_loss: 4.6759 
2023-11-10 08:48:11.502 | INFO     | __main__:train:108 - Epoch: [7][50/63]	 loss 5.14781	 cls_loss: 0.9843 cluster_loss: 2.2117 sup_con_loss: 0.9374 contrastive_loss: 4.6732 
2023-11-10 08:48:29.927 | INFO     | __main__:train:108 - Epoch: [7][60/63]	 loss 5.13399	 cls_loss: 0.9628 cluster_loss: 2.2113 sup_con_loss: 0.9366 contrastive_loss: 4.6644 
2023-11-10 08:48:33.666 | INFO     | __main__:train:111 - Train Epoch: 7 Avg Loss: 5.2438 
2023-11-10 08:48:33.667 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:49:23.335 | INFO     | __main__:train:119 - Train Accuracies: All 0.4425 | Old 0.6752 | New 0.3272
2023-11-10 08:49:31.914 | INFO     | __main__:train:108 - Epoch: [8][0/63]	 loss 5.21063	 cls_loss: 0.8871 cluster_loss: 2.2878 sup_con_loss: 1.0433 contrastive_loss: 4.6891 
2023-11-10 08:49:50.877 | INFO     | __main__:train:108 - Epoch: [8][10/63]	 loss 5.28668	 cls_loss: 0.9049 cluster_loss: 2.3044 sup_con_loss: 1.2250 contrastive_loss: 4.6821 
2023-11-10 08:50:09.397 | INFO     | __main__:train:108 - Epoch: [8][20/63]	 loss 5.27214	 cls_loss: 1.0299 cluster_loss: 2.3331 sup_con_loss: 1.0126 contrastive_loss: 4.6780 
2023-11-10 08:50:27.921 | INFO     | __main__:train:108 - Epoch: [8][30/63]	 loss 5.09759	 cls_loss: 0.9365 cluster_loss: 2.1695 sup_con_loss: 0.9154 contrastive_loss: 4.6757 
2023-11-10 08:50:46.435 | INFO     | __main__:train:108 - Epoch: [8][40/63]	 loss 5.18425	 cls_loss: 0.9513 cluster_loss: 2.1544 sup_con_loss: 1.1994 contrastive_loss: 4.6632 
2023-11-10 08:51:04.939 | INFO     | __main__:train:108 - Epoch: [8][50/63]	 loss 5.03129	 cls_loss: 0.8176 cluster_loss: 2.2208 sup_con_loss: 0.7559 contrastive_loss: 4.6724 
2023-11-10 08:51:23.333 | INFO     | __main__:train:108 - Epoch: [8][60/63]	 loss 5.16171	 cls_loss: 0.8632 cluster_loss: 2.2448 sup_con_loss: 1.0343 contrastive_loss: 4.6745 
2023-11-10 08:51:27.084 | INFO     | __main__:train:111 - Train Epoch: 8 Avg Loss: 5.1550 
2023-11-10 08:51:27.085 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:52:17.189 | INFO     | __main__:train:119 - Train Accuracies: All 0.4531 | Old 0.6663 | New 0.3475
2023-11-10 08:52:29.002 | INFO     | __main__:train:108 - Epoch: [9][0/63]	 loss 4.99062	 cls_loss: 0.8976 cluster_loss: 2.0943 sup_con_loss: 0.8221 contrastive_loss: 4.6576 
2023-11-10 08:52:47.576 | INFO     | __main__:train:108 - Epoch: [9][10/63]	 loss 5.13086	 cls_loss: 0.8661 cluster_loss: 2.1881 sup_con_loss: 1.0794 contrastive_loss: 4.6580 
2023-11-10 08:53:06.116 | INFO     | __main__:train:108 - Epoch: [9][20/63]	 loss 5.32676	 cls_loss: 0.9920 cluster_loss: 2.2766 sup_con_loss: 1.3027 contrastive_loss: 4.6828 
2023-11-10 08:53:24.573 | INFO     | __main__:train:108 - Epoch: [9][30/63]	 loss 5.05696	 cls_loss: 0.7979 cluster_loss: 2.1865 sup_con_loss: 0.9265 contrastive_loss: 4.6649 
2023-11-10 08:53:43.122 | INFO     | __main__:train:108 - Epoch: [9][40/63]	 loss 5.19028	 cls_loss: 0.8544 cluster_loss: 2.1777 sup_con_loss: 1.2950 contrastive_loss: 4.6500 
2023-11-10 08:54:01.580 | INFO     | __main__:train:108 - Epoch: [9][50/63]	 loss 4.90779	 cls_loss: 0.7799 cluster_loss: 2.0809 sup_con_loss: 0.7156 contrastive_loss: 4.6643 
2023-11-10 08:54:19.915 | INFO     | __main__:train:108 - Epoch: [9][60/63]	 loss 5.11400	 cls_loss: 0.8625 cluster_loss: 2.1979 sup_con_loss: 0.9649 contrastive_loss: 4.6858 
2023-11-10 08:54:23.650 | INFO     | __main__:train:111 - Train Epoch: 9 Avg Loss: 5.0823 
2023-11-10 08:54:23.651 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:55:13.363 | INFO     | __main__:train:119 - Train Accuracies: All 0.4738 | Old 0.7024 | New 0.3607
2023-11-10 08:55:22.802 | INFO     | __main__:train:108 - Epoch: [10][0/63]	 loss 4.92997	 cls_loss: 0.8029 cluster_loss: 2.0264 sup_con_loss: 0.8691 contrastive_loss: 4.6578 
2023-11-10 08:55:41.540 | INFO     | __main__:train:108 - Epoch: [10][10/63]	 loss 5.02197	 cls_loss: 0.7820 cluster_loss: 2.0888 sup_con_loss: 1.0285 contrastive_loss: 4.6625 
2023-11-10 08:56:00.038 | INFO     | __main__:train:108 - Epoch: [10][20/63]	 loss 4.98587	 cls_loss: 0.8120 cluster_loss: 2.0856 sup_con_loss: 0.8981 contrastive_loss: 4.6641 
2023-11-10 08:56:18.624 | INFO     | __main__:train:108 - Epoch: [10][30/63]	 loss 5.17515	 cls_loss: 0.8498 cluster_loss: 2.2158 sup_con_loss: 1.1335 contrastive_loss: 4.6781 
2023-11-10 08:56:37.118 | INFO     | __main__:train:108 - Epoch: [10][40/63]	 loss 5.10835	 cls_loss: 0.8022 cluster_loss: 2.1328 sup_con_loss: 1.1586 contrastive_loss: 4.6703 
2023-11-10 08:56:55.579 | INFO     | __main__:train:108 - Epoch: [10][50/63]	 loss 4.90653	 cls_loss: 0.7813 cluster_loss: 2.0011 sup_con_loss: 0.8559 contrastive_loss: 4.6658 
2023-11-10 08:57:14.020 | INFO     | __main__:train:108 - Epoch: [10][60/63]	 loss 4.95734	 cls_loss: 0.7970 cluster_loss: 2.0222 sup_con_loss: 0.9647 contrastive_loss: 4.6558 
2023-11-10 08:57:17.750 | INFO     | __main__:train:111 - Train Epoch: 10 Avg Loss: 5.0075 
2023-11-10 08:57:17.750 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 08:58:07.978 | INFO     | __main__:train:119 - Train Accuracies: All 0.4958 | Old 0.7211 | New 0.3842
2023-11-10 08:58:18.421 | INFO     | __main__:train:108 - Epoch: [11][0/63]	 loss 4.90310	 cls_loss: 0.6467 cluster_loss: 2.0620 sup_con_loss: 0.8751 contrastive_loss: 4.6618 
2023-11-10 08:58:37.143 | INFO     | __main__:train:108 - Epoch: [11][10/63]	 loss 5.02188	 cls_loss: 0.7997 cluster_loss: 1.9645 sup_con_loss: 1.2464 contrastive_loss: 4.6597 
2023-11-10 08:58:55.591 | INFO     | __main__:train:108 - Epoch: [11][20/63]	 loss 4.86125	 cls_loss: 0.6637 cluster_loss: 2.0679 sup_con_loss: 0.7576 contrastive_loss: 4.6456 
2023-11-10 08:59:14.131 | INFO     | __main__:train:108 - Epoch: [11][30/63]	 loss 4.82539	 cls_loss: 0.6831 cluster_loss: 1.9179 sup_con_loss: 0.9176 contrastive_loss: 4.6438 
2023-11-10 08:59:32.671 | INFO     | __main__:train:108 - Epoch: [11][40/63]	 loss 4.94488	 cls_loss: 0.7059 cluster_loss: 1.9755 sup_con_loss: 1.0992 contrastive_loss: 4.6600 
2023-11-10 08:59:51.255 | INFO     | __main__:train:108 - Epoch: [11][50/63]	 loss 5.00065	 cls_loss: 0.7690 cluster_loss: 2.0237 sup_con_loss: 1.1066 contrastive_loss: 4.6597 
2023-11-10 09:00:09.722 | INFO     | __main__:train:108 - Epoch: [11][60/63]	 loss 5.04093	 cls_loss: 0.8218 cluster_loss: 2.0693 sup_con_loss: 1.0852 contrastive_loss: 4.6591 
2023-11-10 09:00:13.451 | INFO     | __main__:train:111 - Train Epoch: 11 Avg Loss: 4.9246 
2023-11-10 09:00:13.452 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:01:03.781 | INFO     | __main__:train:119 - Train Accuracies: All 0.5026 | Old 0.7103 | New 0.3998
2023-11-10 09:01:14.285 | INFO     | __main__:train:108 - Epoch: [12][0/63]	 loss 4.77984	 cls_loss: 0.6859 cluster_loss: 1.9077 sup_con_loss: 0.7783 contrastive_loss: 4.6575 
2023-11-10 09:01:33.208 | INFO     | __main__:train:108 - Epoch: [12][10/63]	 loss 4.83357	 cls_loss: 0.6456 cluster_loss: 2.0001 sup_con_loss: 0.8055 contrastive_loss: 4.6549 
2023-11-10 09:01:51.749 | INFO     | __main__:train:108 - Epoch: [12][20/63]	 loss 4.86112	 cls_loss: 0.6655 cluster_loss: 1.9860 sup_con_loss: 0.8873 contrastive_loss: 4.6566 
2023-11-10 09:02:10.433 | INFO     | __main__:train:108 - Epoch: [12][30/63]	 loss 4.91792	 cls_loss: 0.7387 cluster_loss: 1.9526 sup_con_loss: 1.0514 contrastive_loss: 4.6495 
2023-11-10 09:02:29.035 | INFO     | __main__:train:108 - Epoch: [12][40/63]	 loss 4.94336	 cls_loss: 0.6999 cluster_loss: 1.9600 sup_con_loss: 1.1271 contrastive_loss: 4.6614 
2023-11-10 09:02:47.587 | INFO     | __main__:train:108 - Epoch: [12][50/63]	 loss 4.77609	 cls_loss: 0.6095 cluster_loss: 1.9661 sup_con_loss: 0.7172 contrastive_loss: 4.6674 
2023-11-10 09:03:06.220 | INFO     | __main__:train:108 - Epoch: [12][60/63]	 loss 4.90694	 cls_loss: 0.7582 cluster_loss: 1.9221 sup_con_loss: 1.0616 contrastive_loss: 4.6471 
2023-11-10 09:03:09.951 | INFO     | __main__:train:111 - Train Epoch: 12 Avg Loss: 4.8689 
2023-11-10 09:03:09.951 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:03:59.572 | INFO     | __main__:train:119 - Train Accuracies: All 0.5087 | Old 0.7354 | New 0.3964
2023-11-10 09:04:08.995 | INFO     | __main__:train:108 - Epoch: [13][0/63]	 loss 4.84458	 cls_loss: 0.6560 cluster_loss: 1.9340 sup_con_loss: 0.9610 contrastive_loss: 4.6485 
2023-11-10 09:04:27.825 | INFO     | __main__:train:108 - Epoch: [13][10/63]	 loss 4.88981	 cls_loss: 0.6205 cluster_loss: 1.9301 sup_con_loss: 1.1254 contrastive_loss: 4.6526 
2023-11-10 09:04:46.470 | INFO     | __main__:train:108 - Epoch: [13][20/63]	 loss 4.82504	 cls_loss: 0.6408 cluster_loss: 1.8794 sup_con_loss: 1.0137 contrastive_loss: 4.6528 
2023-11-10 09:05:05.076 | INFO     | __main__:train:108 - Epoch: [13][30/63]	 loss 4.78277	 cls_loss: 0.6685 cluster_loss: 1.8970 sup_con_loss: 0.8396 contrastive_loss: 4.6490 
2023-11-10 09:05:23.769 | INFO     | __main__:train:108 - Epoch: [13][40/63]	 loss 4.94710	 cls_loss: 0.7234 cluster_loss: 2.0654 sup_con_loss: 0.9192 contrastive_loss: 4.6611 
2023-11-10 09:05:42.380 | INFO     | __main__:train:108 - Epoch: [13][50/63]	 loss 4.82992	 cls_loss: 0.7087 cluster_loss: 1.8743 sup_con_loss: 0.9838 contrastive_loss: 4.6450 
2023-11-10 09:06:00.846 | INFO     | __main__:train:108 - Epoch: [13][60/63]	 loss 4.66235	 cls_loss: 0.5499 cluster_loss: 1.7914 sup_con_loss: 0.8290 contrastive_loss: 4.6389 
2023-11-10 09:06:04.596 | INFO     | __main__:train:111 - Train Epoch: 13 Avg Loss: 4.8297 
2023-11-10 09:06:04.596 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:06:55.304 | INFO     | __main__:train:119 - Train Accuracies: All 0.5286 | Old 0.7409 | New 0.4235
2023-11-10 09:07:05.419 | INFO     | __main__:train:108 - Epoch: [14][0/63]	 loss 4.72814	 cls_loss: 0.6372 cluster_loss: 1.8582 sup_con_loss: 0.8064 contrastive_loss: 4.6385 
2023-11-10 09:07:24.131 | INFO     | __main__:train:108 - Epoch: [14][10/63]	 loss 4.69291	 cls_loss: 0.5784 cluster_loss: 1.8532 sup_con_loss: 0.7656 contrastive_loss: 4.6430 
2023-11-10 09:07:42.703 | INFO     | __main__:train:108 - Epoch: [14][20/63]	 loss 4.75564	 cls_loss: 0.6364 cluster_loss: 1.8017 sup_con_loss: 0.9608 contrastive_loss: 4.6547 
2023-11-10 09:08:01.311 | INFO     | __main__:train:108 - Epoch: [14][30/63]	 loss 4.78131	 cls_loss: 0.7179 cluster_loss: 1.8245 sup_con_loss: 0.9286 contrastive_loss: 4.6448 
2023-11-10 09:08:19.917 | INFO     | __main__:train:108 - Epoch: [14][40/63]	 loss 4.69729	 cls_loss: 0.5234 cluster_loss: 1.8558 sup_con_loss: 0.8377 contrastive_loss: 4.6380 
2023-11-10 09:08:38.537 | INFO     | __main__:train:108 - Epoch: [14][50/63]	 loss 4.93821	 cls_loss: 0.6722 cluster_loss: 2.0376 sup_con_loss: 0.9932 contrastive_loss: 4.6629 
2023-11-10 09:08:57.256 | INFO     | __main__:train:108 - Epoch: [14][60/63]	 loss 4.75262	 cls_loss: 0.6227 cluster_loss: 1.8147 sup_con_loss: 0.9722 contrastive_loss: 4.6383 
2023-11-10 09:09:00.982 | INFO     | __main__:train:111 - Train Epoch: 14 Avg Loss: 4.7678 
2023-11-10 09:09:00.983 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:09:50.913 | INFO     | __main__:train:119 - Train Accuracies: All 0.5284 | Old 0.7315 | New 0.4279
2023-11-10 09:10:01.717 | INFO     | __main__:train:108 - Epoch: [15][0/63]	 loss 4.69360	 cls_loss: 0.5900 cluster_loss: 1.8529 sup_con_loss: 0.7303 contrastive_loss: 4.6571 
2023-11-10 09:10:20.466 | INFO     | __main__:train:108 - Epoch: [15][10/63]	 loss 4.69611	 cls_loss: 0.5913 cluster_loss: 1.8376 sup_con_loss: 0.7792 contrastive_loss: 4.6492 
2023-11-10 09:10:39.067 | INFO     | __main__:train:108 - Epoch: [15][20/63]	 loss 4.58742	 cls_loss: 0.5444 cluster_loss: 1.7321 sup_con_loss: 0.7250 contrastive_loss: 4.6420 
2023-11-10 09:10:57.718 | INFO     | __main__:train:108 - Epoch: [15][30/63]	 loss 4.76750	 cls_loss: 0.5514 cluster_loss: 1.8591 sup_con_loss: 0.9810 contrastive_loss: 4.6504 
2023-11-10 09:11:16.390 | INFO     | __main__:train:108 - Epoch: [15][40/63]	 loss 4.71976	 cls_loss: 0.6306 cluster_loss: 1.7773 sup_con_loss: 0.9430 contrastive_loss: 4.6366 
2023-11-10 09:11:34.986 | INFO     | __main__:train:108 - Epoch: [15][50/63]	 loss 4.69472	 cls_loss: 0.5578 cluster_loss: 1.8031 sup_con_loss: 0.8564 contrastive_loss: 4.6580 
2023-11-10 09:11:53.470 | INFO     | __main__:train:108 - Epoch: [15][60/63]	 loss 4.57142	 cls_loss: 0.5444 cluster_loss: 1.7552 sup_con_loss: 0.6284 contrastive_loss: 4.6462 
2023-11-10 09:11:57.227 | INFO     | __main__:train:111 - Train Epoch: 15 Avg Loss: 4.7156 
2023-11-10 09:11:57.228 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:12:47.470 | INFO     | __main__:train:119 - Train Accuracies: All 0.5414 | Old 0.7483 | New 0.4389
2023-11-10 09:12:56.686 | INFO     | __main__:train:108 - Epoch: [16][0/63]	 loss 4.62184	 cls_loss: 0.6026 cluster_loss: 1.8272 sup_con_loss: 0.5756 contrastive_loss: 4.6489 
2023-11-10 09:13:15.553 | INFO     | __main__:train:108 - Epoch: [16][10/63]	 loss 4.65700	 cls_loss: 0.5391 cluster_loss: 1.7807 sup_con_loss: 0.8311 contrastive_loss: 4.6460 
2023-11-10 09:13:34.143 | INFO     | __main__:train:108 - Epoch: [16][20/63]	 loss 4.65543	 cls_loss: 0.5835 cluster_loss: 1.7015 sup_con_loss: 0.9550 contrastive_loss: 4.6322 
2023-11-10 09:13:52.690 | INFO     | __main__:train:108 - Epoch: [16][30/63]	 loss 4.77212	 cls_loss: 0.5633 cluster_loss: 1.9074 sup_con_loss: 0.9068 contrastive_loss: 4.6427 
2023-11-10 09:14:11.304 | INFO     | __main__:train:108 - Epoch: [16][40/63]	 loss 4.60464	 cls_loss: 0.5849 cluster_loss: 1.7262 sup_con_loss: 0.7613 contrastive_loss: 4.6329 
2023-11-10 09:14:29.885 | INFO     | __main__:train:108 - Epoch: [16][50/63]	 loss 4.48315	 cls_loss: 0.5029 cluster_loss: 1.6645 sup_con_loss: 0.6108 contrastive_loss: 4.6330 
2023-11-10 09:14:48.331 | INFO     | __main__:train:108 - Epoch: [16][60/63]	 loss 4.66313	 cls_loss: 0.5494 cluster_loss: 1.7575 sup_con_loss: 0.9034 contrastive_loss: 4.6342 
2023-11-10 09:14:52.069 | INFO     | __main__:train:111 - Train Epoch: 16 Avg Loss: 4.6639 
2023-11-10 09:14:52.070 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:15:42.081 | INFO     | __main__:train:119 - Train Accuracies: All 0.5592 | Old 0.7651 | New 0.4572
2023-11-10 09:15:51.430 | INFO     | __main__:train:108 - Epoch: [17][0/63]	 loss 4.77790	 cls_loss: 0.5136 cluster_loss: 1.9154 sup_con_loss: 0.9338 contrastive_loss: 4.6558 
2023-11-10 09:16:10.261 | INFO     | __main__:train:108 - Epoch: [17][10/63]	 loss 4.74707	 cls_loss: 0.6247 cluster_loss: 1.8400 sup_con_loss: 0.8716 contrastive_loss: 4.6575 
2023-11-10 09:16:28.825 | INFO     | __main__:train:108 - Epoch: [17][20/63]	 loss 4.62885	 cls_loss: 0.5123 cluster_loss: 1.7241 sup_con_loss: 0.9066 contrastive_loss: 4.6332 
2023-11-10 09:16:47.355 | INFO     | __main__:train:108 - Epoch: [17][30/63]	 loss 4.67387	 cls_loss: 0.5093 cluster_loss: 1.7564 sup_con_loss: 0.9491 contrastive_loss: 4.6489 
2023-11-10 09:17:05.982 | INFO     | __main__:train:108 - Epoch: [17][40/63]	 loss 4.62424	 cls_loss: 0.5083 cluster_loss: 1.7544 sup_con_loss: 0.8157 contrastive_loss: 4.6469 
2023-11-10 09:17:24.594 | INFO     | __main__:train:108 - Epoch: [17][50/63]	 loss 4.65588	 cls_loss: 0.5457 cluster_loss: 1.8249 sup_con_loss: 0.7373 contrastive_loss: 4.6471 
2023-11-10 09:17:43.107 | INFO     | __main__:train:108 - Epoch: [17][60/63]	 loss 4.66641	 cls_loss: 0.5325 cluster_loss: 1.7948 sup_con_loss: 0.8572 contrastive_loss: 4.6360 
2023-11-10 09:17:46.892 | INFO     | __main__:train:111 - Train Epoch: 17 Avg Loss: 4.6270 
2023-11-10 09:17:46.892 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:18:36.617 | INFO     | __main__:train:119 - Train Accuracies: All 0.5688 | Old 0.7478 | New 0.4802
2023-11-10 09:18:46.508 | INFO     | __main__:train:108 - Epoch: [18][0/63]	 loss 4.73032	 cls_loss: 0.5375 cluster_loss: 1.7812 sup_con_loss: 1.0334 contrastive_loss: 4.6503 
2023-11-10 09:19:05.457 | INFO     | __main__:train:108 - Epoch: [18][10/63]	 loss 4.55686	 cls_loss: 0.4793 cluster_loss: 1.7385 sup_con_loss: 0.6900 contrastive_loss: 4.6424 
2023-11-10 09:19:24.076 | INFO     | __main__:train:108 - Epoch: [18][20/63]	 loss 4.58069	 cls_loss: 0.5348 cluster_loss: 1.7993 sup_con_loss: 0.5629 contrastive_loss: 4.6569 
2023-11-10 09:19:42.717 | INFO     | __main__:train:108 - Epoch: [18][30/63]	 loss 4.67608	 cls_loss: 0.5346 cluster_loss: 1.7920 sup_con_loss: 0.8645 contrastive_loss: 4.6487 
2023-11-10 09:20:01.299 | INFO     | __main__:train:108 - Epoch: [18][40/63]	 loss 4.42435	 cls_loss: 0.5207 cluster_loss: 1.6440 sup_con_loss: 0.4696 contrastive_loss: 4.6294 
2023-11-10 09:20:19.872 | INFO     | __main__:train:108 - Epoch: [18][50/63]	 loss 4.53606	 cls_loss: 0.4684 cluster_loss: 1.6919 sup_con_loss: 0.7462 contrastive_loss: 4.6327 
2023-11-10 09:20:38.261 | INFO     | __main__:train:108 - Epoch: [18][60/63]	 loss 4.59824	 cls_loss: 0.4932 cluster_loss: 1.7017 sup_con_loss: 0.8542 contrastive_loss: 4.6469 
2023-11-10 09:20:42.022 | INFO     | __main__:train:111 - Train Epoch: 18 Avg Loss: 4.5883 
2023-11-10 09:20:42.023 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:21:32.116 | INFO     | __main__:train:119 - Train Accuracies: All 0.5783 | Old 0.7725 | New 0.4822
2023-11-10 09:21:42.755 | INFO     | __main__:train:108 - Epoch: [19][0/63]	 loss 4.75513	 cls_loss: 0.5636 cluster_loss: 1.8656 sup_con_loss: 0.8980 contrastive_loss: 4.6630 
2023-11-10 09:22:01.483 | INFO     | __main__:train:108 - Epoch: [19][10/63]	 loss 4.53228	 cls_loss: 0.4972 cluster_loss: 1.6646 sup_con_loss: 0.7472 contrastive_loss: 4.6381 
2023-11-10 09:22:20.026 | INFO     | __main__:train:108 - Epoch: [19][20/63]	 loss 4.61134	 cls_loss: 0.5089 cluster_loss: 1.6559 sup_con_loss: 0.9742 contrastive_loss: 4.6398 
2023-11-10 09:22:38.678 | INFO     | __main__:train:108 - Epoch: [19][30/63]	 loss 4.50471	 cls_loss: 0.4543 cluster_loss: 1.6774 sup_con_loss: 0.6870 contrastive_loss: 4.6384 
2023-11-10 09:22:57.348 | INFO     | __main__:train:108 - Epoch: [19][40/63]	 loss 4.42319	 cls_loss: 0.4794 cluster_loss: 1.6493 sup_con_loss: 0.4870 contrastive_loss: 4.6352 
2023-11-10 09:23:15.982 | INFO     | __main__:train:108 - Epoch: [19][50/63]	 loss 4.53759	 cls_loss: 0.5254 cluster_loss: 1.7175 sup_con_loss: 0.6298 contrastive_loss: 4.6413 
2023-11-10 09:23:34.521 | INFO     | __main__:train:108 - Epoch: [19][60/63]	 loss 4.60023	 cls_loss: 0.4560 cluster_loss: 1.7006 sup_con_loss: 0.9176 contrastive_loss: 4.6371 
2023-11-10 09:23:38.283 | INFO     | __main__:train:111 - Train Epoch: 19 Avg Loss: 4.5620 
2023-11-10 09:23:38.283 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:24:28.404 | INFO     | __main__:train:119 - Train Accuracies: All 0.5850 | Old 0.7641 | New 0.4963
2023-11-10 09:24:39.204 | INFO     | __main__:train:108 - Epoch: [20][0/63]	 loss 4.36650	 cls_loss: 0.5241 cluster_loss: 1.5917 sup_con_loss: 0.3903 contrastive_loss: 4.6336 
2023-11-10 09:24:58.027 | INFO     | __main__:train:108 - Epoch: [20][10/63]	 loss 4.64457	 cls_loss: 0.4708 cluster_loss: 1.7595 sup_con_loss: 0.9187 contrastive_loss: 4.6377 
2023-11-10 09:25:16.587 | INFO     | __main__:train:108 - Epoch: [20][20/63]	 loss 4.55575	 cls_loss: 0.4693 cluster_loss: 1.6937 sup_con_loss: 0.8115 contrastive_loss: 4.6255 
2023-11-10 09:25:35.131 | INFO     | __main__:train:108 - Epoch: [20][30/63]	 loss 4.52190	 cls_loss: 0.5208 cluster_loss: 1.6762 sup_con_loss: 0.6776 contrastive_loss: 4.6353 
2023-11-10 09:25:53.742 | INFO     | __main__:train:108 - Epoch: [20][40/63]	 loss 4.66225	 cls_loss: 0.5661 cluster_loss: 1.7479 sup_con_loss: 0.8902 contrastive_loss: 4.6406 
2023-11-10 09:26:12.337 | INFO     | __main__:train:108 - Epoch: [20][50/63]	 loss 4.59896	 cls_loss: 0.5070 cluster_loss: 1.6879 sup_con_loss: 0.8710 contrastive_loss: 4.6455 
2023-11-10 09:26:30.783 | INFO     | __main__:train:108 - Epoch: [20][60/63]	 loss 4.60155	 cls_loss: 0.4866 cluster_loss: 1.7429 sup_con_loss: 0.8058 contrastive_loss: 4.6405 
2023-11-10 09:26:34.544 | INFO     | __main__:train:111 - Train Epoch: 20 Avg Loss: 4.5288 
2023-11-10 09:26:34.545 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:27:24.294 | INFO     | __main__:train:119 - Train Accuracies: All 0.5977 | Old 0.7651 | New 0.5149
2023-11-10 09:27:34.608 | INFO     | __main__:train:108 - Epoch: [21][0/63]	 loss 4.57417	 cls_loss: 0.4885 cluster_loss: 1.7137 sup_con_loss: 0.7910 contrastive_loss: 4.6345 
2023-11-10 09:27:53.340 | INFO     | __main__:train:108 - Epoch: [21][10/63]	 loss 4.50271	 cls_loss: 0.5061 cluster_loss: 1.6615 sup_con_loss: 0.6566 contrastive_loss: 4.6397 
2023-11-10 09:28:11.942 | INFO     | __main__:train:108 - Epoch: [21][20/63]	 loss 4.71699	 cls_loss: 0.5356 cluster_loss: 1.8005 sup_con_loss: 0.9759 contrastive_loss: 4.6425 
2023-11-10 09:28:30.555 | INFO     | __main__:train:108 - Epoch: [21][30/63]	 loss 4.42815	 cls_loss: 0.4117 cluster_loss: 1.6389 sup_con_loss: 0.5854 contrastive_loss: 4.6367 
2023-11-10 09:28:49.244 | INFO     | __main__:train:108 - Epoch: [21][40/63]	 loss 4.38612	 cls_loss: 0.4396 cluster_loss: 1.5548 sup_con_loss: 0.5877 contrastive_loss: 4.6399 
2023-11-10 09:29:07.818 | INFO     | __main__:train:108 - Epoch: [21][50/63]	 loss 4.45873	 cls_loss: 0.4114 cluster_loss: 1.5996 sup_con_loss: 0.7719 contrastive_loss: 4.6229 
2023-11-10 09:29:26.324 | INFO     | __main__:train:108 - Epoch: [21][60/63]	 loss 4.47529	 cls_loss: 0.4448 cluster_loss: 1.6018 sup_con_loss: 0.7604 contrastive_loss: 4.6343 
2023-11-10 09:29:30.064 | INFO     | __main__:train:111 - Train Epoch: 21 Avg Loss: 4.4925 
2023-11-10 09:29:30.065 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:30:20.609 | INFO     | __main__:train:119 - Train Accuracies: All 0.5909 | Old 0.7744 | New 0.5000
2023-11-10 09:30:32.615 | INFO     | __main__:train:108 - Epoch: [22][0/63]	 loss 4.39977	 cls_loss: 0.4139 cluster_loss: 1.5563 sup_con_loss: 0.6732 contrastive_loss: 4.6272 
2023-11-10 09:30:51.438 | INFO     | __main__:train:108 - Epoch: [22][10/63]	 loss 4.60972	 cls_loss: 0.4344 cluster_loss: 1.6878 sup_con_loss: 0.9913 contrastive_loss: 4.6364 
2023-11-10 09:31:09.976 | INFO     | __main__:train:108 - Epoch: [22][20/63]	 loss 4.41949	 cls_loss: 0.4122 cluster_loss: 1.5855 sup_con_loss: 0.6731 contrastive_loss: 4.6293 
2023-11-10 09:31:28.671 | INFO     | __main__:train:108 - Epoch: [22][30/63]	 loss 4.33889	 cls_loss: 0.4353 cluster_loss: 1.5363 sup_con_loss: 0.4964 contrastive_loss: 4.6372 
2023-11-10 09:31:47.399 | INFO     | __main__:train:108 - Epoch: [22][40/63]	 loss 4.56964	 cls_loss: 0.4760 cluster_loss: 1.6304 sup_con_loss: 0.9532 contrastive_loss: 4.6303 
2023-11-10 09:32:06.051 | INFO     | __main__:train:108 - Epoch: [22][50/63]	 loss 4.39849	 cls_loss: 0.4600 cluster_loss: 1.4936 sup_con_loss: 0.7447 contrastive_loss: 4.6246 
2023-11-10 09:32:24.593 | INFO     | __main__:train:108 - Epoch: [22][60/63]	 loss 4.43433	 cls_loss: 0.4144 cluster_loss: 1.5565 sup_con_loss: 0.7683 contrastive_loss: 4.6287 
2023-11-10 09:32:28.335 | INFO     | __main__:train:111 - Train Epoch: 22 Avg Loss: 4.4662 
2023-11-10 09:32:28.335 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:33:18.214 | INFO     | __main__:train:119 - Train Accuracies: All 0.6079 | Old 0.7720 | New 0.5266
2023-11-10 09:33:28.949 | INFO     | __main__:train:108 - Epoch: [23][0/63]	 loss 4.40896	 cls_loss: 0.3798 cluster_loss: 1.6555 sup_con_loss: 0.5420 contrastive_loss: 4.6312 
2023-11-10 09:33:47.851 | INFO     | __main__:train:108 - Epoch: [23][10/63]	 loss 4.41523	 cls_loss: 0.4283 cluster_loss: 1.6032 sup_con_loss: 0.6047 contrastive_loss: 4.6332 
2023-11-10 09:34:06.438 | INFO     | __main__:train:108 - Epoch: [23][20/63]	 loss 4.48830	 cls_loss: 0.4594 cluster_loss: 1.6366 sup_con_loss: 0.7133 contrastive_loss: 4.6370 
2023-11-10 09:34:25.096 | INFO     | __main__:train:108 - Epoch: [23][30/63]	 loss 4.51994	 cls_loss: 0.3894 cluster_loss: 1.5827 sup_con_loss: 1.0052 contrastive_loss: 4.6201 
2023-11-10 09:34:43.741 | INFO     | __main__:train:108 - Epoch: [23][40/63]	 loss 4.50123	 cls_loss: 0.4661 cluster_loss: 1.6523 sup_con_loss: 0.6912 contrastive_loss: 4.6494 
2023-11-10 09:35:02.450 | INFO     | __main__:train:108 - Epoch: [23][50/63]	 loss 4.38067	 cls_loss: 0.3923 cluster_loss: 1.4915 sup_con_loss: 0.7717 contrastive_loss: 4.6212 
2023-11-10 09:35:20.954 | INFO     | __main__:train:108 - Epoch: [23][60/63]	 loss 4.40918	 cls_loss: 0.3916 cluster_loss: 1.5893 sup_con_loss: 0.6604 contrastive_loss: 4.6276 
2023-11-10 09:35:24.713 | INFO     | __main__:train:111 - Train Epoch: 23 Avg Loss: 4.4263 
2023-11-10 09:35:24.714 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:36:15.741 | INFO     | __main__:train:119 - Train Accuracies: All 0.5968 | Old 0.7641 | New 0.5139
2023-11-10 09:36:26.007 | INFO     | __main__:train:108 - Epoch: [24][0/63]	 loss 4.52310	 cls_loss: 0.4376 cluster_loss: 1.6763 sup_con_loss: 0.7392 contrastive_loss: 4.6487 
2023-11-10 09:36:45.062 | INFO     | __main__:train:108 - Epoch: [24][10/63]	 loss 4.39922	 cls_loss: 0.3783 cluster_loss: 1.5880 sup_con_loss: 0.6249 contrastive_loss: 4.6398 
2023-11-10 09:37:03.685 | INFO     | __main__:train:108 - Epoch: [24][20/63]	 loss 4.40253	 cls_loss: 0.3692 cluster_loss: 1.5270 sup_con_loss: 0.7933 contrastive_loss: 4.6202 
2023-11-10 09:37:22.389 | INFO     | __main__:train:108 - Epoch: [24][30/63]	 loss 4.40799	 cls_loss: 0.4010 cluster_loss: 1.4842 sup_con_loss: 0.8579 contrastive_loss: 4.6194 
2023-11-10 09:37:41.152 | INFO     | __main__:train:108 - Epoch: [24][40/63]	 loss 4.48344	 cls_loss: 0.4323 cluster_loss: 1.5917 sup_con_loss: 0.8188 contrastive_loss: 4.6322 
2023-11-10 09:37:59.902 | INFO     | __main__:train:108 - Epoch: [24][50/63]	 loss 4.41512	 cls_loss: 0.3792 cluster_loss: 1.5234 sup_con_loss: 0.8373 contrastive_loss: 4.6140 
2023-11-10 09:38:18.468 | INFO     | __main__:train:108 - Epoch: [24][60/63]	 loss 4.43379	 cls_loss: 0.3664 cluster_loss: 1.5991 sup_con_loss: 0.7329 contrastive_loss: 4.6302 
2023-11-10 09:38:22.225 | INFO     | __main__:train:111 - Train Epoch: 24 Avg Loss: 4.4045 
2023-11-10 09:38:22.226 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:39:13.411 | INFO     | __main__:train:119 - Train Accuracies: All 0.6219 | Old 0.7799 | New 0.5437
2023-11-10 09:39:23.578 | INFO     | __main__:train:108 - Epoch: [25][0/63]	 loss 4.43265	 cls_loss: 0.4373 cluster_loss: 1.5045 sup_con_loss: 0.8256 contrastive_loss: 4.6349 
2023-11-10 09:39:42.588 | INFO     | __main__:train:108 - Epoch: [25][10/63]	 loss 4.41397	 cls_loss: 0.3991 cluster_loss: 1.5668 sup_con_loss: 0.7205 contrastive_loss: 4.6210 
2023-11-10 09:40:01.291 | INFO     | __main__:train:108 - Epoch: [25][20/63]	 loss 4.42018	 cls_loss: 0.4285 cluster_loss: 1.5256 sup_con_loss: 0.7669 contrastive_loss: 4.6310 
2023-11-10 09:40:20.060 | INFO     | __main__:train:108 - Epoch: [25][30/63]	 loss 4.41025	 cls_loss: 0.4453 cluster_loss: 1.5621 sup_con_loss: 0.6431 contrastive_loss: 4.6369 
2023-11-10 09:40:38.881 | INFO     | __main__:train:108 - Epoch: [25][40/63]	 loss 4.51762	 cls_loss: 0.3758 cluster_loss: 1.6252 sup_con_loss: 0.9186 contrastive_loss: 4.6280 
2023-11-10 09:40:57.610 | INFO     | __main__:train:108 - Epoch: [25][50/63]	 loss 4.55950	 cls_loss: 0.4213 cluster_loss: 1.6074 sup_con_loss: 1.0174 contrastive_loss: 4.6325 
2023-11-10 09:41:16.180 | INFO     | __main__:train:108 - Epoch: [25][60/63]	 loss 4.33218	 cls_loss: 0.3940 cluster_loss: 1.4633 sup_con_loss: 0.6662 contrastive_loss: 4.6307 
2023-11-10 09:41:19.934 | INFO     | __main__:train:111 - Train Epoch: 25 Avg Loss: 4.3818 
2023-11-10 09:41:19.935 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:42:10.631 | INFO     | __main__:train:119 - Train Accuracies: All 0.6205 | Old 0.7616 | New 0.5506
2023-11-10 09:42:21.668 | INFO     | __main__:train:108 - Epoch: [26][0/63]	 loss 4.32178	 cls_loss: 0.3988 cluster_loss: 1.4683 sup_con_loss: 0.6207 contrastive_loss: 4.6317 
2023-11-10 09:42:40.565 | INFO     | __main__:train:108 - Epoch: [26][10/63]	 loss 4.23344	 cls_loss: 0.3454 cluster_loss: 1.3873 sup_con_loss: 0.6154 contrastive_loss: 4.6083 
2023-11-10 09:42:59.262 | INFO     | __main__:train:108 - Epoch: [26][20/63]	 loss 4.24921	 cls_loss: 0.3490 cluster_loss: 1.4300 sup_con_loss: 0.5547 contrastive_loss: 4.6206 
2023-11-10 09:43:18.024 | INFO     | __main__:train:108 - Epoch: [26][30/63]	 loss 4.24813	 cls_loss: 0.4138 cluster_loss: 1.4079 sup_con_loss: 0.5364 contrastive_loss: 4.6160 
2023-11-10 09:43:36.736 | INFO     | __main__:train:108 - Epoch: [26][40/63]	 loss 4.32363	 cls_loss: 0.3673 cluster_loss: 1.4556 sup_con_loss: 0.6915 contrastive_loss: 4.6260 
2023-11-10 09:43:55.371 | INFO     | __main__:train:108 - Epoch: [26][50/63]	 loss 4.36891	 cls_loss: 0.4138 cluster_loss: 1.4647 sup_con_loss: 0.7728 contrastive_loss: 4.6177 
2023-11-10 09:44:13.977 | INFO     | __main__:train:108 - Epoch: [26][60/63]	 loss 4.29155	 cls_loss: 0.3386 cluster_loss: 1.4518 sup_con_loss: 0.6497 contrastive_loss: 4.6185 
2023-11-10 09:44:17.769 | INFO     | __main__:train:111 - Train Epoch: 26 Avg Loss: 4.3452 
2023-11-10 09:44:17.770 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:45:08.522 | INFO     | __main__:train:119 - Train Accuracies: All 0.6339 | Old 0.7744 | New 0.5643
2023-11-10 09:45:18.991 | INFO     | __main__:train:108 - Epoch: [27][0/63]	 loss 4.35344	 cls_loss: 0.3870 cluster_loss: 1.5280 sup_con_loss: 0.6303 contrastive_loss: 4.6218 
2023-11-10 09:45:37.934 | INFO     | __main__:train:108 - Epoch: [27][10/63]	 loss 4.26617	 cls_loss: 0.3802 cluster_loss: 1.3772 sup_con_loss: 0.6671 contrastive_loss: 4.6222 
2023-11-10 09:45:56.690 | INFO     | __main__:train:108 - Epoch: [27][20/63]	 loss 4.21284	 cls_loss: 0.3201 cluster_loss: 1.3607 sup_con_loss: 0.6215 contrastive_loss: 4.6136 
2023-11-10 09:46:15.454 | INFO     | __main__:train:108 - Epoch: [27][30/63]	 loss 4.25659	 cls_loss: 0.3382 cluster_loss: 1.5056 sup_con_loss: 0.4603 contrastive_loss: 4.6130 
2023-11-10 09:46:34.197 | INFO     | __main__:train:108 - Epoch: [27][40/63]	 loss 4.31832	 cls_loss: 0.3551 cluster_loss: 1.4886 sup_con_loss: 0.6254 contrastive_loss: 4.6271 
2023-11-10 09:46:52.917 | INFO     | __main__:train:108 - Epoch: [27][50/63]	 loss 4.25288	 cls_loss: 0.3432 cluster_loss: 1.3874 sup_con_loss: 0.6617 contrastive_loss: 4.6144 
2023-11-10 09:47:11.538 | INFO     | __main__:train:108 - Epoch: [27][60/63]	 loss 4.35287	 cls_loss: 0.3342 cluster_loss: 1.4939 sup_con_loss: 0.7619 contrastive_loss: 4.6126 
2023-11-10 09:47:15.285 | INFO     | __main__:train:111 - Train Epoch: 27 Avg Loss: 4.3232 
2023-11-10 09:47:15.285 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:48:05.090 | INFO     | __main__:train:119 - Train Accuracies: All 0.6293 | Old 0.7808 | New 0.5543
2023-11-10 09:48:15.601 | INFO     | __main__:train:108 - Epoch: [28][0/63]	 loss 4.41778	 cls_loss: 0.3744 cluster_loss: 1.5208 sup_con_loss: 0.8297 contrastive_loss: 4.6274 
2023-11-10 09:48:34.563 | INFO     | __main__:train:108 - Epoch: [28][10/63]	 loss 4.33480	 cls_loss: 0.3932 cluster_loss: 1.4882 sup_con_loss: 0.6464 contrastive_loss: 4.6209 
2023-11-10 09:48:53.267 | INFO     | __main__:train:108 - Epoch: [28][20/63]	 loss 4.13683	 cls_loss: 0.3193 cluster_loss: 1.3047 sup_con_loss: 0.5045 contrastive_loss: 4.6161 
2023-11-10 09:49:11.962 | INFO     | __main__:train:108 - Epoch: [28][30/63]	 loss 4.27482	 cls_loss: 0.4085 cluster_loss: 1.3950 sup_con_loss: 0.6383 contrastive_loss: 4.6179 
2023-11-10 09:49:30.702 | INFO     | __main__:train:108 - Epoch: [28][40/63]	 loss 4.34976	 cls_loss: 0.3478 cluster_loss: 1.4695 sup_con_loss: 0.7770 contrastive_loss: 4.6168 
2023-11-10 09:49:49.457 | INFO     | __main__:train:108 - Epoch: [28][50/63]	 loss 4.33854	 cls_loss: 0.3784 cluster_loss: 1.4521 sup_con_loss: 0.7379 contrastive_loss: 4.6215 
2023-11-10 09:50:08.046 | INFO     | __main__:train:108 - Epoch: [28][60/63]	 loss 4.31160	 cls_loss: 0.3261 cluster_loss: 1.4584 sup_con_loss: 0.7075 contrastive_loss: 4.6182 
2023-11-10 09:50:11.859 | INFO     | __main__:train:111 - Train Epoch: 28 Avg Loss: 4.3209 
2023-11-10 09:50:11.860 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:51:02.607 | INFO     | __main__:train:119 - Train Accuracies: All 0.6499 | Old 0.7952 | New 0.5780
2023-11-10 09:51:12.398 | INFO     | __main__:train:108 - Epoch: [29][0/63]	 loss 4.56301	 cls_loss: 0.3440 cluster_loss: 1.7063 sup_con_loss: 0.9025 contrastive_loss: 4.6425 
2023-11-10 09:51:31.332 | INFO     | __main__:train:108 - Epoch: [29][10/63]	 loss 4.28684	 cls_loss: 0.3268 cluster_loss: 1.3730 sup_con_loss: 0.8060 contrastive_loss: 4.6122 
2023-11-10 09:51:49.985 | INFO     | __main__:train:108 - Epoch: [29][20/63]	 loss 4.22366	 cls_loss: 0.3600 cluster_loss: 1.3623 sup_con_loss: 0.6032 contrastive_loss: 4.6170 
2023-11-10 09:52:08.724 | INFO     | __main__:train:108 - Epoch: [29][30/63]	 loss 4.30197	 cls_loss: 0.3316 cluster_loss: 1.4719 sup_con_loss: 0.6416 contrastive_loss: 4.6224 
2023-11-10 09:52:27.498 | INFO     | __main__:train:108 - Epoch: [29][40/63]	 loss 4.41775	 cls_loss: 0.3390 cluster_loss: 1.5633 sup_con_loss: 0.7798 contrastive_loss: 4.6308 
2023-11-10 09:52:46.139 | INFO     | __main__:train:108 - Epoch: [29][50/63]	 loss 4.34655	 cls_loss: 0.3472 cluster_loss: 1.5474 sup_con_loss: 0.5960 contrastive_loss: 4.6317 
2023-11-10 09:53:04.680 | INFO     | __main__:train:108 - Epoch: [29][60/63]	 loss 4.27899	 cls_loss: 0.3596 cluster_loss: 1.3996 sup_con_loss: 0.6921 contrastive_loss: 4.6171 
2023-11-10 09:53:08.455 | INFO     | __main__:train:111 - Train Epoch: 29 Avg Loss: 4.2885 
2023-11-10 09:53:08.455 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:53:59.359 | INFO     | __main__:train:119 - Train Accuracies: All 0.6535 | Old 0.7868 | New 0.5875
2023-11-10 09:54:11.746 | INFO     | __main__:train:108 - Epoch: [30][0/63]	 loss 4.29079	 cls_loss: 0.3146 cluster_loss: 1.4347 sup_con_loss: 0.7076 contrastive_loss: 4.6160 
2023-11-10 09:54:30.488 | INFO     | __main__:train:108 - Epoch: [30][10/63]	 loss 4.33942	 cls_loss: 0.3787 cluster_loss: 1.4343 sup_con_loss: 0.7868 contrastive_loss: 4.6141 
2023-11-10 09:54:49.279 | INFO     | __main__:train:108 - Epoch: [30][20/63]	 loss 4.31672	 cls_loss: 0.3121 cluster_loss: 1.4133 sup_con_loss: 0.8437 contrastive_loss: 4.6055 
2023-11-10 09:55:07.991 | INFO     | __main__:train:108 - Epoch: [30][30/63]	 loss 4.27990	 cls_loss: 0.3490 cluster_loss: 1.4321 sup_con_loss: 0.6297 contrastive_loss: 4.6254 
2023-11-10 09:55:26.746 | INFO     | __main__:train:108 - Epoch: [30][40/63]	 loss 4.20818	 cls_loss: 0.3187 cluster_loss: 1.3813 sup_con_loss: 0.5588 contrastive_loss: 4.6203 
2023-11-10 09:55:45.459 | INFO     | __main__:train:108 - Epoch: [30][50/63]	 loss 4.21142	 cls_loss: 0.3058 cluster_loss: 1.3867 sup_con_loss: 0.5824 contrastive_loss: 4.6142 
2023-11-10 09:56:04.023 | INFO     | __main__:train:108 - Epoch: [30][60/63]	 loss 4.30628	 cls_loss: 0.3357 cluster_loss: 1.4317 sup_con_loss: 0.7326 contrastive_loss: 4.6181 
2023-11-10 09:56:07.778 | INFO     | __main__:train:111 - Train Epoch: 30 Avg Loss: 4.2763 
2023-11-10 09:56:07.778 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:56:58.444 | INFO     | __main__:train:119 - Train Accuracies: All 0.6648 | Old 0.7887 | New 0.6034
2023-11-10 09:57:09.264 | INFO     | __main__:train:108 - Epoch: [31][0/63]	 loss 4.26057	 cls_loss: 0.3227 cluster_loss: 1.4399 sup_con_loss: 0.6102 contrastive_loss: 4.6125 
2023-11-10 09:57:28.206 | INFO     | __main__:train:108 - Epoch: [31][10/63]	 loss 4.39457	 cls_loss: 0.3654 cluster_loss: 1.5370 sup_con_loss: 0.7380 contrastive_loss: 4.6297 
2023-11-10 09:57:46.913 | INFO     | __main__:train:108 - Epoch: [31][20/63]	 loss 4.30396	 cls_loss: 0.3128 cluster_loss: 1.4812 sup_con_loss: 0.6732 contrastive_loss: 4.6093 
2023-11-10 09:58:05.588 | INFO     | __main__:train:108 - Epoch: [31][30/63]	 loss 4.29304	 cls_loss: 0.2956 cluster_loss: 1.4326 sup_con_loss: 0.7250 contrastive_loss: 4.6225 
2023-11-10 09:58:24.294 | INFO     | __main__:train:108 - Epoch: [31][40/63]	 loss 4.31960	 cls_loss: 0.3547 cluster_loss: 1.5019 sup_con_loss: 0.6134 contrastive_loss: 4.6223 
2023-11-10 09:58:43.023 | INFO     | __main__:train:108 - Epoch: [31][50/63]	 loss 4.39841	 cls_loss: 0.3480 cluster_loss: 1.5304 sup_con_loss: 0.7997 contrastive_loss: 4.6183 
2023-11-10 09:59:01.621 | INFO     | __main__:train:108 - Epoch: [31][60/63]	 loss 4.43776	 cls_loss: 0.4295 cluster_loss: 1.4709 sup_con_loss: 0.9191 contrastive_loss: 4.6303 
2023-11-10 09:59:05.408 | INFO     | __main__:train:111 - Train Epoch: 31 Avg Loss: 4.2887 
2023-11-10 09:59:05.409 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 09:59:56.310 | INFO     | __main__:train:119 - Train Accuracies: All 0.6666 | Old 0.7804 | New 0.6102
2023-11-10 10:00:06.892 | INFO     | __main__:train:108 - Epoch: [32][0/63]	 loss 4.37024	 cls_loss: 0.3245 cluster_loss: 1.5186 sup_con_loss: 0.7537 contrastive_loss: 4.6243 
2023-11-10 10:00:25.810 | INFO     | __main__:train:108 - Epoch: [32][10/63]	 loss 4.27207	 cls_loss: 0.3153 cluster_loss: 1.3899 sup_con_loss: 0.7389 contrastive_loss: 4.6149 
2023-11-10 10:00:44.555 | INFO     | __main__:train:108 - Epoch: [32][20/63]	 loss 4.21401	 cls_loss: 0.2864 cluster_loss: 1.3579 sup_con_loss: 0.6600 contrastive_loss: 4.6156 
2023-11-10 10:01:03.281 | INFO     | __main__:train:108 - Epoch: [32][30/63]	 loss 4.24347	 cls_loss: 0.3319 cluster_loss: 1.4209 sup_con_loss: 0.5899 contrastive_loss: 4.6112 
2023-11-10 10:01:22.050 | INFO     | __main__:train:108 - Epoch: [32][40/63]	 loss 4.38367	 cls_loss: 0.2945 cluster_loss: 1.4762 sup_con_loss: 0.9234 contrastive_loss: 4.6122 
2023-11-10 10:01:40.744 | INFO     | __main__:train:108 - Epoch: [32][50/63]	 loss 4.28299	 cls_loss: 0.3385 cluster_loss: 1.4442 sup_con_loss: 0.6444 contrastive_loss: 4.6157 
2023-11-10 10:01:59.328 | INFO     | __main__:train:108 - Epoch: [32][60/63]	 loss 4.17071	 cls_loss: 0.3030 cluster_loss: 1.2828 sup_con_loss: 0.6715 contrastive_loss: 4.6089 
2023-11-10 10:02:03.053 | INFO     | __main__:train:111 - Train Epoch: 32 Avg Loss: 4.2639 
2023-11-10 10:02:03.054 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:02:53.556 | INFO     | __main__:train:119 - Train Accuracies: All 0.6693 | Old 0.7902 | New 0.6095
2023-11-10 10:03:04.877 | INFO     | __main__:train:108 - Epoch: [33][0/63]	 loss 4.30855	 cls_loss: 0.2995 cluster_loss: 1.4624 sup_con_loss: 0.7311 contrastive_loss: 4.6112 
2023-11-10 10:03:23.784 | INFO     | __main__:train:108 - Epoch: [33][10/63]	 loss 4.22156	 cls_loss: 0.3428 cluster_loss: 1.3545 sup_con_loss: 0.6567 contrastive_loss: 4.6020 
2023-11-10 10:03:42.489 | INFO     | __main__:train:108 - Epoch: [33][20/63]	 loss 4.25246	 cls_loss: 0.3167 cluster_loss: 1.4220 sup_con_loss: 0.6406 contrastive_loss: 4.6048 
2023-11-10 10:04:01.251 | INFO     | __main__:train:108 - Epoch: [33][30/63]	 loss 4.33822	 cls_loss: 0.3687 cluster_loss: 1.4956 sup_con_loss: 0.6631 contrastive_loss: 4.6231 
2023-11-10 10:04:19.982 | INFO     | __main__:train:108 - Epoch: [33][40/63]	 loss 4.26102	 cls_loss: 0.3471 cluster_loss: 1.3862 sup_con_loss: 0.6799 contrastive_loss: 4.6163 
2023-11-10 10:04:38.718 | INFO     | __main__:train:108 - Epoch: [33][50/63]	 loss 4.26302	 cls_loss: 0.3125 cluster_loss: 1.4149 sup_con_loss: 0.6780 contrastive_loss: 4.6103 
2023-11-10 10:04:57.323 | INFO     | __main__:train:108 - Epoch: [33][60/63]	 loss 4.27721	 cls_loss: 0.3478 cluster_loss: 1.4325 sup_con_loss: 0.6309 contrastive_loss: 4.6208 
2023-11-10 10:05:01.128 | INFO     | __main__:train:111 - Train Epoch: 33 Avg Loss: 4.2599 
2023-11-10 10:05:01.129 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:05:52.448 | INFO     | __main__:train:119 - Train Accuracies: All 0.6813 | Old 0.7981 | New 0.6234
2023-11-10 10:06:02.127 | INFO     | __main__:train:108 - Epoch: [34][0/63]	 loss 4.27375	 cls_loss: 0.2694 cluster_loss: 1.4430 sup_con_loss: 0.6993 contrastive_loss: 4.6104 
2023-11-10 10:06:21.189 | INFO     | __main__:train:108 - Epoch: [34][10/63]	 loss 4.29921	 cls_loss: 0.3068 cluster_loss: 1.4298 sup_con_loss: 0.7439 contrastive_loss: 4.6186 
2023-11-10 10:06:39.970 | INFO     | __main__:train:108 - Epoch: [34][20/63]	 loss 4.21456	 cls_loss: 0.3149 cluster_loss: 1.3353 sup_con_loss: 0.6947 contrastive_loss: 4.6050 
2023-11-10 10:06:58.731 | INFO     | __main__:train:108 - Epoch: [34][30/63]	 loss 4.29999	 cls_loss: 0.3366 cluster_loss: 1.4197 sup_con_loss: 0.7649 contrastive_loss: 4.6026 
2023-11-10 10:07:17.494 | INFO     | __main__:train:108 - Epoch: [34][40/63]	 loss 4.21854	 cls_loss: 0.3155 cluster_loss: 1.3663 sup_con_loss: 0.6527 contrastive_loss: 4.6024 
2023-11-10 10:07:36.174 | INFO     | __main__:train:108 - Epoch: [34][50/63]	 loss 4.20578	 cls_loss: 0.2830 cluster_loss: 1.3774 sup_con_loss: 0.6235 contrastive_loss: 4.6049 
2023-11-10 10:07:54.776 | INFO     | __main__:train:108 - Epoch: [34][60/63]	 loss 4.29184	 cls_loss: 0.3089 cluster_loss: 1.4088 sup_con_loss: 0.7635 contrastive_loss: 4.6166 
2023-11-10 10:07:58.538 | INFO     | __main__:train:111 - Train Epoch: 34 Avg Loss: 4.2561 
2023-11-10 10:07:58.538 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:08:49.291 | INFO     | __main__:train:119 - Train Accuracies: All 0.6795 | Old 0.7764 | New 0.6315
2023-11-10 10:08:58.844 | INFO     | __main__:train:108 - Epoch: [35][0/63]	 loss 4.10676	 cls_loss: 0.3205 cluster_loss: 1.3212 sup_con_loss: 0.3942 contrastive_loss: 4.6121 
2023-11-10 10:09:17.843 | INFO     | __main__:train:108 - Epoch: [35][10/63]	 loss 4.27793	 cls_loss: 0.3618 cluster_loss: 1.3392 sup_con_loss: 0.8210 contrastive_loss: 4.6053 
2023-11-10 10:09:36.578 | INFO     | __main__:train:108 - Epoch: [35][20/63]	 loss 4.26216	 cls_loss: 0.3532 cluster_loss: 1.4075 sup_con_loss: 0.6523 contrastive_loss: 4.6083 
2023-11-10 10:09:55.370 | INFO     | __main__:train:108 - Epoch: [35][30/63]	 loss 4.22179	 cls_loss: 0.2868 cluster_loss: 1.3695 sup_con_loss: 0.6631 contrastive_loss: 4.6141 
2023-11-10 10:10:14.134 | INFO     | __main__:train:108 - Epoch: [35][40/63]	 loss 4.25744	 cls_loss: 0.3067 cluster_loss: 1.3607 sup_con_loss: 0.7846 contrastive_loss: 4.6015 
2023-11-10 10:10:32.829 | INFO     | __main__:train:108 - Epoch: [35][50/63]	 loss 4.22634	 cls_loss: 0.3113 cluster_loss: 1.4124 sup_con_loss: 0.5820 contrastive_loss: 4.6087 
2023-11-10 10:10:51.443 | INFO     | __main__:train:108 - Epoch: [35][60/63]	 loss 4.22059	 cls_loss: 0.3185 cluster_loss: 1.3806 sup_con_loss: 0.6199 contrastive_loss: 4.6073 
2023-11-10 10:10:55.181 | INFO     | __main__:train:111 - Train Epoch: 35 Avg Loss: 4.2383 
2023-11-10 10:10:55.182 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:11:45.832 | INFO     | __main__:train:119 - Train Accuracies: All 0.6855 | Old 0.7848 | New 0.6364
2023-11-10 10:11:56.830 | INFO     | __main__:train:108 - Epoch: [36][0/63]	 loss 4.24789	 cls_loss: 0.3400 cluster_loss: 1.4168 sup_con_loss: 0.6065 contrastive_loss: 4.6088 
2023-11-10 10:12:15.838 | INFO     | __main__:train:108 - Epoch: [36][10/63]	 loss 4.17389	 cls_loss: 0.3140 cluster_loss: 1.3470 sup_con_loss: 0.5398 contrastive_loss: 4.6146 
2023-11-10 10:12:34.572 | INFO     | __main__:train:108 - Epoch: [36][20/63]	 loss 4.31409	 cls_loss: 0.2831 cluster_loss: 1.5306 sup_con_loss: 0.6270 contrastive_loss: 4.6164 
2023-11-10 10:12:53.323 | INFO     | __main__:train:108 - Epoch: [36][30/63]	 loss 4.26299	 cls_loss: 0.3539 cluster_loss: 1.4034 sup_con_loss: 0.6648 contrastive_loss: 4.6065 
2023-11-10 10:13:12.095 | INFO     | __main__:train:108 - Epoch: [36][40/63]	 loss 4.22335	 cls_loss: 0.3519 cluster_loss: 1.4376 sup_con_loss: 0.4739 contrastive_loss: 4.6152 
2023-11-10 10:13:30.782 | INFO     | __main__:train:108 - Epoch: [36][50/63]	 loss 4.29314	 cls_loss: 0.3130 cluster_loss: 1.4117 sup_con_loss: 0.7833 contrastive_loss: 4.6028 
2023-11-10 10:13:49.469 | INFO     | __main__:train:108 - Epoch: [36][60/63]	 loss 4.31281	 cls_loss: 0.2807 cluster_loss: 1.4328 sup_con_loss: 0.8290 contrastive_loss: 4.6048 
2023-11-10 10:13:53.255 | INFO     | __main__:train:111 - Train Epoch: 36 Avg Loss: 4.2243 
2023-11-10 10:13:53.255 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:14:43.875 | INFO     | __main__:train:119 - Train Accuracies: All 0.6811 | Old 0.7868 | New 0.6288
2023-11-10 10:14:52.448 | INFO     | __main__:train:108 - Epoch: [37][0/63]	 loss 4.15275	 cls_loss: 0.3408 cluster_loss: 1.3200 sup_con_loss: 0.5167 contrastive_loss: 4.6071 
2023-11-10 10:15:11.801 | INFO     | __main__:train:108 - Epoch: [37][10/63]	 loss 4.31084	 cls_loss: 0.3053 cluster_loss: 1.4827 sup_con_loss: 0.6706 contrastive_loss: 4.6239 
2023-11-10 10:15:30.563 | INFO     | __main__:train:108 - Epoch: [37][20/63]	 loss 4.20495	 cls_loss: 0.3229 cluster_loss: 1.3419 sup_con_loss: 0.6447 contrastive_loss: 4.6062 
2023-11-10 10:15:49.355 | INFO     | __main__:train:108 - Epoch: [37][30/63]	 loss 4.25168	 cls_loss: 0.2879 cluster_loss: 1.4213 sup_con_loss: 0.6551 contrastive_loss: 4.6119 
2023-11-10 10:16:08.117 | INFO     | __main__:train:108 - Epoch: [37][40/63]	 loss 4.26910	 cls_loss: 0.3004 cluster_loss: 1.4184 sup_con_loss: 0.7028 contrastive_loss: 4.6093 
2023-11-10 10:16:26.826 | INFO     | __main__:train:108 - Epoch: [37][50/63]	 loss 4.16039	 cls_loss: 0.2838 cluster_loss: 1.3253 sup_con_loss: 0.6024 contrastive_loss: 4.5981 
2023-11-10 10:16:45.413 | INFO     | __main__:train:108 - Epoch: [37][60/63]	 loss 4.18290	 cls_loss: 0.2947 cluster_loss: 1.3721 sup_con_loss: 0.5378 contrastive_loss: 4.6149 
2023-11-10 10:16:49.198 | INFO     | __main__:train:111 - Train Epoch: 37 Avg Loss: 4.2333 
2023-11-10 10:16:49.198 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:17:39.168 | INFO     | __main__:train:119 - Train Accuracies: All 0.6976 | Old 0.7976 | New 0.6481
2023-11-10 10:17:49.541 | INFO     | __main__:train:108 - Epoch: [38][0/63]	 loss 4.22904	 cls_loss: 0.2723 cluster_loss: 1.3431 sup_con_loss: 0.7733 contrastive_loss: 4.6001 
2023-11-10 10:18:08.502 | INFO     | __main__:train:108 - Epoch: [38][10/63]	 loss 4.17519	 cls_loss: 0.2666 cluster_loss: 1.3712 sup_con_loss: 0.5573 contrastive_loss: 4.6085 
2023-11-10 10:18:27.242 | INFO     | __main__:train:108 - Epoch: [38][20/63]	 loss 3.98385	 cls_loss: 0.2817 cluster_loss: 1.1729 sup_con_loss: 0.3729 contrastive_loss: 4.6036 
2023-11-10 10:18:46.007 | INFO     | __main__:train:108 - Epoch: [38][30/63]	 loss 4.29006	 cls_loss: 0.2919 cluster_loss: 1.4530 sup_con_loss: 0.7078 contrastive_loss: 4.6087 
2023-11-10 10:19:04.725 | INFO     | __main__:train:108 - Epoch: [38][40/63]	 loss 4.25735	 cls_loss: 0.2866 cluster_loss: 1.4239 sup_con_loss: 0.6534 contrastive_loss: 4.6197 
2023-11-10 10:19:23.354 | INFO     | __main__:train:108 - Epoch: [38][50/63]	 loss 4.36421	 cls_loss: 0.3159 cluster_loss: 1.4327 sup_con_loss: 0.9253 contrastive_loss: 4.6131 
2023-11-10 10:19:41.938 | INFO     | __main__:train:108 - Epoch: [38][60/63]	 loss 4.21117	 cls_loss: 0.2902 cluster_loss: 1.3331 sup_con_loss: 0.7183 contrastive_loss: 4.6025 
2023-11-10 10:19:45.706 | INFO     | __main__:train:111 - Train Epoch: 38 Avg Loss: 4.2194 
2023-11-10 10:19:45.707 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:20:36.285 | INFO     | __main__:train:119 - Train Accuracies: All 0.7010 | Old 0.7986 | New 0.6527
2023-11-10 10:20:46.002 | INFO     | __main__:train:108 - Epoch: [39][0/63]	 loss 4.25921	 cls_loss: 0.2526 cluster_loss: 1.4624 sup_con_loss: 0.6516 contrastive_loss: 4.6034 
2023-11-10 10:21:05.130 | INFO     | __main__:train:108 - Epoch: [39][10/63]	 loss 4.29262	 cls_loss: 0.2878 cluster_loss: 1.4793 sup_con_loss: 0.6750 contrastive_loss: 4.6063 
2023-11-10 10:21:23.838 | INFO     | __main__:train:108 - Epoch: [39][20/63]	 loss 4.37029	 cls_loss: 0.3166 cluster_loss: 1.5522 sup_con_loss: 0.7024 contrastive_loss: 4.6226 
2023-11-10 10:21:42.532 | INFO     | __main__:train:108 - Epoch: [39][30/63]	 loss 4.24867	 cls_loss: 0.3226 cluster_loss: 1.3785 sup_con_loss: 0.7021 contrastive_loss: 4.6061 
2023-11-10 10:22:01.268 | INFO     | __main__:train:108 - Epoch: [39][40/63]	 loss 4.07583	 cls_loss: 0.2928 cluster_loss: 1.2492 sup_con_loss: 0.4929 contrastive_loss: 4.5982 
2023-11-10 10:22:19.977 | INFO     | __main__:train:108 - Epoch: [39][50/63]	 loss 4.28437	 cls_loss: 0.2589 cluster_loss: 1.4563 sup_con_loss: 0.7134 contrastive_loss: 4.6115 
2023-11-10 10:22:38.567 | INFO     | __main__:train:108 - Epoch: [39][60/63]	 loss 4.21888	 cls_loss: 0.2973 cluster_loss: 1.3684 sup_con_loss: 0.6665 contrastive_loss: 4.6032 
2023-11-10 10:22:42.353 | INFO     | __main__:train:111 - Train Epoch: 39 Avg Loss: 4.2175 
2023-11-10 10:22:42.354 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:23:33.330 | INFO     | __main__:train:119 - Train Accuracies: All 0.6961 | Old 0.7799 | New 0.6547
2023-11-10 10:23:44.079 | INFO     | __main__:train:108 - Epoch: [40][0/63]	 loss 4.23443	 cls_loss: 0.2684 cluster_loss: 1.3822 sup_con_loss: 0.7138 contrastive_loss: 4.6034 
2023-11-10 10:24:02.942 | INFO     | __main__:train:108 - Epoch: [40][10/63]	 loss 4.25453	 cls_loss: 0.2641 cluster_loss: 1.4011 sup_con_loss: 0.7351 contrastive_loss: 4.6063 
2023-11-10 10:24:21.668 | INFO     | __main__:train:108 - Epoch: [40][20/63]	 loss 4.31457	 cls_loss: 0.2782 cluster_loss: 1.4721 sup_con_loss: 0.7649 contrastive_loss: 4.6041 
2023-11-10 10:24:40.389 | INFO     | __main__:train:108 - Epoch: [40][30/63]	 loss 4.15980	 cls_loss: 0.2716 cluster_loss: 1.2815 sup_con_loss: 0.6992 contrastive_loss: 4.5954 
2023-11-10 10:24:59.140 | INFO     | __main__:train:108 - Epoch: [40][40/63]	 loss 4.11885	 cls_loss: 0.2717 cluster_loss: 1.3013 sup_con_loss: 0.5445 contrastive_loss: 4.5958 
2023-11-10 10:25:17.877 | INFO     | __main__:train:108 - Epoch: [40][50/63]	 loss 4.05588	 cls_loss: 0.2301 cluster_loss: 1.2353 sup_con_loss: 0.5292 contrastive_loss: 4.5957 
2023-11-10 10:25:36.506 | INFO     | __main__:train:108 - Epoch: [40][60/63]	 loss 4.20491	 cls_loss: 0.2806 cluster_loss: 1.3440 sup_con_loss: 0.6945 contrastive_loss: 4.6000 
2023-11-10 10:25:40.288 | INFO     | __main__:train:111 - Train Epoch: 40 Avg Loss: 4.1983 
2023-11-10 10:25:40.288 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:26:31.523 | INFO     | __main__:train:119 - Train Accuracies: All 0.7012 | Old 0.7976 | New 0.6535
2023-11-10 10:26:43.300 | INFO     | __main__:train:108 - Epoch: [41][0/63]	 loss 4.17223	 cls_loss: 0.2783 cluster_loss: 1.3389 sup_con_loss: 0.6186 contrastive_loss: 4.5969 
2023-11-10 10:27:02.330 | INFO     | __main__:train:108 - Epoch: [41][10/63]	 loss 4.22995	 cls_loss: 0.3101 cluster_loss: 1.3898 sup_con_loss: 0.6476 contrastive_loss: 4.6022 
2023-11-10 10:27:21.145 | INFO     | __main__:train:108 - Epoch: [41][20/63]	 loss 4.27097	 cls_loss: 0.2701 cluster_loss: 1.4924 sup_con_loss: 0.6049 contrastive_loss: 4.6072 
2023-11-10 10:27:39.954 | INFO     | __main__:train:108 - Epoch: [41][30/63]	 loss 4.12636	 cls_loss: 0.2797 cluster_loss: 1.3502 sup_con_loss: 0.4491 contrastive_loss: 4.6056 
2023-11-10 10:27:58.714 | INFO     | __main__:train:108 - Epoch: [41][40/63]	 loss 4.17330	 cls_loss: 0.2576 cluster_loss: 1.3063 sup_con_loss: 0.6859 contrastive_loss: 4.6061 
2023-11-10 10:28:17.369 | INFO     | __main__:train:108 - Epoch: [41][50/63]	 loss 4.13073	 cls_loss: 0.3115 cluster_loss: 1.3031 sup_con_loss: 0.5176 contrastive_loss: 4.6055 
2023-11-10 10:28:35.994 | INFO     | __main__:train:108 - Epoch: [41][60/63]	 loss 4.19612	 cls_loss: 0.3051 cluster_loss: 1.3918 sup_con_loss: 0.5435 contrastive_loss: 4.6068 
2023-11-10 10:28:39.776 | INFO     | __main__:train:111 - Train Epoch: 41 Avg Loss: 4.1974 
2023-11-10 10:28:39.776 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:29:30.577 | INFO     | __main__:train:119 - Train Accuracies: All 0.7007 | Old 0.7863 | New 0.6584
2023-11-10 10:29:41.965 | INFO     | __main__:train:108 - Epoch: [42][0/63]	 loss 4.21005	 cls_loss: 0.2577 cluster_loss: 1.3414 sup_con_loss: 0.7446 contrastive_loss: 4.5959 
2023-11-10 10:30:00.914 | INFO     | __main__:train:108 - Epoch: [42][10/63]	 loss 4.13370	 cls_loss: 0.2804 cluster_loss: 1.3316 sup_con_loss: 0.5296 contrastive_loss: 4.5918 
2023-11-10 10:30:19.591 | INFO     | __main__:train:108 - Epoch: [42][20/63]	 loss 4.17408	 cls_loss: 0.2572 cluster_loss: 1.3571 sup_con_loss: 0.6010 contrastive_loss: 4.6024 
2023-11-10 10:30:38.352 | INFO     | __main__:train:108 - Epoch: [42][30/63]	 loss 4.27955	 cls_loss: 0.2486 cluster_loss: 1.4694 sup_con_loss: 0.6797 contrastive_loss: 4.6147 
2023-11-10 10:30:57.076 | INFO     | __main__:train:108 - Epoch: [42][40/63]	 loss 4.14903	 cls_loss: 0.3112 cluster_loss: 1.3313 sup_con_loss: 0.5169 contrastive_loss: 4.6059 
2023-11-10 10:31:15.787 | INFO     | __main__:train:108 - Epoch: [42][50/63]	 loss 4.26045	 cls_loss: 0.3065 cluster_loss: 1.3989 sup_con_loss: 0.7143 contrastive_loss: 4.6059 
2023-11-10 10:31:34.404 | INFO     | __main__:train:108 - Epoch: [42][60/63]	 loss 4.30828	 cls_loss: 0.3193 cluster_loss: 1.4491 sup_con_loss: 0.7408 contrastive_loss: 4.6082 
2023-11-10 10:31:38.198 | INFO     | __main__:train:111 - Train Epoch: 42 Avg Loss: 4.2259 
2023-11-10 10:31:38.199 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:32:28.598 | INFO     | __main__:train:119 - Train Accuracies: All 0.7024 | Old 0.7897 | New 0.6591
2023-11-10 10:32:39.478 | INFO     | __main__:train:108 - Epoch: [43][0/63]	 loss 4.17946	 cls_loss: 0.2833 cluster_loss: 1.3349 sup_con_loss: 0.6345 contrastive_loss: 4.6009 
2023-11-10 10:32:58.678 | INFO     | __main__:train:108 - Epoch: [43][10/63]	 loss 4.21961	 cls_loss: 0.3148 cluster_loss: 1.3694 sup_con_loss: 0.6492 contrastive_loss: 4.6033 
2023-11-10 10:33:17.362 | INFO     | __main__:train:108 - Epoch: [43][20/63]	 loss 4.15112	 cls_loss: 0.2800 cluster_loss: 1.3429 sup_con_loss: 0.5270 contrastive_loss: 4.6089 
2023-11-10 10:33:36.035 | INFO     | __main__:train:108 - Epoch: [43][30/63]	 loss 4.23687	 cls_loss: 0.3011 cluster_loss: 1.3830 sup_con_loss: 0.6924 contrastive_loss: 4.6003 
2023-11-10 10:33:54.776 | INFO     | __main__:train:108 - Epoch: [43][40/63]	 loss 4.11190	 cls_loss: 0.2737 cluster_loss: 1.3389 sup_con_loss: 0.4490 contrastive_loss: 4.5979 
2023-11-10 10:34:13.521 | INFO     | __main__:train:108 - Epoch: [43][50/63]	 loss 4.13136	 cls_loss: 0.2558 cluster_loss: 1.2945 sup_con_loss: 0.6084 contrastive_loss: 4.5961 
2023-11-10 10:34:32.122 | INFO     | __main__:train:108 - Epoch: [43][60/63]	 loss 4.18241	 cls_loss: 0.2553 cluster_loss: 1.3736 sup_con_loss: 0.5910 contrastive_loss: 4.6052 
2023-11-10 10:34:35.915 | INFO     | __main__:train:111 - Train Epoch: 43 Avg Loss: 4.1968 
2023-11-10 10:34:35.916 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:35:26.819 | INFO     | __main__:train:119 - Train Accuracies: All 0.7028 | Old 0.7892 | New 0.6601
2023-11-10 10:35:36.250 | INFO     | __main__:train:108 - Epoch: [44][0/63]	 loss 4.19730	 cls_loss: 0.3055 cluster_loss: 1.2777 sup_con_loss: 0.7727 contrastive_loss: 4.5991 
2023-11-10 10:35:55.270 | INFO     | __main__:train:108 - Epoch: [44][10/63]	 loss 4.05781	 cls_loss: 0.2821 cluster_loss: 1.2418 sup_con_loss: 0.4705 contrastive_loss: 4.5958 
2023-11-10 10:36:13.985 | INFO     | __main__:train:108 - Epoch: [44][20/63]	 loss 4.24918	 cls_loss: 0.2997 cluster_loss: 1.4127 sup_con_loss: 0.6618 contrastive_loss: 4.6068 
2023-11-10 10:36:32.644 | INFO     | __main__:train:108 - Epoch: [44][30/63]	 loss 4.11862	 cls_loss: 0.2836 cluster_loss: 1.2725 sup_con_loss: 0.5840 contrastive_loss: 4.5966 
2023-11-10 10:36:51.391 | INFO     | __main__:train:108 - Epoch: [44][40/63]	 loss 4.31596	 cls_loss: 0.3118 cluster_loss: 1.4205 sup_con_loss: 0.8334 contrastive_loss: 4.6028 
2023-11-10 10:37:10.092 | INFO     | __main__:train:108 - Epoch: [44][50/63]	 loss 4.17910	 cls_loss: 0.2515 cluster_loss: 1.3561 sup_con_loss: 0.6344 contrastive_loss: 4.5962 
2023-11-10 10:37:28.781 | INFO     | __main__:train:108 - Epoch: [44][60/63]	 loss 4.22701	 cls_loss: 0.3247 cluster_loss: 1.3453 sup_con_loss: 0.7281 contrastive_loss: 4.5910 
2023-11-10 10:37:32.553 | INFO     | __main__:train:111 - Train Epoch: 44 Avg Loss: 4.2011 
2023-11-10 10:37:32.554 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:38:24.749 | INFO     | __main__:train:119 - Train Accuracies: All 0.7077 | Old 0.7804 | New 0.6718
2023-11-10 10:38:34.957 | INFO     | __main__:train:108 - Epoch: [45][0/63]	 loss 4.14494	 cls_loss: 0.2765 cluster_loss: 1.3445 sup_con_loss: 0.5182 contrastive_loss: 4.6044 
2023-11-10 10:38:53.906 | INFO     | __main__:train:108 - Epoch: [45][10/63]	 loss 4.23269	 cls_loss: 0.2628 cluster_loss: 1.3734 sup_con_loss: 0.7360 contrastive_loss: 4.6007 
2023-11-10 10:39:12.638 | INFO     | __main__:train:108 - Epoch: [45][20/63]	 loss 4.26295	 cls_loss: 0.2657 cluster_loss: 1.3719 sup_con_loss: 0.8103 contrastive_loss: 4.6070 
2023-11-10 10:39:31.439 | INFO     | __main__:train:108 - Epoch: [45][30/63]	 loss 4.43276	 cls_loss: 0.2455 cluster_loss: 1.6004 sup_con_loss: 0.8788 contrastive_loss: 4.6138 
2023-11-10 10:39:50.183 | INFO     | __main__:train:108 - Epoch: [45][40/63]	 loss 4.13967	 cls_loss: 0.2612 cluster_loss: 1.3750 sup_con_loss: 0.4699 contrastive_loss: 4.6000 
2023-11-10 10:40:08.913 | INFO     | __main__:train:108 - Epoch: [45][50/63]	 loss 4.29549	 cls_loss: 0.2574 cluster_loss: 1.4970 sup_con_loss: 0.6794 contrastive_loss: 4.6070 
2023-11-10 10:40:27.543 | INFO     | __main__:train:108 - Epoch: [45][60/63]	 loss 4.28305	 cls_loss: 0.2785 cluster_loss: 1.4385 sup_con_loss: 0.7440 contrastive_loss: 4.6003 
2023-11-10 10:40:31.290 | INFO     | __main__:train:111 - Train Epoch: 45 Avg Loss: 4.2092 
2023-11-10 10:40:31.290 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:41:22.871 | INFO     | __main__:train:119 - Train Accuracies: All 0.7076 | Old 0.7813 | New 0.6711
2023-11-10 10:41:33.098 | INFO     | __main__:train:108 - Epoch: [46][0/63]	 loss 4.19225	 cls_loss: 0.2714 cluster_loss: 1.3535 sup_con_loss: 0.6605 contrastive_loss: 4.5943 
2023-11-10 10:41:52.151 | INFO     | __main__:train:108 - Epoch: [46][10/63]	 loss 4.29407	 cls_loss: 0.2495 cluster_loss: 1.4242 sup_con_loss: 0.8352 contrastive_loss: 4.5980 
2023-11-10 10:42:10.905 | INFO     | __main__:train:108 - Epoch: [46][20/63]	 loss 4.26780	 cls_loss: 0.2597 cluster_loss: 1.4124 sup_con_loss: 0.7732 contrastive_loss: 4.5973 
2023-11-10 10:42:29.639 | INFO     | __main__:train:108 - Epoch: [46][30/63]	 loss 4.09625	 cls_loss: 0.2709 cluster_loss: 1.3191 sup_con_loss: 0.4480 contrastive_loss: 4.5957 
2023-11-10 10:42:48.488 | INFO     | __main__:train:108 - Epoch: [46][40/63]	 loss 4.13400	 cls_loss: 0.2818 cluster_loss: 1.2832 sup_con_loss: 0.6102 contrastive_loss: 4.5966 
2023-11-10 10:43:07.218 | INFO     | __main__:train:108 - Epoch: [46][50/63]	 loss 4.19128	 cls_loss: 0.2926 cluster_loss: 1.3497 sup_con_loss: 0.6351 contrastive_loss: 4.5989 
2023-11-10 10:43:25.814 | INFO     | __main__:train:108 - Epoch: [46][60/63]	 loss 4.12100	 cls_loss: 0.3129 cluster_loss: 1.2779 sup_con_loss: 0.5542 contrastive_loss: 4.5952 
2023-11-10 10:43:29.635 | INFO     | __main__:train:111 - Train Epoch: 46 Avg Loss: 4.1825 
2023-11-10 10:43:29.635 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:44:21.338 | INFO     | __main__:train:119 - Train Accuracies: All 0.7102 | Old 0.7715 | New 0.6799
2023-11-10 10:44:31.412 | INFO     | __main__:train:108 - Epoch: [47][0/63]	 loss 4.24254	 cls_loss: 0.2917 cluster_loss: 1.3751 sup_con_loss: 0.7353 contrastive_loss: 4.5989 
2023-11-10 10:44:50.499 | INFO     | __main__:train:108 - Epoch: [47][10/63]	 loss 4.18109	 cls_loss: 0.2538 cluster_loss: 1.3796 sup_con_loss: 0.5860 contrastive_loss: 4.6007 
2023-11-10 10:45:09.228 | INFO     | __main__:train:108 - Epoch: [47][20/63]	 loss 4.18561	 cls_loss: 0.2867 cluster_loss: 1.3037 sup_con_loss: 0.7151 contrastive_loss: 4.5963 
2023-11-10 10:45:27.968 | INFO     | __main__:train:108 - Epoch: [47][30/63]	 loss 4.23418	 cls_loss: 0.3123 cluster_loss: 1.4290 sup_con_loss: 0.5849 contrastive_loss: 4.6020 
2023-11-10 10:45:46.704 | INFO     | __main__:train:108 - Epoch: [47][40/63]	 loss 4.09843	 cls_loss: 0.3171 cluster_loss: 1.2913 sup_con_loss: 0.4496 contrastive_loss: 4.6011 
2023-11-10 10:46:05.374 | INFO     | __main__:train:108 - Epoch: [47][50/63]	 loss 4.09679	 cls_loss: 0.2551 cluster_loss: 1.2885 sup_con_loss: 0.5050 contrastive_loss: 4.6050 
2023-11-10 10:46:23.973 | INFO     | __main__:train:108 - Epoch: [47][60/63]	 loss 4.20689	 cls_loss: 0.3122 cluster_loss: 1.2890 sup_con_loss: 0.7819 contrastive_loss: 4.5940 
2023-11-10 10:46:27.739 | INFO     | __main__:train:111 - Train Epoch: 47 Avg Loss: 4.1872 
2023-11-10 10:46:27.740 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:47:19.332 | INFO     | __main__:train:119 - Train Accuracies: All 0.7135 | Old 0.7843 | New 0.6784
2023-11-10 10:47:30.335 | INFO     | __main__:train:108 - Epoch: [48][0/63]	 loss 4.21088	 cls_loss: 0.3221 cluster_loss: 1.3452 sup_con_loss: 0.6757 contrastive_loss: 4.5958 
2023-11-10 10:47:49.283 | INFO     | __main__:train:108 - Epoch: [48][10/63]	 loss 4.15968	 cls_loss: 0.2666 cluster_loss: 1.3044 sup_con_loss: 0.6640 contrastive_loss: 4.5940 
2023-11-10 10:48:08.028 | INFO     | __main__:train:108 - Epoch: [48][20/63]	 loss 4.31973	 cls_loss: 0.2433 cluster_loss: 1.4965 sup_con_loss: 0.7781 contrastive_loss: 4.5993 
2023-11-10 10:48:26.753 | INFO     | __main__:train:108 - Epoch: [48][30/63]	 loss 4.23128	 cls_loss: 0.2802 cluster_loss: 1.3792 sup_con_loss: 0.7196 contrastive_loss: 4.5921 
2023-11-10 10:48:45.463 | INFO     | __main__:train:108 - Epoch: [48][40/63]	 loss 4.14973	 cls_loss: 0.2526 cluster_loss: 1.3046 sup_con_loss: 0.6375 contrastive_loss: 4.6003 
2023-11-10 10:49:04.217 | INFO     | __main__:train:108 - Epoch: [48][50/63]	 loss 4.19333	 cls_loss: 0.2584 cluster_loss: 1.4444 sup_con_loss: 0.4773 contrastive_loss: 4.6107 
2023-11-10 10:49:22.794 | INFO     | __main__:train:108 - Epoch: [48][60/63]	 loss 4.34633	 cls_loss: 0.2416 cluster_loss: 1.4577 sup_con_loss: 0.9281 contrastive_loss: 4.5992 
2023-11-10 10:49:26.593 | INFO     | __main__:train:111 - Train Epoch: 48 Avg Loss: 4.1780 
2023-11-10 10:49:26.594 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:50:17.737 | INFO     | __main__:train:119 - Train Accuracies: All 0.7197 | Old 0.7996 | New 0.6801
2023-11-10 10:50:28.301 | INFO     | __main__:train:108 - Epoch: [49][0/63]	 loss 4.22725	 cls_loss: 0.2726 cluster_loss: 1.4162 sup_con_loss: 0.6139 contrastive_loss: 4.6099 
2023-11-10 10:50:47.296 | INFO     | __main__:train:108 - Epoch: [49][10/63]	 loss 4.27237	 cls_loss: 0.3174 cluster_loss: 1.3681 sup_con_loss: 0.8021 contrastive_loss: 4.6019 
2023-11-10 10:51:06.042 | INFO     | __main__:train:108 - Epoch: [49][20/63]	 loss 4.16054	 cls_loss: 0.2479 cluster_loss: 1.3041 sup_con_loss: 0.6925 contrastive_loss: 4.5903 
2023-11-10 10:51:24.761 | INFO     | __main__:train:108 - Epoch: [49][30/63]	 loss 4.15270	 cls_loss: 0.3073 cluster_loss: 1.3359 sup_con_loss: 0.5252 contrastive_loss: 4.6046 
2023-11-10 10:51:43.598 | INFO     | __main__:train:108 - Epoch: [49][40/63]	 loss 4.17592	 cls_loss: 0.2420 cluster_loss: 1.2990 sup_con_loss: 0.7394 contrastive_loss: 4.5970 
2023-11-10 10:52:02.333 | INFO     | __main__:train:108 - Epoch: [49][50/63]	 loss 4.03163	 cls_loss: 0.2673 cluster_loss: 1.2249 sup_con_loss: 0.4498 contrastive_loss: 4.5915 
2023-11-10 10:52:20.936 | INFO     | __main__:train:108 - Epoch: [49][60/63]	 loss 4.14126	 cls_loss: 0.2610 cluster_loss: 1.2475 sup_con_loss: 0.7177 contrastive_loss: 4.5967 
2023-11-10 10:52:24.720 | INFO     | __main__:train:111 - Train Epoch: 49 Avg Loss: 4.1573 
2023-11-10 10:52:24.721 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:53:15.701 | INFO     | __main__:train:119 - Train Accuracies: All 0.7215 | Old 0.7912 | New 0.6870
2023-11-10 10:53:25.642 | INFO     | __main__:train:108 - Epoch: [50][0/63]	 loss 4.00427	 cls_loss: 0.2663 cluster_loss: 1.1917 sup_con_loss: 0.4385 contrastive_loss: 4.5892 
2023-11-10 10:53:44.549 | INFO     | __main__:train:108 - Epoch: [50][10/63]	 loss 4.21553	 cls_loss: 0.2346 cluster_loss: 1.3259 sup_con_loss: 0.8185 contrastive_loss: 4.5925 
2023-11-10 10:54:03.299 | INFO     | __main__:train:108 - Epoch: [50][20/63]	 loss 4.28683	 cls_loss: 0.2579 cluster_loss: 1.4480 sup_con_loss: 0.7689 contrastive_loss: 4.5943 
2023-11-10 10:54:22.089 | INFO     | __main__:train:108 - Epoch: [50][30/63]	 loss 4.13355	 cls_loss: 0.2695 cluster_loss: 1.2727 sup_con_loss: 0.6493 contrastive_loss: 4.5919 
2023-11-10 10:54:40.973 | INFO     | __main__:train:108 - Epoch: [50][40/63]	 loss 4.13168	 cls_loss: 0.2356 cluster_loss: 1.2829 sup_con_loss: 0.6505 contrastive_loss: 4.5964 
2023-11-10 10:54:59.815 | INFO     | __main__:train:108 - Epoch: [50][50/63]	 loss 4.25038	 cls_loss: 0.2542 cluster_loss: 1.3747 sup_con_loss: 0.8096 contrastive_loss: 4.5915 
2023-11-10 10:55:18.549 | INFO     | __main__:train:108 - Epoch: [50][60/63]	 loss 4.09017	 cls_loss: 0.2351 cluster_loss: 1.2733 sup_con_loss: 0.5566 contrastive_loss: 4.5929 
2023-11-10 10:55:22.378 | INFO     | __main__:train:111 - Train Epoch: 50 Avg Loss: 4.1624 
2023-11-10 10:55:22.378 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:56:12.942 | INFO     | __main__:train:119 - Train Accuracies: All 0.7259 | Old 0.8115 | New 0.6835
2023-11-10 10:56:23.411 | INFO     | __main__:train:108 - Epoch: [51][0/63]	 loss 3.99433	 cls_loss: 0.2158 cluster_loss: 1.1741 sup_con_loss: 0.4909 contrastive_loss: 4.5905 
2023-11-10 10:56:42.371 | INFO     | __main__:train:108 - Epoch: [51][10/63]	 loss 4.22813	 cls_loss: 0.2279 cluster_loss: 1.3803 sup_con_loss: 0.7679 contrastive_loss: 4.5883 
2023-11-10 10:57:01.154 | INFO     | __main__:train:108 - Epoch: [51][20/63]	 loss 4.03798	 cls_loss: 0.2244 cluster_loss: 1.2785 sup_con_loss: 0.4002 contrastive_loss: 4.5974 
2023-11-10 10:57:19.929 | INFO     | __main__:train:108 - Epoch: [51][30/63]	 loss 4.20190	 cls_loss: 0.2519 cluster_loss: 1.3539 sup_con_loss: 0.6997 contrastive_loss: 4.5981 
2023-11-10 10:57:38.669 | INFO     | __main__:train:108 - Epoch: [51][40/63]	 loss 4.15749	 cls_loss: 0.2368 cluster_loss: 1.3566 sup_con_loss: 0.6013 contrastive_loss: 4.5883 
2023-11-10 10:57:57.411 | INFO     | __main__:train:108 - Epoch: [51][50/63]	 loss 4.07095	 cls_loss: 0.2417 cluster_loss: 1.2589 sup_con_loss: 0.5296 contrastive_loss: 4.5888 
2023-11-10 10:58:16.039 | INFO     | __main__:train:108 - Epoch: [51][60/63]	 loss 4.16749	 cls_loss: 0.2596 cluster_loss: 1.3100 sup_con_loss: 0.6678 contrastive_loss: 4.6022 
2023-11-10 10:58:19.833 | INFO     | __main__:train:111 - Train Epoch: 51 Avg Loss: 4.1440 
2023-11-10 10:58:19.834 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 10:59:10.616 | INFO     | __main__:train:119 - Train Accuracies: All 0.7285 | Old 0.7902 | New 0.6979
2023-11-10 10:59:21.222 | INFO     | __main__:train:108 - Epoch: [52][0/63]	 loss 4.04125	 cls_loss: 0.2721 cluster_loss: 1.1952 sup_con_loss: 0.5361 contrastive_loss: 4.5869 
2023-11-10 10:59:40.199 | INFO     | __main__:train:108 - Epoch: [52][10/63]	 loss 4.22049	 cls_loss: 0.2438 cluster_loss: 1.3623 sup_con_loss: 0.7470 contrastive_loss: 4.5973 
2023-11-10 10:59:58.886 | INFO     | __main__:train:108 - Epoch: [52][20/63]	 loss 4.17324	 cls_loss: 0.2204 cluster_loss: 1.4221 sup_con_loss: 0.5143 contrastive_loss: 4.6026 
2023-11-10 11:00:17.639 | INFO     | __main__:train:108 - Epoch: [52][30/63]	 loss 4.12090	 cls_loss: 0.2263 cluster_loss: 1.3142 sup_con_loss: 0.5772 contrastive_loss: 4.5930 
2023-11-10 11:00:36.433 | INFO     | __main__:train:108 - Epoch: [52][40/63]	 loss 4.05385	 cls_loss: 0.2349 cluster_loss: 1.2925 sup_con_loss: 0.4140 contrastive_loss: 4.5948 
2023-11-10 11:00:55.149 | INFO     | __main__:train:108 - Epoch: [52][50/63]	 loss 4.12236	 cls_loss: 0.2518 cluster_loss: 1.2777 sup_con_loss: 0.6354 contrastive_loss: 4.5866 
2023-11-10 11:01:13.738 | INFO     | __main__:train:108 - Epoch: [52][60/63]	 loss 4.14298	 cls_loss: 0.2684 cluster_loss: 1.3027 sup_con_loss: 0.6098 contrastive_loss: 4.5982 
2023-11-10 11:01:17.464 | INFO     | __main__:train:111 - Train Epoch: 52 Avg Loss: 4.1374 
2023-11-10 11:01:17.465 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:02:08.077 | INFO     | __main__:train:119 - Train Accuracies: All 0.7332 | Old 0.7986 | New 0.7009
2023-11-10 11:02:17.769 | INFO     | __main__:train:108 - Epoch: [53][0/63]	 loss 4.19469	 cls_loss: 0.2443 cluster_loss: 1.4047 sup_con_loss: 0.6000 contrastive_loss: 4.5940 
2023-11-10 11:02:36.940 | INFO     | __main__:train:108 - Epoch: [53][10/63]	 loss 4.26865	 cls_loss: 0.2475 cluster_loss: 1.4008 sup_con_loss: 0.8255 contrastive_loss: 4.5886 
2023-11-10 11:02:55.631 | INFO     | __main__:train:108 - Epoch: [53][20/63]	 loss 4.10048	 cls_loss: 0.2723 cluster_loss: 1.2283 sup_con_loss: 0.6393 contrastive_loss: 4.5893 
2023-11-10 11:03:14.371 | INFO     | __main__:train:108 - Epoch: [53][30/63]	 loss 4.22996	 cls_loss: 0.2409 cluster_loss: 1.3487 sup_con_loss: 0.8240 contrastive_loss: 4.5856 
2023-11-10 11:03:33.091 | INFO     | __main__:train:108 - Epoch: [53][40/63]	 loss 4.19831	 cls_loss: 0.2654 cluster_loss: 1.3173 sup_con_loss: 0.7654 contrastive_loss: 4.5865 
2023-11-10 11:03:51.828 | INFO     | __main__:train:108 - Epoch: [53][50/63]	 loss 4.12991	 cls_loss: 0.2493 cluster_loss: 1.2968 sup_con_loss: 0.6119 contrastive_loss: 4.5932 
2023-11-10 11:04:10.379 | INFO     | __main__:train:108 - Epoch: [53][60/63]	 loss 4.17492	 cls_loss: 0.2748 cluster_loss: 1.3019 sup_con_loss: 0.7180 contrastive_loss: 4.5865 
2023-11-10 11:04:14.187 | INFO     | __main__:train:111 - Train Epoch: 53 Avg Loss: 4.1577 
2023-11-10 11:04:14.187 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:05:05.305 | INFO     | __main__:train:119 - Train Accuracies: All 0.7337 | Old 0.7991 | New 0.7014
2023-11-10 11:05:14.726 | INFO     | __main__:train:108 - Epoch: [54][0/63]	 loss 4.09756	 cls_loss: 0.2719 cluster_loss: 1.2268 sup_con_loss: 0.6330 contrastive_loss: 4.5899 
2023-11-10 11:05:33.786 | INFO     | __main__:train:108 - Epoch: [54][10/63]	 loss 4.14925	 cls_loss: 0.2363 cluster_loss: 1.3344 sup_con_loss: 0.6074 contrastive_loss: 4.5948 
2023-11-10 11:05:52.540 | INFO     | __main__:train:108 - Epoch: [54][20/63]	 loss 4.14850	 cls_loss: 0.2490 cluster_loss: 1.2999 sup_con_loss: 0.6732 contrastive_loss: 4.5858 
2023-11-10 11:06:11.319 | INFO     | __main__:train:108 - Epoch: [54][30/63]	 loss 4.09860	 cls_loss: 0.2445 cluster_loss: 1.2303 sup_con_loss: 0.6644 contrastive_loss: 4.5858 
2023-11-10 11:06:30.146 | INFO     | __main__:train:108 - Epoch: [54][40/63]	 loss 4.10462	 cls_loss: 0.2296 cluster_loss: 1.2990 sup_con_loss: 0.5614 contrastive_loss: 4.5899 
2023-11-10 11:06:48.882 | INFO     | __main__:train:108 - Epoch: [54][50/63]	 loss 4.26536	 cls_loss: 0.2398 cluster_loss: 1.4398 sup_con_loss: 0.7259 contrastive_loss: 4.6023 
2023-11-10 11:07:07.483 | INFO     | __main__:train:108 - Epoch: [54][60/63]	 loss 4.01091	 cls_loss: 0.3026 cluster_loss: 1.1866 sup_con_loss: 0.4314 contrastive_loss: 4.5889 
2023-11-10 11:07:11.242 | INFO     | __main__:train:111 - Train Epoch: 54 Avg Loss: 4.1415 
2023-11-10 11:07:11.242 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:08:02.000 | INFO     | __main__:train:119 - Train Accuracies: All 0.7259 | Old 0.7912 | New 0.6935
2023-11-10 11:08:12.733 | INFO     | __main__:train:108 - Epoch: [55][0/63]	 loss 4.20269	 cls_loss: 0.2324 cluster_loss: 1.3973 sup_con_loss: 0.6499 contrastive_loss: 4.5933 
2023-11-10 11:08:31.757 | INFO     | __main__:train:108 - Epoch: [55][10/63]	 loss 4.06374	 cls_loss: 0.2310 cluster_loss: 1.2308 sup_con_loss: 0.5539 contrastive_loss: 4.5984 
2023-11-10 11:08:50.469 | INFO     | __main__:train:108 - Epoch: [55][20/63]	 loss 4.11287	 cls_loss: 0.2172 cluster_loss: 1.2643 sup_con_loss: 0.6654 contrastive_loss: 4.5879 
2023-11-10 11:09:09.184 | INFO     | __main__:train:108 - Epoch: [55][30/63]	 loss 4.07816	 cls_loss: 0.2489 cluster_loss: 1.2780 sup_con_loss: 0.5126 contrastive_loss: 4.5860 
2023-11-10 11:09:27.961 | INFO     | __main__:train:108 - Epoch: [55][40/63]	 loss 4.17482	 cls_loss: 0.2346 cluster_loss: 1.3340 sup_con_loss: 0.6929 contrastive_loss: 4.5894 
2023-11-10 11:09:46.703 | INFO     | __main__:train:108 - Epoch: [55][50/63]	 loss 4.11167	 cls_loss: 0.2614 cluster_loss: 1.2411 sup_con_loss: 0.6671 contrastive_loss: 4.5846 
2023-11-10 11:10:05.339 | INFO     | __main__:train:108 - Epoch: [55][60/63]	 loss 4.15994	 cls_loss: 0.2485 cluster_loss: 1.2950 sup_con_loss: 0.7129 contrastive_loss: 4.5872 
2023-11-10 11:10:09.142 | INFO     | __main__:train:111 - Train Epoch: 55 Avg Loss: 4.1483 
2023-11-10 11:10:09.142 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:10:59.269 | INFO     | __main__:train:119 - Train Accuracies: All 0.7295 | Old 0.8016 | New 0.6938
2023-11-10 11:11:09.278 | INFO     | __main__:train:108 - Epoch: [56][0/63]	 loss 4.14956	 cls_loss: 0.2813 cluster_loss: 1.3139 sup_con_loss: 0.5979 contrastive_loss: 4.5967 
2023-11-10 11:11:28.247 | INFO     | __main__:train:108 - Epoch: [56][10/63]	 loss 4.04466	 cls_loss: 0.2954 cluster_loss: 1.2138 sup_con_loss: 0.4984 contrastive_loss: 4.5813 
2023-11-10 11:11:46.923 | INFO     | __main__:train:108 - Epoch: [56][20/63]	 loss 4.09572	 cls_loss: 0.2488 cluster_loss: 1.2717 sup_con_loss: 0.5613 contrastive_loss: 4.5932 
2023-11-10 11:12:05.674 | INFO     | __main__:train:108 - Epoch: [56][30/63]	 loss 4.14335	 cls_loss: 0.2428 cluster_loss: 1.2684 sup_con_loss: 0.7152 contrastive_loss: 4.5901 
2023-11-10 11:12:24.484 | INFO     | __main__:train:108 - Epoch: [56][40/63]	 loss 4.15805	 cls_loss: 0.2340 cluster_loss: 1.3451 sup_con_loss: 0.6146 contrastive_loss: 4.5950 
2023-11-10 11:12:43.278 | INFO     | __main__:train:108 - Epoch: [56][50/63]	 loss 4.06609	 cls_loss: 0.2494 cluster_loss: 1.2532 sup_con_loss: 0.5138 contrastive_loss: 4.5914 
2023-11-10 11:13:01.900 | INFO     | __main__:train:108 - Epoch: [56][60/63]	 loss 4.22067	 cls_loss: 0.2558 cluster_loss: 1.3866 sup_con_loss: 0.6907 contrastive_loss: 4.5971 
2023-11-10 11:13:05.667 | INFO     | __main__:train:111 - Train Epoch: 56 Avg Loss: 4.1514 
2023-11-10 11:13:05.668 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:13:56.323 | INFO     | __main__:train:119 - Train Accuracies: All 0.7283 | Old 0.7966 | New 0.6945
2023-11-10 11:14:07.577 | INFO     | __main__:train:108 - Epoch: [57][0/63]	 loss 4.01816	 cls_loss: 0.2328 cluster_loss: 1.2381 sup_con_loss: 0.4296 contrastive_loss: 4.5870 
2023-11-10 11:14:26.482 | INFO     | __main__:train:108 - Epoch: [57][10/63]	 loss 4.21136	 cls_loss: 0.2826 cluster_loss: 1.3948 sup_con_loss: 0.6257 contrastive_loss: 4.5951 
2023-11-10 11:14:45.265 | INFO     | __main__:train:108 - Epoch: [57][20/63]	 loss 4.03350	 cls_loss: 0.2467 cluster_loss: 1.1993 sup_con_loss: 0.5171 contrastive_loss: 4.5948 
2023-11-10 11:15:04.076 | INFO     | __main__:train:108 - Epoch: [57][30/63]	 loss 4.01541	 cls_loss: 0.2383 cluster_loss: 1.1700 sup_con_loss: 0.5469 contrastive_loss: 4.5848 
2023-11-10 11:15:22.859 | INFO     | __main__:train:108 - Epoch: [57][40/63]	 loss 4.20639	 cls_loss: 0.2736 cluster_loss: 1.3776 sup_con_loss: 0.6655 contrastive_loss: 4.5881 
2023-11-10 11:15:41.692 | INFO     | __main__:train:108 - Epoch: [57][50/63]	 loss 4.16853	 cls_loss: 0.2698 cluster_loss: 1.3638 sup_con_loss: 0.5705 contrastive_loss: 4.5969 
2023-11-10 11:16:00.369 | INFO     | __main__:train:108 - Epoch: [57][60/63]	 loss 4.06339	 cls_loss: 0.2649 cluster_loss: 1.2296 sup_con_loss: 0.5324 contrastive_loss: 4.5924 
2023-11-10 11:16:04.138 | INFO     | __main__:train:111 - Train Epoch: 57 Avg Loss: 4.1299 
2023-11-10 11:16:04.138 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:16:55.282 | INFO     | __main__:train:119 - Train Accuracies: All 0.7290 | Old 0.7962 | New 0.6957
2023-11-10 11:17:04.554 | INFO     | __main__:train:108 - Epoch: [58][0/63]	 loss 4.19391	 cls_loss: 0.2508 cluster_loss: 1.3295 sup_con_loss: 0.7424 contrastive_loss: 4.5879 
2023-11-10 11:17:23.611 | INFO     | __main__:train:108 - Epoch: [58][10/63]	 loss 4.17463	 cls_loss: 0.2522 cluster_loss: 1.3933 sup_con_loss: 0.5619 contrastive_loss: 4.5908 
2023-11-10 11:17:42.404 | INFO     | __main__:train:108 - Epoch: [58][20/63]	 loss 4.18688	 cls_loss: 0.2369 cluster_loss: 1.3163 sup_con_loss: 0.7659 contrastive_loss: 4.5851 
2023-11-10 11:18:01.192 | INFO     | __main__:train:108 - Epoch: [58][30/63]	 loss 4.15827	 cls_loss: 0.2344 cluster_loss: 1.3029 sup_con_loss: 0.7180 contrastive_loss: 4.5816 
2023-11-10 11:18:19.965 | INFO     | __main__:train:108 - Epoch: [58][40/63]	 loss 4.04336	 cls_loss: 0.2478 cluster_loss: 1.2487 sup_con_loss: 0.4631 contrastive_loss: 4.5890 
2023-11-10 11:18:38.757 | INFO     | __main__:train:108 - Epoch: [58][50/63]	 loss 4.07072	 cls_loss: 0.2471 cluster_loss: 1.2746 sup_con_loss: 0.4941 contrastive_loss: 4.5889 
2023-11-10 11:18:57.372 | INFO     | __main__:train:108 - Epoch: [58][60/63]	 loss 4.02579	 cls_loss: 0.2268 cluster_loss: 1.2590 sup_con_loss: 0.4156 contrastive_loss: 4.5887 
2023-11-10 11:19:01.173 | INFO     | __main__:train:111 - Train Epoch: 58 Avg Loss: 4.1399 
2023-11-10 11:19:01.173 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:19:52.173 | INFO     | __main__:train:119 - Train Accuracies: All 0.7321 | Old 0.7996 | New 0.6987
2023-11-10 11:20:01.608 | INFO     | __main__:train:108 - Epoch: [59][0/63]	 loss 4.09529	 cls_loss: 0.2406 cluster_loss: 1.2673 sup_con_loss: 0.5905 contrastive_loss: 4.5856 
2023-11-10 11:20:20.623 | INFO     | __main__:train:108 - Epoch: [59][10/63]	 loss 4.21057	 cls_loss: 0.2497 cluster_loss: 1.3963 sup_con_loss: 0.6619 contrastive_loss: 4.5906 
2023-11-10 11:20:39.320 | INFO     | __main__:train:108 - Epoch: [59][20/63]	 loss 4.15909	 cls_loss: 0.2593 cluster_loss: 1.2913 sup_con_loss: 0.7079 contrastive_loss: 4.5865 
2023-11-10 11:20:58.070 | INFO     | __main__:train:108 - Epoch: [59][30/63]	 loss 4.28934	 cls_loss: 0.2138 cluster_loss: 1.4039 sup_con_loss: 0.9076 contrastive_loss: 4.5912 
2023-11-10 11:21:16.821 | INFO     | __main__:train:108 - Epoch: [59][40/63]	 loss 4.05859	 cls_loss: 0.2310 cluster_loss: 1.2116 sup_con_loss: 0.6082 contrastive_loss: 4.5805 
2023-11-10 11:21:35.574 | INFO     | __main__:train:108 - Epoch: [59][50/63]	 loss 4.08471	 cls_loss: 0.2151 cluster_loss: 1.2721 sup_con_loss: 0.5813 contrastive_loss: 4.5832 
2023-11-10 11:21:54.218 | INFO     | __main__:train:108 - Epoch: [59][60/63]	 loss 4.08521	 cls_loss: 0.2508 cluster_loss: 1.3172 sup_con_loss: 0.4610 contrastive_loss: 4.5845 
2023-11-10 11:21:57.983 | INFO     | __main__:train:111 - Train Epoch: 59 Avg Loss: 4.1201 
2023-11-10 11:21:57.983 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:22:48.450 | INFO     | __main__:train:119 - Train Accuracies: All 0.7370 | Old 0.8011 | New 0.7053
2023-11-10 11:22:57.730 | INFO     | __main__:train:108 - Epoch: [60][0/63]	 loss 3.99187	 cls_loss: 0.2338 cluster_loss: 1.2435 sup_con_loss: 0.3252 contrastive_loss: 4.5969 
2023-11-10 11:23:16.898 | INFO     | __main__:train:108 - Epoch: [60][10/63]	 loss 4.13731	 cls_loss: 0.2365 cluster_loss: 1.3607 sup_con_loss: 0.5302 contrastive_loss: 4.5916 
2023-11-10 11:23:35.608 | INFO     | __main__:train:108 - Epoch: [60][20/63]	 loss 4.10349	 cls_loss: 0.2150 cluster_loss: 1.3219 sup_con_loss: 0.5304 contrastive_loss: 4.5898 
2023-11-10 11:23:54.378 | INFO     | __main__:train:108 - Epoch: [60][30/63]	 loss 4.03610	 cls_loss: 0.2250 cluster_loss: 1.2258 sup_con_loss: 0.5167 contrastive_loss: 4.5841 
2023-11-10 11:24:13.103 | INFO     | __main__:train:108 - Epoch: [60][40/63]	 loss 4.05402	 cls_loss: 0.2299 cluster_loss: 1.2458 sup_con_loss: 0.5069 contrastive_loss: 4.5944 
2023-11-10 11:24:31.778 | INFO     | __main__:train:108 - Epoch: [60][50/63]	 loss 4.04955	 cls_loss: 0.2271 cluster_loss: 1.2691 sup_con_loss: 0.4627 contrastive_loss: 4.5896 
2023-11-10 11:24:50.360 | INFO     | __main__:train:108 - Epoch: [60][60/63]	 loss 4.12982	 cls_loss: 0.2116 cluster_loss: 1.2707 sup_con_loss: 0.7176 contrastive_loss: 4.5825 
2023-11-10 11:24:54.164 | INFO     | __main__:train:111 - Train Epoch: 60 Avg Loss: 4.1161 
2023-11-10 11:24:54.164 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:25:45.548 | INFO     | __main__:train:119 - Train Accuracies: All 0.7323 | Old 0.7976 | New 0.6999
2023-11-10 11:25:55.728 | INFO     | __main__:train:108 - Epoch: [61][0/63]	 loss 4.19272	 cls_loss: 0.2218 cluster_loss: 1.3612 sup_con_loss: 0.7127 contrastive_loss: 4.5859 
2023-11-10 11:26:14.731 | INFO     | __main__:train:108 - Epoch: [61][10/63]	 loss 4.06808	 cls_loss: 0.2391 cluster_loss: 1.2931 sup_con_loss: 0.4466 contrastive_loss: 4.5962 
2023-11-10 11:26:33.496 | INFO     | __main__:train:108 - Epoch: [61][20/63]	 loss 4.25223	 cls_loss: 0.2447 cluster_loss: 1.4198 sup_con_loss: 0.7385 contrastive_loss: 4.5926 
2023-11-10 11:26:52.241 | INFO     | __main__:train:108 - Epoch: [61][30/63]	 loss 4.03196	 cls_loss: 0.2271 cluster_loss: 1.2470 sup_con_loss: 0.4516 contrastive_loss: 4.5905 
2023-11-10 11:27:11.015 | INFO     | __main__:train:108 - Epoch: [61][40/63]	 loss 4.25338	 cls_loss: 0.2401 cluster_loss: 1.3574 sup_con_loss: 0.8646 contrastive_loss: 4.5914 
2023-11-10 11:27:29.713 | INFO     | __main__:train:108 - Epoch: [61][50/63]	 loss 4.09348	 cls_loss: 0.1938 cluster_loss: 1.2964 sup_con_loss: 0.5671 contrastive_loss: 4.5915 
2023-11-10 11:27:48.341 | INFO     | __main__:train:108 - Epoch: [61][60/63]	 loss 4.16071	 cls_loss: 0.2456 cluster_loss: 1.3300 sup_con_loss: 0.6298 contrastive_loss: 4.5997 
2023-11-10 11:27:52.105 | INFO     | __main__:train:111 - Train Epoch: 61 Avg Loss: 4.1368 
2023-11-10 11:27:52.105 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:28:42.727 | INFO     | __main__:train:119 - Train Accuracies: All 0.7411 | Old 0.7996 | New 0.7121
2023-11-10 11:28:51.910 | INFO     | __main__:train:108 - Epoch: [62][0/63]	 loss 4.12865	 cls_loss: 0.2400 cluster_loss: 1.3270 sup_con_loss: 0.5589 contrastive_loss: 4.5946 
2023-11-10 11:29:10.918 | INFO     | __main__:train:108 - Epoch: [62][10/63]	 loss 4.10005	 cls_loss: 0.2547 cluster_loss: 1.2505 sup_con_loss: 0.6144 contrastive_loss: 4.5893 
2023-11-10 11:29:29.616 | INFO     | __main__:train:108 - Epoch: [62][20/63]	 loss 4.07203	 cls_loss: 0.2268 cluster_loss: 1.2602 sup_con_loss: 0.5578 contrastive_loss: 4.5820 
2023-11-10 11:29:48.350 | INFO     | __main__:train:108 - Epoch: [62][30/63]	 loss 4.19222	 cls_loss: 0.2262 cluster_loss: 1.3521 sup_con_loss: 0.7172 contrastive_loss: 4.5895 
2023-11-10 11:30:07.063 | INFO     | __main__:train:108 - Epoch: [62][40/63]	 loss 4.14950	 cls_loss: 0.2463 cluster_loss: 1.3153 sup_con_loss: 0.6468 contrastive_loss: 4.5876 
2023-11-10 11:30:25.763 | INFO     | __main__:train:108 - Epoch: [62][50/63]	 loss 3.97062	 cls_loss: 0.2370 cluster_loss: 1.1913 sup_con_loss: 0.3890 contrastive_loss: 4.5803 
2023-11-10 11:30:44.402 | INFO     | __main__:train:108 - Epoch: [62][60/63]	 loss 4.12535	 cls_loss: 0.2568 cluster_loss: 1.3072 sup_con_loss: 0.5728 contrastive_loss: 4.5928 
2023-11-10 11:30:48.169 | INFO     | __main__:train:111 - Train Epoch: 62 Avg Loss: 4.1326 
2023-11-10 11:30:48.169 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:31:38.118 | INFO     | __main__:train:119 - Train Accuracies: All 0.7324 | Old 0.8040 | New 0.6970
2023-11-10 11:31:47.434 | INFO     | __main__:train:108 - Epoch: [63][0/63]	 loss 4.06354	 cls_loss: 0.2257 cluster_loss: 1.2695 sup_con_loss: 0.5009 contrastive_loss: 4.5908 
2023-11-10 11:32:06.536 | INFO     | __main__:train:108 - Epoch: [63][10/63]	 loss 4.17377	 cls_loss: 0.2135 cluster_loss: 1.3964 sup_con_loss: 0.6066 contrastive_loss: 4.5832 
2023-11-10 11:32:25.226 | INFO     | __main__:train:108 - Epoch: [63][20/63]	 loss 4.11077	 cls_loss: 0.2403 cluster_loss: 1.2758 sup_con_loss: 0.6254 contrastive_loss: 4.5824 
2023-11-10 11:32:43.973 | INFO     | __main__:train:108 - Epoch: [63][30/63]	 loss 4.01303	 cls_loss: 0.2443 cluster_loss: 1.1961 sup_con_loss: 0.4920 contrastive_loss: 4.5813 
2023-11-10 11:33:02.660 | INFO     | __main__:train:108 - Epoch: [63][40/63]	 loss 4.18032	 cls_loss: 0.2127 cluster_loss: 1.3085 sup_con_loss: 0.7885 contrastive_loss: 4.5837 
2023-11-10 11:33:21.356 | INFO     | __main__:train:108 - Epoch: [63][50/63]	 loss 4.10297	 cls_loss: 0.2328 cluster_loss: 1.3076 sup_con_loss: 0.5398 contrastive_loss: 4.5887 
2023-11-10 11:33:39.935 | INFO     | __main__:train:108 - Epoch: [63][60/63]	 loss 4.05266	 cls_loss: 0.2223 cluster_loss: 1.2871 sup_con_loss: 0.4564 contrastive_loss: 4.5824 
2023-11-10 11:33:43.705 | INFO     | __main__:train:111 - Train Epoch: 63 Avg Loss: 4.1206 
2023-11-10 11:33:43.705 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:34:34.078 | INFO     | __main__:train:119 - Train Accuracies: All 0.7360 | Old 0.7986 | New 0.7050
2023-11-10 11:34:45.429 | INFO     | __main__:train:108 - Epoch: [64][0/63]	 loss 4.32420	 cls_loss: 0.2396 cluster_loss: 1.4798 sup_con_loss: 0.8480 contrastive_loss: 4.5872 
2023-11-10 11:35:04.337 | INFO     | __main__:train:108 - Epoch: [64][10/63]	 loss 4.18904	 cls_loss: 0.2408 cluster_loss: 1.3609 sup_con_loss: 0.6836 contrastive_loss: 4.5860 
2023-11-10 11:35:23.003 | INFO     | __main__:train:108 - Epoch: [64][20/63]	 loss 3.99731	 cls_loss: 0.2742 cluster_loss: 1.1518 sup_con_loss: 0.5089 contrastive_loss: 4.5762 
2023-11-10 11:35:41.763 | INFO     | __main__:train:108 - Epoch: [64][30/63]	 loss 4.12639	 cls_loss: 0.2564 cluster_loss: 1.3130 sup_con_loss: 0.5756 contrastive_loss: 4.5873 
2023-11-10 11:36:00.528 | INFO     | __main__:train:108 - Epoch: [64][40/63]	 loss 4.35980	 cls_loss: 0.2195 cluster_loss: 1.4905 sup_con_loss: 0.9346 contrastive_loss: 4.5955 
2023-11-10 11:36:19.219 | INFO     | __main__:train:108 - Epoch: [64][50/63]	 loss 4.13968	 cls_loss: 0.2363 cluster_loss: 1.2923 sup_con_loss: 0.6735 contrastive_loss: 4.5866 
2023-11-10 11:36:37.772 | INFO     | __main__:train:108 - Epoch: [64][60/63]	 loss 4.19114	 cls_loss: 0.2342 cluster_loss: 1.3921 sup_con_loss: 0.6248 contrastive_loss: 4.5933 
2023-11-10 11:36:41.496 | INFO     | __main__:train:111 - Train Epoch: 64 Avg Loss: 4.1377 
2023-11-10 11:36:41.496 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:37:32.077 | INFO     | __main__:train:119 - Train Accuracies: All 0.7396 | Old 0.7981 | New 0.7107
2023-11-10 11:37:42.282 | INFO     | __main__:train:108 - Epoch: [65][0/63]	 loss 4.05985	 cls_loss: 0.2608 cluster_loss: 1.2627 sup_con_loss: 0.4759 contrastive_loss: 4.5866 
2023-11-10 11:38:01.429 | INFO     | __main__:train:108 - Epoch: [65][10/63]	 loss 4.20104	 cls_loss: 0.2513 cluster_loss: 1.3777 sup_con_loss: 0.6612 contrastive_loss: 4.5941 
2023-11-10 11:38:20.179 | INFO     | __main__:train:108 - Epoch: [65][20/63]	 loss 4.01307	 cls_loss: 0.2418 cluster_loss: 1.1858 sup_con_loss: 0.5161 contrastive_loss: 4.5800 
2023-11-10 11:38:38.913 | INFO     | __main__:train:108 - Epoch: [65][30/63]	 loss 4.05340	 cls_loss: 0.2435 cluster_loss: 1.2381 sup_con_loss: 0.5238 contrastive_loss: 4.5848 
2023-11-10 11:38:57.668 | INFO     | __main__:train:108 - Epoch: [65][40/63]	 loss 3.97472	 cls_loss: 0.2239 cluster_loss: 1.1711 sup_con_loss: 0.4469 contrastive_loss: 4.5827 
2023-11-10 11:39:16.369 | INFO     | __main__:train:108 - Epoch: [65][50/63]	 loss 4.17947	 cls_loss: 0.2453 cluster_loss: 1.3273 sup_con_loss: 0.6943 contrastive_loss: 4.5967 
2023-11-10 11:39:34.934 | INFO     | __main__:train:108 - Epoch: [65][60/63]	 loss 4.23079	 cls_loss: 0.2358 cluster_loss: 1.3623 sup_con_loss: 0.7975 contrastive_loss: 4.5902 
2023-11-10 11:39:38.727 | INFO     | __main__:train:111 - Train Epoch: 65 Avg Loss: 4.1346 
2023-11-10 11:39:38.728 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:40:29.836 | INFO     | __main__:train:119 - Train Accuracies: All 0.7362 | Old 0.7937 | New 0.7077
2023-11-10 11:40:41.235 | INFO     | __main__:train:108 - Epoch: [66][0/63]	 loss 4.01494	 cls_loss: 0.2052 cluster_loss: 1.1830 sup_con_loss: 0.5650 contrastive_loss: 4.5790 
2023-11-10 11:41:00.173 | INFO     | __main__:train:108 - Epoch: [66][10/63]	 loss 4.05625	 cls_loss: 0.2212 cluster_loss: 1.2320 sup_con_loss: 0.5733 contrastive_loss: 4.5806 
2023-11-10 11:41:18.899 | INFO     | __main__:train:108 - Epoch: [66][20/63]	 loss 4.07560	 cls_loss: 0.2589 cluster_loss: 1.2602 sup_con_loss: 0.5222 contrastive_loss: 4.5893 
2023-11-10 11:41:37.686 | INFO     | __main__:train:108 - Epoch: [66][30/63]	 loss 3.99219	 cls_loss: 0.2185 cluster_loss: 1.1783 sup_con_loss: 0.4893 contrastive_loss: 4.5824 
2023-11-10 11:41:56.471 | INFO     | __main__:train:108 - Epoch: [66][40/63]	 loss 4.20177	 cls_loss: 0.2272 cluster_loss: 1.3467 sup_con_loss: 0.7620 contrastive_loss: 4.5849 
2023-11-10 11:42:15.187 | INFO     | __main__:train:108 - Epoch: [66][50/63]	 loss 4.20422	 cls_loss: 0.2340 cluster_loss: 1.3203 sup_con_loss: 0.7972 contrastive_loss: 4.5925 
2023-11-10 11:42:33.813 | INFO     | __main__:train:108 - Epoch: [66][60/63]	 loss 4.05296	 cls_loss: 0.2148 cluster_loss: 1.2161 sup_con_loss: 0.6058 contrastive_loss: 4.5774 
2023-11-10 11:42:37.553 | INFO     | __main__:train:111 - Train Epoch: 66 Avg Loss: 4.1103 
2023-11-10 11:42:37.553 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:43:28.004 | INFO     | __main__:train:119 - Train Accuracies: All 0.7411 | Old 0.8001 | New 0.7119
2023-11-10 11:43:38.161 | INFO     | __main__:train:108 - Epoch: [67][0/63]	 loss 4.12238	 cls_loss: 0.2334 cluster_loss: 1.2711 sup_con_loss: 0.6737 contrastive_loss: 4.5826 
2023-11-10 11:43:57.219 | INFO     | __main__:train:108 - Epoch: [67][10/63]	 loss 4.06950	 cls_loss: 0.2609 cluster_loss: 1.2077 sup_con_loss: 0.6096 contrastive_loss: 4.5843 
2023-11-10 11:44:15.991 | INFO     | __main__:train:108 - Epoch: [67][20/63]	 loss 4.05824	 cls_loss: 0.2353 cluster_loss: 1.2068 sup_con_loss: 0.6118 contrastive_loss: 4.5805 
2023-11-10 11:44:34.749 | INFO     | __main__:train:108 - Epoch: [67][30/63]	 loss 4.09576	 cls_loss: 0.2408 cluster_loss: 1.2451 sup_con_loss: 0.6318 contrastive_loss: 4.5862 
2023-11-10 11:44:53.530 | INFO     | __main__:train:108 - Epoch: [67][40/63]	 loss 4.31031	 cls_loss: 0.2276 cluster_loss: 1.5172 sup_con_loss: 0.7306 contrastive_loss: 4.5981 
2023-11-10 11:45:12.299 | INFO     | __main__:train:108 - Epoch: [67][50/63]	 loss 4.07867	 cls_loss: 0.2277 cluster_loss: 1.2793 sup_con_loss: 0.5399 contrastive_loss: 4.5823 
2023-11-10 11:45:30.967 | INFO     | __main__:train:108 - Epoch: [67][60/63]	 loss 4.13101	 cls_loss: 0.2445 cluster_loss: 1.2686 sup_con_loss: 0.6916 contrastive_loss: 4.5828 
2023-11-10 11:45:34.741 | INFO     | __main__:train:111 - Train Epoch: 67 Avg Loss: 4.1036 
2023-11-10 11:45:34.742 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:46:25.030 | INFO     | __main__:train:119 - Train Accuracies: All 0.7364 | Old 0.7912 | New 0.7092
2023-11-10 11:46:33.838 | INFO     | __main__:train:108 - Epoch: [68][0/63]	 loss 4.08535	 cls_loss: 0.2613 cluster_loss: 1.2636 sup_con_loss: 0.5439 contrastive_loss: 4.5880 
2023-11-10 11:46:53.097 | INFO     | __main__:train:108 - Epoch: [68][10/63]	 loss 4.18062	 cls_loss: 0.2166 cluster_loss: 1.4182 sup_con_loss: 0.5601 contrastive_loss: 4.5953 
2023-11-10 11:47:11.774 | INFO     | __main__:train:108 - Epoch: [68][20/63]	 loss 4.08522	 cls_loss: 0.2407 cluster_loss: 1.2765 sup_con_loss: 0.5418 contrastive_loss: 4.5871 
2023-11-10 11:47:30.511 | INFO     | __main__:train:108 - Epoch: [68][30/63]	 loss 4.10153	 cls_loss: 0.2276 cluster_loss: 1.2948 sup_con_loss: 0.5773 contrastive_loss: 4.5819 
2023-11-10 11:47:49.248 | INFO     | __main__:train:108 - Epoch: [68][40/63]	 loss 4.20589	 cls_loss: 0.2217 cluster_loss: 1.3333 sup_con_loss: 0.8144 contrastive_loss: 4.5794 
2023-11-10 11:48:08.016 | INFO     | __main__:train:108 - Epoch: [68][50/63]	 loss 4.12311	 cls_loss: 0.2383 cluster_loss: 1.2537 sup_con_loss: 0.7013 contrastive_loss: 4.5835 
2023-11-10 11:48:26.696 | INFO     | __main__:train:108 - Epoch: [68][60/63]	 loss 4.04118	 cls_loss: 0.2640 cluster_loss: 1.2400 sup_con_loss: 0.4609 contrastive_loss: 4.5869 
2023-11-10 11:48:30.450 | INFO     | __main__:train:111 - Train Epoch: 68 Avg Loss: 4.1081 
2023-11-10 11:48:30.451 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:49:21.505 | INFO     | __main__:train:119 - Train Accuracies: All 0.7408 | Old 0.7912 | New 0.7158
2023-11-10 11:49:30.672 | INFO     | __main__:train:108 - Epoch: [69][0/63]	 loss 4.13655	 cls_loss: 0.2270 cluster_loss: 1.2917 sup_con_loss: 0.6895 contrastive_loss: 4.5787 
2023-11-10 11:49:49.687 | INFO     | __main__:train:108 - Epoch: [69][10/63]	 loss 3.99138	 cls_loss: 0.2607 cluster_loss: 1.1514 sup_con_loss: 0.4961 contrastive_loss: 4.5817 
2023-11-10 11:50:08.441 | INFO     | __main__:train:108 - Epoch: [69][20/63]	 loss 4.02763	 cls_loss: 0.2191 cluster_loss: 1.2738 sup_con_loss: 0.4112 contrastive_loss: 4.5832 
2023-11-10 11:50:27.192 | INFO     | __main__:train:108 - Epoch: [69][30/63]	 loss 4.14033	 cls_loss: 0.2437 cluster_loss: 1.2819 sup_con_loss: 0.6903 contrastive_loss: 4.5850 
2023-11-10 11:50:45.919 | INFO     | __main__:train:108 - Epoch: [69][40/63]	 loss 4.00250	 cls_loss: 0.2384 cluster_loss: 1.1757 sup_con_loss: 0.5075 contrastive_loss: 4.5803 
2023-11-10 11:51:04.665 | INFO     | __main__:train:108 - Epoch: [69][50/63]	 loss 4.16015	 cls_loss: 0.2095 cluster_loss: 1.3451 sup_con_loss: 0.6631 contrastive_loss: 4.5853 
2023-11-10 11:51:23.327 | INFO     | __main__:train:108 - Epoch: [69][60/63]	 loss 4.07058	 cls_loss: 0.2262 cluster_loss: 1.2767 sup_con_loss: 0.5282 contrastive_loss: 4.5795 
2023-11-10 11:51:27.124 | INFO     | __main__:train:111 - Train Epoch: 69 Avg Loss: 4.1082 
2023-11-10 11:51:27.124 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:52:18.558 | INFO     | __main__:train:119 - Train Accuracies: All 0.7435 | Old 0.7947 | New 0.7182
2023-11-10 11:52:29.769 | INFO     | __main__:train:108 - Epoch: [70][0/63]	 loss 4.27618	 cls_loss: 0.2363 cluster_loss: 1.3544 sup_con_loss: 0.9559 contrastive_loss: 4.5825 
2023-11-10 11:52:48.760 | INFO     | __main__:train:108 - Epoch: [70][10/63]	 loss 4.07061	 cls_loss: 0.2490 cluster_loss: 1.2472 sup_con_loss: 0.5452 contrastive_loss: 4.5876 
2023-11-10 11:53:07.543 | INFO     | __main__:train:108 - Epoch: [70][20/63]	 loss 3.99616	 cls_loss: 0.2180 cluster_loss: 1.1856 sup_con_loss: 0.4928 contrastive_loss: 4.5796 
2023-11-10 11:53:26.307 | INFO     | __main__:train:108 - Epoch: [70][30/63]	 loss 4.10348	 cls_loss: 0.2330 cluster_loss: 1.2538 sup_con_loss: 0.6612 contrastive_loss: 4.5777 
2023-11-10 11:53:45.099 | INFO     | __main__:train:108 - Epoch: [70][40/63]	 loss 4.25032	 cls_loss: 0.2188 cluster_loss: 1.4001 sup_con_loss: 0.8058 contrastive_loss: 4.5871 
2023-11-10 11:54:03.874 | INFO     | __main__:train:108 - Epoch: [70][50/63]	 loss 4.10936	 cls_loss: 0.2119 cluster_loss: 1.2461 sup_con_loss: 0.7092 contrastive_loss: 4.5800 
2023-11-10 11:54:22.511 | INFO     | __main__:train:108 - Epoch: [70][60/63]	 loss 3.96122	 cls_loss: 0.2032 cluster_loss: 1.2302 sup_con_loss: 0.3274 contrastive_loss: 4.5782 
2023-11-10 11:54:26.273 | INFO     | __main__:train:111 - Train Epoch: 70 Avg Loss: 4.1165 
2023-11-10 11:54:26.273 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:55:17.480 | INFO     | __main__:train:119 - Train Accuracies: All 0.7411 | Old 0.7927 | New 0.7155
2023-11-10 11:55:27.622 | INFO     | __main__:train:108 - Epoch: [71][0/63]	 loss 4.20517	 cls_loss: 0.2523 cluster_loss: 1.3723 sup_con_loss: 0.6755 contrastive_loss: 4.5976 
2023-11-10 11:55:46.870 | INFO     | __main__:train:108 - Epoch: [71][10/63]	 loss 4.10274	 cls_loss: 0.2861 cluster_loss: 1.2396 sup_con_loss: 0.6299 contrastive_loss: 4.5791 
2023-11-10 11:56:05.682 | INFO     | __main__:train:108 - Epoch: [71][20/63]	 loss 4.12322	 cls_loss: 0.2226 cluster_loss: 1.2732 sup_con_loss: 0.6755 contrastive_loss: 4.5866 
2023-11-10 11:56:24.446 | INFO     | __main__:train:108 - Epoch: [71][30/63]	 loss 4.09730	 cls_loss: 0.2282 cluster_loss: 1.2293 sup_con_loss: 0.6954 contrastive_loss: 4.5769 
2023-11-10 11:56:43.252 | INFO     | __main__:train:108 - Epoch: [71][40/63]	 loss 4.05831	 cls_loss: 0.2267 cluster_loss: 1.2323 sup_con_loss: 0.5705 contrastive_loss: 4.5820 
2023-11-10 11:57:02.035 | INFO     | __main__:train:108 - Epoch: [71][50/63]	 loss 4.14358	 cls_loss: 0.2164 cluster_loss: 1.3018 sup_con_loss: 0.6912 contrastive_loss: 4.5842 
2023-11-10 11:57:20.683 | INFO     | __main__:train:108 - Epoch: [71][60/63]	 loss 4.11616	 cls_loss: 0.2138 cluster_loss: 1.2712 sup_con_loss: 0.6710 contrastive_loss: 4.5849 
2023-11-10 11:57:24.433 | INFO     | __main__:train:111 - Train Epoch: 71 Avg Loss: 4.1132 
2023-11-10 11:57:24.434 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 11:58:15.358 | INFO     | __main__:train:119 - Train Accuracies: All 0.7455 | Old 0.7912 | New 0.7229
2023-11-10 11:58:26.496 | INFO     | __main__:train:108 - Epoch: [72][0/63]	 loss 4.06777	 cls_loss: 0.2196 cluster_loss: 1.2909 sup_con_loss: 0.4961 contrastive_loss: 4.5818 
2023-11-10 11:58:45.501 | INFO     | __main__:train:108 - Epoch: [72][10/63]	 loss 4.14503	 cls_loss: 0.2042 cluster_loss: 1.3288 sup_con_loss: 0.6441 contrastive_loss: 4.5914 
2023-11-10 11:59:04.337 | INFO     | __main__:train:108 - Epoch: [72][20/63]	 loss 4.02268	 cls_loss: 0.2484 cluster_loss: 1.1901 sup_con_loss: 0.5275 contrastive_loss: 4.5808 
2023-11-10 11:59:23.148 | INFO     | __main__:train:108 - Epoch: [72][30/63]	 loss 4.07530	 cls_loss: 0.2264 cluster_loss: 1.2726 sup_con_loss: 0.5375 contrastive_loss: 4.5857 
2023-11-10 11:59:42.021 | INFO     | __main__:train:108 - Epoch: [72][40/63]	 loss 4.17175	 cls_loss: 0.2632 cluster_loss: 1.2951 sup_con_loss: 0.7420 contrastive_loss: 4.5818 
2023-11-10 12:00:00.875 | INFO     | __main__:train:108 - Epoch: [72][50/63]	 loss 4.10713	 cls_loss: 0.2463 cluster_loss: 1.3176 sup_con_loss: 0.5282 contrastive_loss: 4.5840 
2023-11-10 12:00:19.586 | INFO     | __main__:train:108 - Epoch: [72][60/63]	 loss 4.09741	 cls_loss: 0.2285 cluster_loss: 1.2430 sup_con_loss: 0.6634 contrastive_loss: 4.5804 
2023-11-10 12:00:23.391 | INFO     | __main__:train:111 - Train Epoch: 72 Avg Loss: 4.0951 
2023-11-10 12:00:23.392 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:01:13.629 | INFO     | __main__:train:119 - Train Accuracies: All 0.7450 | Old 0.7947 | New 0.7204
2023-11-10 12:01:23.618 | INFO     | __main__:train:108 - Epoch: [73][0/63]	 loss 4.10357	 cls_loss: 0.2035 cluster_loss: 1.2822 sup_con_loss: 0.6383 contrastive_loss: 4.5777 
2023-11-10 12:01:42.644 | INFO     | __main__:train:108 - Epoch: [73][10/63]	 loss 4.17116	 cls_loss: 0.2714 cluster_loss: 1.3615 sup_con_loss: 0.5800 contrastive_loss: 4.5973 
2023-11-10 12:02:01.439 | INFO     | __main__:train:108 - Epoch: [73][20/63]	 loss 4.15502	 cls_loss: 0.2127 cluster_loss: 1.3246 sup_con_loss: 0.6905 contrastive_loss: 4.5813 
2023-11-10 12:02:20.313 | INFO     | __main__:train:108 - Epoch: [73][30/63]	 loss 4.09068	 cls_loss: 0.2024 cluster_loss: 1.2609 sup_con_loss: 0.6426 contrastive_loss: 4.5774 
2023-11-10 12:02:39.157 | INFO     | __main__:train:108 - Epoch: [73][40/63]	 loss 4.03490	 cls_loss: 0.2388 cluster_loss: 1.2341 sup_con_loss: 0.4877 contrastive_loss: 4.5822 
2023-11-10 12:02:57.924 | INFO     | __main__:train:108 - Epoch: [73][50/63]	 loss 4.08584	 cls_loss: 0.2213 cluster_loss: 1.2827 sup_con_loss: 0.5511 contrastive_loss: 4.5873 
2023-11-10 12:03:16.575 | INFO     | __main__:train:108 - Epoch: [73][60/63]	 loss 4.05168	 cls_loss: 0.2490 cluster_loss: 1.1976 sup_con_loss: 0.6065 contrastive_loss: 4.5751 
2023-11-10 12:03:20.354 | INFO     | __main__:train:111 - Train Epoch: 73 Avg Loss: 4.1114 
2023-11-10 12:03:20.354 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:04:11.254 | INFO     | __main__:train:119 - Train Accuracies: All 0.7413 | Old 0.7887 | New 0.7177
2023-11-10 12:04:20.715 | INFO     | __main__:train:108 - Epoch: [74][0/63]	 loss 4.23217	 cls_loss: 0.2726 cluster_loss: 1.3627 sup_con_loss: 0.7708 contrastive_loss: 4.5865 
2023-11-10 12:04:39.791 | INFO     | __main__:train:108 - Epoch: [74][10/63]	 loss 4.07829	 cls_loss: 0.2560 cluster_loss: 1.2578 sup_con_loss: 0.5461 contrastive_loss: 4.5846 
2023-11-10 12:04:58.506 | INFO     | __main__:train:108 - Epoch: [74][20/63]	 loss 4.10587	 cls_loss: 0.2225 cluster_loss: 1.2095 sup_con_loss: 0.7540 contrastive_loss: 4.5814 
2023-11-10 12:05:17.288 | INFO     | __main__:train:108 - Epoch: [74][30/63]	 loss 3.99722	 cls_loss: 0.2281 cluster_loss: 1.1674 sup_con_loss: 0.5273 contrastive_loss: 4.5754 
2023-11-10 12:05:36.101 | INFO     | __main__:train:108 - Epoch: [74][40/63]	 loss 4.06534	 cls_loss: 0.2494 cluster_loss: 1.1945 sup_con_loss: 0.6422 contrastive_loss: 4.5798 
2023-11-10 12:05:54.846 | INFO     | __main__:train:108 - Epoch: [74][50/63]	 loss 4.15161	 cls_loss: 0.2162 cluster_loss: 1.3233 sup_con_loss: 0.6749 contrastive_loss: 4.5840 
2023-11-10 12:06:13.490 | INFO     | __main__:train:108 - Epoch: [74][60/63]	 loss 4.06185	 cls_loss: 0.2036 cluster_loss: 1.3004 sup_con_loss: 0.4796 contrastive_loss: 4.5807 
2023-11-10 12:06:17.298 | INFO     | __main__:train:111 - Train Epoch: 74 Avg Loss: 4.1070 
2023-11-10 12:06:17.298 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:07:07.707 | INFO     | __main__:train:119 - Train Accuracies: All 0.7380 | Old 0.7863 | New 0.7141
2023-11-10 12:07:18.273 | INFO     | __main__:train:108 - Epoch: [75][0/63]	 loss 4.03599	 cls_loss: 0.2221 cluster_loss: 1.1958 sup_con_loss: 0.5837 contrastive_loss: 4.5795 
2023-11-10 12:07:37.260 | INFO     | __main__:train:108 - Epoch: [75][10/63]	 loss 4.27685	 cls_loss: 0.2222 cluster_loss: 1.3802 sup_con_loss: 0.9225 contrastive_loss: 4.5832 
2023-11-10 12:07:56.061 | INFO     | __main__:train:108 - Epoch: [75][20/63]	 loss 4.09019	 cls_loss: 0.2333 cluster_loss: 1.3336 sup_con_loss: 0.4414 contrastive_loss: 4.5957 
2023-11-10 12:08:14.860 | INFO     | __main__:train:108 - Epoch: [75][30/63]	 loss 4.24519	 cls_loss: 0.2193 cluster_loss: 1.3882 sup_con_loss: 0.8095 contrastive_loss: 4.5889 
2023-11-10 12:08:33.688 | INFO     | __main__:train:108 - Epoch: [75][40/63]	 loss 3.93533	 cls_loss: 0.2050 cluster_loss: 1.1494 sup_con_loss: 0.3969 contrastive_loss: 4.5809 
2023-11-10 12:08:52.464 | INFO     | __main__:train:108 - Epoch: [75][50/63]	 loss 4.08428	 cls_loss: 0.2029 cluster_loss: 1.2374 sup_con_loss: 0.6635 contrastive_loss: 4.5795 
2023-11-10 12:09:11.074 | INFO     | __main__:train:108 - Epoch: [75][60/63]	 loss 4.12604	 cls_loss: 0.2135 cluster_loss: 1.3244 sup_con_loss: 0.6106 contrastive_loss: 4.5796 
2023-11-10 12:09:14.860 | INFO     | __main__:train:111 - Train Epoch: 75 Avg Loss: 4.1045 
2023-11-10 12:09:14.861 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:10:05.001 | INFO     | __main__:train:119 - Train Accuracies: All 0.7431 | Old 0.7897 | New 0.7199
2023-11-10 12:10:14.934 | INFO     | __main__:train:108 - Epoch: [76][0/63]	 loss 4.24034	 cls_loss: 0.2146 cluster_loss: 1.3593 sup_con_loss: 0.8768 contrastive_loss: 4.5766 
2023-11-10 12:10:34.158 | INFO     | __main__:train:108 - Epoch: [76][10/63]	 loss 4.10638	 cls_loss: 0.2450 cluster_loss: 1.2850 sup_con_loss: 0.5799 contrastive_loss: 4.5883 
2023-11-10 12:10:52.914 | INFO     | __main__:train:108 - Epoch: [76][20/63]	 loss 4.17193	 cls_loss: 0.2322 cluster_loss: 1.3310 sup_con_loss: 0.6957 contrastive_loss: 4.5877 
2023-11-10 12:11:11.648 | INFO     | __main__:train:108 - Epoch: [76][30/63]	 loss 4.04109	 cls_loss: 0.2285 cluster_loss: 1.1978 sup_con_loss: 0.5891 contrastive_loss: 4.5790 
2023-11-10 12:11:30.480 | INFO     | __main__:train:108 - Epoch: [76][40/63]	 loss 3.97401	 cls_loss: 0.2306 cluster_loss: 1.1699 sup_con_loss: 0.4429 contrastive_loss: 4.5814 
2023-11-10 12:11:49.210 | INFO     | __main__:train:108 - Epoch: [76][50/63]	 loss 4.16638	 cls_loss: 0.2452 cluster_loss: 1.2484 sup_con_loss: 0.8424 contrastive_loss: 4.5758 
2023-11-10 12:12:07.881 | INFO     | __main__:train:108 - Epoch: [76][60/63]	 loss 4.20866	 cls_loss: 0.2378 cluster_loss: 1.4145 sup_con_loss: 0.6287 contrastive_loss: 4.5939 
2023-11-10 12:12:11.681 | INFO     | __main__:train:111 - Train Epoch: 76 Avg Loss: 4.0865 
2023-11-10 12:12:11.681 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:13:02.633 | INFO     | __main__:train:119 - Train Accuracies: All 0.7406 | Old 0.7808 | New 0.7207
2023-11-10 12:13:11.544 | INFO     | __main__:train:108 - Epoch: [77][0/63]	 loss 4.06236	 cls_loss: 0.2585 cluster_loss: 1.2843 sup_con_loss: 0.4511 contrastive_loss: 4.5835 
2023-11-10 12:13:30.538 | INFO     | __main__:train:108 - Epoch: [77][10/63]	 loss 4.06959	 cls_loss: 0.2350 cluster_loss: 1.2153 sup_con_loss: 0.6127 contrastive_loss: 4.5892 
2023-11-10 12:13:49.279 | INFO     | __main__:train:108 - Epoch: [77][20/63]	 loss 4.00570	 cls_loss: 0.2270 cluster_loss: 1.2221 sup_con_loss: 0.4330 contrastive_loss: 4.5850 
2023-11-10 12:14:08.074 | INFO     | __main__:train:108 - Epoch: [77][30/63]	 loss 4.12910	 cls_loss: 0.2550 cluster_loss: 1.2536 sup_con_loss: 0.7082 contrastive_loss: 4.5802 
2023-11-10 12:14:26.899 | INFO     | __main__:train:108 - Epoch: [77][40/63]	 loss 4.09268	 cls_loss: 0.2166 cluster_loss: 1.2308 sup_con_loss: 0.6915 contrastive_loss: 4.5766 
2023-11-10 12:14:45.691 | INFO     | __main__:train:108 - Epoch: [77][50/63]	 loss 4.11157	 cls_loss: 0.2098 cluster_loss: 1.3339 sup_con_loss: 0.5580 contrastive_loss: 4.5782 
2023-11-10 12:15:04.325 | INFO     | __main__:train:108 - Epoch: [77][60/63]	 loss 4.05300	 cls_loss: 0.2102 cluster_loss: 1.2189 sup_con_loss: 0.5988 contrastive_loss: 4.5809 
2023-11-10 12:15:08.123 | INFO     | __main__:train:111 - Train Epoch: 77 Avg Loss: 4.1157 
2023-11-10 12:15:08.124 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:15:58.427 | INFO     | __main__:train:119 - Train Accuracies: All 0.7426 | Old 0.7971 | New 0.7155
2023-11-10 12:16:07.618 | INFO     | __main__:train:108 - Epoch: [78][0/63]	 loss 4.16919	 cls_loss: 0.2321 cluster_loss: 1.2869 sup_con_loss: 0.7841 contrastive_loss: 4.5801 
2023-11-10 12:16:26.849 | INFO     | __main__:train:108 - Epoch: [78][10/63]	 loss 4.29618	 cls_loss: 0.2189 cluster_loss: 1.4099 sup_con_loss: 0.9200 contrastive_loss: 4.5864 
2023-11-10 12:16:45.606 | INFO     | __main__:train:108 - Epoch: [78][20/63]	 loss 4.05643	 cls_loss: 0.2825 cluster_loss: 1.2087 sup_con_loss: 0.5540 contrastive_loss: 4.5815 
2023-11-10 12:17:04.409 | INFO     | __main__:train:108 - Epoch: [78][30/63]	 loss 4.00634	 cls_loss: 0.2292 cluster_loss: 1.2278 sup_con_loss: 0.4169 contrastive_loss: 4.5880 
2023-11-10 12:17:23.208 | INFO     | __main__:train:108 - Epoch: [78][40/63]	 loss 4.19035	 cls_loss: 0.2247 cluster_loss: 1.3216 sup_con_loss: 0.7924 contrastive_loss: 4.5774 
2023-11-10 12:17:41.953 | INFO     | __main__:train:108 - Epoch: [78][50/63]	 loss 4.15185	 cls_loss: 0.2263 cluster_loss: 1.2697 sup_con_loss: 0.7748 contrastive_loss: 4.5787 
2023-11-10 12:18:00.628 | INFO     | __main__:train:108 - Epoch: [78][60/63]	 loss 4.02857	 cls_loss: 0.2632 cluster_loss: 1.1778 sup_con_loss: 0.5486 contrastive_loss: 4.5829 
2023-11-10 12:18:04.405 | INFO     | __main__:train:111 - Train Epoch: 78 Avg Loss: 4.1003 
2023-11-10 12:18:04.406 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:18:55.512 | INFO     | __main__:train:119 - Train Accuracies: All 0.7465 | Old 0.7902 | New 0.7248
2023-11-10 12:19:05.861 | INFO     | __main__:train:108 - Epoch: [79][0/63]	 loss 4.17035	 cls_loss: 0.2352 cluster_loss: 1.2782 sup_con_loss: 0.7992 contrastive_loss: 4.5808 
2023-11-10 12:19:24.926 | INFO     | __main__:train:108 - Epoch: [79][10/63]	 loss 4.11348	 cls_loss: 0.2291 cluster_loss: 1.2774 sup_con_loss: 0.6436 contrastive_loss: 4.5811 
2023-11-10 12:19:43.667 | INFO     | __main__:train:108 - Epoch: [79][20/63]	 loss 4.01471	 cls_loss: 0.2373 cluster_loss: 1.1246 sup_con_loss: 0.6510 contrastive_loss: 4.5736 
2023-11-10 12:20:02.464 | INFO     | __main__:train:108 - Epoch: [79][30/63]	 loss 4.21930	 cls_loss: 0.2406 cluster_loss: 1.3010 sup_con_loss: 0.8935 contrastive_loss: 4.5795 
2023-11-10 12:20:21.290 | INFO     | __main__:train:108 - Epoch: [79][40/63]	 loss 4.05312	 cls_loss: 0.2326 cluster_loss: 1.2203 sup_con_loss: 0.5841 contrastive_loss: 4.5756 
2023-11-10 12:20:40.052 | INFO     | __main__:train:108 - Epoch: [79][50/63]	 loss 4.00912	 cls_loss: 0.2232 cluster_loss: 1.1692 sup_con_loss: 0.5641 contrastive_loss: 4.5748 
2023-11-10 12:20:58.722 | INFO     | __main__:train:108 - Epoch: [79][60/63]	 loss 4.10432	 cls_loss: 0.2322 cluster_loss: 1.2411 sup_con_loss: 0.6846 contrastive_loss: 4.5796 
2023-11-10 12:21:02.477 | INFO     | __main__:train:111 - Train Epoch: 79 Avg Loss: 4.0859 
2023-11-10 12:21:02.477 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:21:52.835 | INFO     | __main__:train:119 - Train Accuracies: All 0.7520 | Old 0.8001 | New 0.7283
2023-11-10 12:22:01.742 | INFO     | __main__:train:108 - Epoch: [80][0/63]	 loss 4.08953	 cls_loss: 0.2336 cluster_loss: 1.2318 sup_con_loss: 0.6415 contrastive_loss: 4.5885 
2023-11-10 12:22:21.741 | INFO     | __main__:train:108 - Epoch: [80][10/63]	 loss 4.05339	 cls_loss: 0.2395 cluster_loss: 1.2166 sup_con_loss: 0.5747 contrastive_loss: 4.5810 
2023-11-10 12:22:40.516 | INFO     | __main__:train:108 - Epoch: [80][20/63]	 loss 4.07534	 cls_loss: 0.2142 cluster_loss: 1.2437 sup_con_loss: 0.6184 contrastive_loss: 4.5777 
2023-11-10 12:22:59.248 | INFO     | __main__:train:108 - Epoch: [80][30/63]	 loss 4.07742	 cls_loss: 0.2349 cluster_loss: 1.2604 sup_con_loss: 0.5748 contrastive_loss: 4.5766 
2023-11-10 12:23:18.050 | INFO     | __main__:train:108 - Epoch: [80][40/63]	 loss 4.17176	 cls_loss: 0.2070 cluster_loss: 1.3274 sup_con_loss: 0.7412 contrastive_loss: 4.5802 
2023-11-10 12:23:36.793 | INFO     | __main__:train:108 - Epoch: [80][50/63]	 loss 4.07470	 cls_loss: 0.2121 cluster_loss: 1.3256 sup_con_loss: 0.4481 contrastive_loss: 4.5876 
2023-11-10 12:23:55.358 | INFO     | __main__:train:108 - Epoch: [80][60/63]	 loss 4.04018	 cls_loss: 0.2200 cluster_loss: 1.2150 sup_con_loss: 0.5668 contrastive_loss: 4.5770 
2023-11-10 12:23:59.111 | INFO     | __main__:train:111 - Train Epoch: 80 Avg Loss: 4.0924 
2023-11-10 12:23:59.112 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:24:49.863 | INFO     | __main__:train:119 - Train Accuracies: All 0.7493 | Old 0.8075 | New 0.7204
2023-11-10 12:25:00.054 | INFO     | __main__:train:108 - Epoch: [81][0/63]	 loss 3.99760	 cls_loss: 0.2118 cluster_loss: 1.2177 sup_con_loss: 0.4424 contrastive_loss: 4.5802 
2023-11-10 12:25:19.070 | INFO     | __main__:train:108 - Epoch: [81][10/63]	 loss 4.07609	 cls_loss: 0.2311 cluster_loss: 1.2479 sup_con_loss: 0.5940 contrastive_loss: 4.5786 
2023-11-10 12:25:37.808 | INFO     | __main__:train:108 - Epoch: [81][20/63]	 loss 4.09901	 cls_loss: 0.2036 cluster_loss: 1.2925 sup_con_loss: 0.6026 contrastive_loss: 4.5796 
2023-11-10 12:25:56.612 | INFO     | __main__:train:108 - Epoch: [81][30/63]	 loss 4.07685	 cls_loss: 0.2006 cluster_loss: 1.2827 sup_con_loss: 0.5605 contrastive_loss: 4.5795 
2023-11-10 12:26:15.392 | INFO     | __main__:train:108 - Epoch: [81][40/63]	 loss 4.02043	 cls_loss: 0.2189 cluster_loss: 1.1765 sup_con_loss: 0.5876 contrastive_loss: 4.5745 
2023-11-10 12:26:34.104 | INFO     | __main__:train:108 - Epoch: [81][50/63]	 loss 4.09071	 cls_loss: 0.2075 cluster_loss: 1.2355 sup_con_loss: 0.6919 contrastive_loss: 4.5736 
2023-11-10 12:26:52.762 | INFO     | __main__:train:108 - Epoch: [81][60/63]	 loss 4.11436	 cls_loss: 0.2222 cluster_loss: 1.2792 sup_con_loss: 0.6506 contrastive_loss: 4.5806 
2023-11-10 12:26:56.593 | INFO     | __main__:train:111 - Train Epoch: 81 Avg Loss: 4.0806 
2023-11-10 12:26:56.594 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:27:47.151 | INFO     | __main__:train:119 - Train Accuracies: All 0.7484 | Old 0.7917 | New 0.7270
2023-11-10 12:27:55.691 | INFO     | __main__:train:108 - Epoch: [82][0/63]	 loss 4.02775	 cls_loss: 0.2402 cluster_loss: 1.1847 sup_con_loss: 0.5637 contrastive_loss: 4.5790 
2023-11-10 12:28:15.899 | INFO     | __main__:train:108 - Epoch: [82][10/63]	 loss 3.91974	 cls_loss: 0.2241 cluster_loss: 1.1366 sup_con_loss: 0.3619 contrastive_loss: 4.5782 
2023-11-10 12:28:34.694 | INFO     | __main__:train:108 - Epoch: [82][20/63]	 loss 4.18420	 cls_loss: 0.2154 cluster_loss: 1.3506 sup_con_loss: 0.7104 contrastive_loss: 4.5882 
2023-11-10 12:28:53.512 | INFO     | __main__:train:108 - Epoch: [82][30/63]	 loss 4.03161	 cls_loss: 0.2269 cluster_loss: 1.1766 sup_con_loss: 0.5956 contrastive_loss: 4.5830 
2023-11-10 12:29:12.384 | INFO     | __main__:train:108 - Epoch: [82][40/63]	 loss 4.12346	 cls_loss: 0.2380 cluster_loss: 1.2387 sup_con_loss: 0.7420 contrastive_loss: 4.5774 
2023-11-10 12:29:31.163 | INFO     | __main__:train:108 - Epoch: [82][50/63]	 loss 4.15406	 cls_loss: 0.2196 cluster_loss: 1.3152 sup_con_loss: 0.7088 contrastive_loss: 4.5757 
2023-11-10 12:29:49.811 | INFO     | __main__:train:108 - Epoch: [82][60/63]	 loss 4.06079	 cls_loss: 0.2406 cluster_loss: 1.2024 sup_con_loss: 0.6159 contrastive_loss: 4.5837 
2023-11-10 12:29:53.622 | INFO     | __main__:train:111 - Train Epoch: 82 Avg Loss: 4.1003 
2023-11-10 12:29:53.623 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:30:44.151 | INFO     | __main__:train:119 - Train Accuracies: All 0.7484 | Old 0.7833 | New 0.7312
2023-11-10 12:30:53.733 | INFO     | __main__:train:108 - Epoch: [83][0/63]	 loss 4.12004	 cls_loss: 0.2875 cluster_loss: 1.2487 sup_con_loss: 0.6574 contrastive_loss: 4.5810 
2023-11-10 12:31:12.823 | INFO     | __main__:train:108 - Epoch: [83][10/63]	 loss 4.08674	 cls_loss: 0.2124 cluster_loss: 1.2669 sup_con_loss: 0.6062 contrastive_loss: 4.5796 
2023-11-10 12:31:31.642 | INFO     | __main__:train:108 - Epoch: [83][20/63]	 loss 3.98516	 cls_loss: 0.2200 cluster_loss: 1.1481 sup_con_loss: 0.5316 contrastive_loss: 4.5783 
2023-11-10 12:31:50.509 | INFO     | __main__:train:108 - Epoch: [83][30/63]	 loss 4.10637	 cls_loss: 0.2183 cluster_loss: 1.2606 sup_con_loss: 0.6694 contrastive_loss: 4.5789 
2023-11-10 12:32:09.369 | INFO     | __main__:train:108 - Epoch: [83][40/63]	 loss 4.11373	 cls_loss: 0.2109 cluster_loss: 1.2993 sup_con_loss: 0.6103 contrastive_loss: 4.5873 
2023-11-10 12:32:28.173 | INFO     | __main__:train:108 - Epoch: [83][50/63]	 loss 3.95244	 cls_loss: 0.2269 cluster_loss: 1.1915 sup_con_loss: 0.3394 contrastive_loss: 4.5843 
2023-11-10 12:32:46.869 | INFO     | __main__:train:108 - Epoch: [83][60/63]	 loss 3.99677	 cls_loss: 0.2025 cluster_loss: 1.2151 sup_con_loss: 0.4587 contrastive_loss: 4.5777 
2023-11-10 12:32:50.652 | INFO     | __main__:train:111 - Train Epoch: 83 Avg Loss: 4.0795 
2023-11-10 12:32:50.652 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:33:41.007 | INFO     | __main__:train:119 - Train Accuracies: All 0.7519 | Old 0.7991 | New 0.7285
2023-11-10 12:33:49.639 | INFO     | __main__:train:108 - Epoch: [84][0/63]	 loss 4.19842	 cls_loss: 0.2160 cluster_loss: 1.3283 sup_con_loss: 0.8116 contrastive_loss: 4.5776 
2023-11-10 12:34:08.904 | INFO     | __main__:train:108 - Epoch: [84][10/63]	 loss 4.10486	 cls_loss: 0.2482 cluster_loss: 1.2931 sup_con_loss: 0.5684 contrastive_loss: 4.5824 
2023-11-10 12:34:27.680 | INFO     | __main__:train:108 - Epoch: [84][20/63]	 loss 4.04409	 cls_loss: 0.2060 cluster_loss: 1.2060 sup_con_loss: 0.6131 contrastive_loss: 4.5746 
2023-11-10 12:34:46.471 | INFO     | __main__:train:108 - Epoch: [84][30/63]	 loss 3.99244	 cls_loss: 0.2467 cluster_loss: 1.1852 sup_con_loss: 0.4655 contrastive_loss: 4.5735 
2023-11-10 12:35:05.301 | INFO     | __main__:train:108 - Epoch: [84][40/63]	 loss 4.06306	 cls_loss: 0.2021 cluster_loss: 1.2606 sup_con_loss: 0.5666 contrastive_loss: 4.5764 
2023-11-10 12:35:24.064 | INFO     | __main__:train:108 - Epoch: [84][50/63]	 loss 3.96905	 cls_loss: 0.2100 cluster_loss: 1.1822 sup_con_loss: 0.4270 contrastive_loss: 4.5810 
2023-11-10 12:35:42.755 | INFO     | __main__:train:108 - Epoch: [84][60/63]	 loss 4.06333	 cls_loss: 0.2570 cluster_loss: 1.1928 sup_con_loss: 0.6479 contrastive_loss: 4.5712 
2023-11-10 12:35:46.544 | INFO     | __main__:train:111 - Train Epoch: 84 Avg Loss: 4.0838 
2023-11-10 12:35:46.545 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:36:37.296 | INFO     | __main__:train:119 - Train Accuracies: All 0.7458 | Old 0.8031 | New 0.7175
2023-11-10 12:36:47.199 | INFO     | __main__:train:108 - Epoch: [85][0/63]	 loss 4.16245	 cls_loss: 0.2384 cluster_loss: 1.2796 sup_con_loss: 0.7742 contrastive_loss: 4.5789 
2023-11-10 12:37:06.218 | INFO     | __main__:train:108 - Epoch: [85][10/63]	 loss 4.06885	 cls_loss: 0.2291 cluster_loss: 1.2675 sup_con_loss: 0.5133 contrastive_loss: 4.5925 
2023-11-10 12:37:24.962 | INFO     | __main__:train:108 - Epoch: [85][20/63]	 loss 4.07971	 cls_loss: 0.2019 cluster_loss: 1.2669 sup_con_loss: 0.5951 contrastive_loss: 4.5804 
2023-11-10 12:37:43.836 | INFO     | __main__:train:108 - Epoch: [85][30/63]	 loss 4.07046	 cls_loss: 0.2013 cluster_loss: 1.2131 sup_con_loss: 0.6719 contrastive_loss: 4.5790 
2023-11-10 12:38:02.699 | INFO     | __main__:train:108 - Epoch: [85][40/63]	 loss 4.11958	 cls_loss: 0.2338 cluster_loss: 1.2643 sup_con_loss: 0.6814 contrastive_loss: 4.5807 
2023-11-10 12:38:21.501 | INFO     | __main__:train:108 - Epoch: [85][50/63]	 loss 3.93984	 cls_loss: 0.2327 cluster_loss: 1.1448 sup_con_loss: 0.3994 contrastive_loss: 4.5762 
2023-11-10 12:38:40.159 | INFO     | __main__:train:108 - Epoch: [85][60/63]	 loss 4.13363	 cls_loss: 0.2034 cluster_loss: 1.2716 sup_con_loss: 0.7503 contrastive_loss: 4.5743 
2023-11-10 12:38:43.951 | INFO     | __main__:train:111 - Train Epoch: 85 Avg Loss: 4.0950 
2023-11-10 12:38:43.952 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:39:34.480 | INFO     | __main__:train:119 - Train Accuracies: All 0.7553 | Old 0.8040 | New 0.7312
2023-11-10 12:39:44.960 | INFO     | __main__:train:108 - Epoch: [86][0/63]	 loss 3.98753	 cls_loss: 0.2188 cluster_loss: 1.1873 sup_con_loss: 0.4697 contrastive_loss: 4.5767 
2023-11-10 12:40:04.020 | INFO     | __main__:train:108 - Epoch: [86][10/63]	 loss 4.08414	 cls_loss: 0.2212 cluster_loss: 1.2393 sup_con_loss: 0.6413 contrastive_loss: 4.5796 
2023-11-10 12:40:22.814 | INFO     | __main__:train:108 - Epoch: [86][20/63]	 loss 4.08192	 cls_loss: 0.2225 cluster_loss: 1.1943 sup_con_loss: 0.7242 contrastive_loss: 4.5758 
2023-11-10 12:40:41.647 | INFO     | __main__:train:108 - Epoch: [86][30/63]	 loss 4.15337	 cls_loss: 0.2259 cluster_loss: 1.2755 sup_con_loss: 0.7729 contrastive_loss: 4.5764 
2023-11-10 12:41:00.439 | INFO     | __main__:train:108 - Epoch: [86][40/63]	 loss 4.04621	 cls_loss: 0.2238 cluster_loss: 1.2237 sup_con_loss: 0.5553 contrastive_loss: 4.5818 
2023-11-10 12:41:19.231 | INFO     | __main__:train:108 - Epoch: [86][50/63]	 loss 4.09475	 cls_loss: 0.2182 cluster_loss: 1.2865 sup_con_loss: 0.5873 contrastive_loss: 4.5793 
2023-11-10 12:41:37.900 | INFO     | __main__:train:108 - Epoch: [86][60/63]	 loss 4.04082	 cls_loss: 0.2193 cluster_loss: 1.2200 sup_con_loss: 0.5584 contrastive_loss: 4.5779 
2023-11-10 12:41:41.729 | INFO     | __main__:train:111 - Train Epoch: 86 Avg Loss: 4.0799 
2023-11-10 12:41:41.729 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:42:32.261 | INFO     | __main__:train:119 - Train Accuracies: All 0.7529 | Old 0.8050 | New 0.7270
2023-11-10 12:42:42.399 | INFO     | __main__:train:108 - Epoch: [87][0/63]	 loss 3.98827	 cls_loss: 0.2284 cluster_loss: 1.1561 sup_con_loss: 0.5222 contrastive_loss: 4.5755 
2023-11-10 12:43:01.571 | INFO     | __main__:train:108 - Epoch: [87][10/63]	 loss 4.09286	 cls_loss: 0.2452 cluster_loss: 1.2395 sup_con_loss: 0.6396 contrastive_loss: 4.5807 
2023-11-10 12:43:20.391 | INFO     | __main__:train:108 - Epoch: [87][20/63]	 loss 4.09101	 cls_loss: 0.2324 cluster_loss: 1.2691 sup_con_loss: 0.6043 contrastive_loss: 4.5742 
2023-11-10 12:43:39.232 | INFO     | __main__:train:108 - Epoch: [87][30/63]	 loss 4.24814	 cls_loss: 0.2700 cluster_loss: 1.3438 sup_con_loss: 0.8586 contrastive_loss: 4.5840 
2023-11-10 12:43:58.077 | INFO     | __main__:train:108 - Epoch: [87][40/63]	 loss 3.98373	 cls_loss: 0.2004 cluster_loss: 1.2219 sup_con_loss: 0.4161 contrastive_loss: 4.5749 
2023-11-10 12:44:16.898 | INFO     | __main__:train:108 - Epoch: [87][50/63]	 loss 3.96297	 cls_loss: 0.2064 cluster_loss: 1.1388 sup_con_loss: 0.5138 contrastive_loss: 4.5702 
2023-11-10 12:44:35.635 | INFO     | __main__:train:108 - Epoch: [87][60/63]	 loss 4.06602	 cls_loss: 0.2246 cluster_loss: 1.2220 sup_con_loss: 0.6350 contrastive_loss: 4.5706 
2023-11-10 12:44:39.459 | INFO     | __main__:train:111 - Train Epoch: 87 Avg Loss: 4.0903 
2023-11-10 12:44:39.460 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:45:29.795 | INFO     | __main__:train:119 - Train Accuracies: All 0.7512 | Old 0.7942 | New 0.7300
2023-11-10 12:45:39.803 | INFO     | __main__:train:108 - Epoch: [88][0/63]	 loss 4.17565	 cls_loss: 0.2519 cluster_loss: 1.3180 sup_con_loss: 0.7302 contrastive_loss: 4.5773 
2023-11-10 12:45:59.053 | INFO     | __main__:train:108 - Epoch: [88][10/63]	 loss 4.03564	 cls_loss: 0.2397 cluster_loss: 1.2047 sup_con_loss: 0.5556 contrastive_loss: 4.5757 
2023-11-10 12:46:17.857 | INFO     | __main__:train:108 - Epoch: [88][20/63]	 loss 4.12515	 cls_loss: 0.2430 cluster_loss: 1.2458 sup_con_loss: 0.7329 contrastive_loss: 4.5751 
2023-11-10 12:46:36.730 | INFO     | __main__:train:108 - Epoch: [88][30/63]	 loss 4.06517	 cls_loss: 0.2500 cluster_loss: 1.2232 sup_con_loss: 0.5963 contrastive_loss: 4.5751 
2023-11-10 12:46:55.627 | INFO     | __main__:train:108 - Epoch: [88][40/63]	 loss 4.02748	 cls_loss: 0.2092 cluster_loss: 1.1771 sup_con_loss: 0.6145 contrastive_loss: 4.5755 
2023-11-10 12:47:14.447 | INFO     | __main__:train:108 - Epoch: [88][50/63]	 loss 4.02436	 cls_loss: 0.2097 cluster_loss: 1.2029 sup_con_loss: 0.5560 contrastive_loss: 4.5761 
2023-11-10 12:47:33.183 | INFO     | __main__:train:108 - Epoch: [88][60/63]	 loss 4.07510	 cls_loss: 0.2166 cluster_loss: 1.2429 sup_con_loss: 0.6228 contrastive_loss: 4.5745 
2023-11-10 12:47:37.001 | INFO     | __main__:train:111 - Train Epoch: 88 Avg Loss: 4.0909 
2023-11-10 12:47:37.001 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:48:27.275 | INFO     | __main__:train:119 - Train Accuracies: All 0.7547 | Old 0.8026 | New 0.7309
2023-11-10 12:48:36.940 | INFO     | __main__:train:108 - Epoch: [89][0/63]	 loss 4.01371	 cls_loss: 0.2206 cluster_loss: 1.1911 sup_con_loss: 0.5394 contrastive_loss: 4.5746 
2023-11-10 12:48:56.229 | INFO     | __main__:train:108 - Epoch: [89][10/63]	 loss 4.13105	 cls_loss: 0.2275 cluster_loss: 1.2578 sup_con_loss: 0.7364 contrastive_loss: 4.5787 
2023-11-10 12:49:15.006 | INFO     | __main__:train:108 - Epoch: [89][20/63]	 loss 4.18559	 cls_loss: 0.2294 cluster_loss: 1.3102 sup_con_loss: 0.7965 contrastive_loss: 4.5768 
2023-11-10 12:49:33.822 | INFO     | __main__:train:108 - Epoch: [89][30/63]	 loss 4.00286	 cls_loss: 0.2272 cluster_loss: 1.1683 sup_con_loss: 0.5397 contrastive_loss: 4.5770 
2023-11-10 12:49:52.702 | INFO     | __main__:train:108 - Epoch: [89][40/63]	 loss 4.15658	 cls_loss: 0.2101 cluster_loss: 1.3125 sup_con_loss: 0.7104 contrastive_loss: 4.5865 
2023-11-10 12:50:11.585 | INFO     | __main__:train:108 - Epoch: [89][50/63]	 loss 4.04051	 cls_loss: 0.2215 cluster_loss: 1.2514 sup_con_loss: 0.4897 contrastive_loss: 4.5818 
2023-11-10 12:50:30.270 | INFO     | __main__:train:108 - Epoch: [89][60/63]	 loss 4.09459	 cls_loss: 0.2236 cluster_loss: 1.2701 sup_con_loss: 0.6218 contrastive_loss: 4.5740 
2023-11-10 12:50:34.106 | INFO     | __main__:train:111 - Train Epoch: 89 Avg Loss: 4.0858 
2023-11-10 12:50:34.107 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:51:24.789 | INFO     | __main__:train:119 - Train Accuracies: All 0.7617 | Old 0.8080 | New 0.7388
2023-11-10 12:51:34.155 | INFO     | __main__:train:108 - Epoch: [90][0/63]	 loss 4.16897	 cls_loss: 0.2228 cluster_loss: 1.3013 sup_con_loss: 0.7681 contrastive_loss: 4.5790 
2023-11-10 12:51:53.283 | INFO     | __main__:train:108 - Epoch: [90][10/63]	 loss 3.97553	 cls_loss: 0.2518 cluster_loss: 1.1302 sup_con_loss: 0.5124 contrastive_loss: 4.5746 
2023-11-10 12:52:12.082 | INFO     | __main__:train:108 - Epoch: [90][20/63]	 loss 4.08927	 cls_loss: 0.2334 cluster_loss: 1.2005 sup_con_loss: 0.7170 contrastive_loss: 4.5789 
2023-11-10 12:52:30.936 | INFO     | __main__:train:108 - Epoch: [90][30/63]	 loss 4.19290	 cls_loss: 0.2386 cluster_loss: 1.3284 sup_con_loss: 0.7720 contrastive_loss: 4.5780 
2023-11-10 12:52:49.767 | INFO     | __main__:train:108 - Epoch: [90][40/63]	 loss 4.08029	 cls_loss: 0.2195 cluster_loss: 1.2400 sup_con_loss: 0.6262 contrastive_loss: 4.5819 
2023-11-10 12:53:08.606 | INFO     | __main__:train:108 - Epoch: [90][50/63]	 loss 4.17964	 cls_loss: 0.2090 cluster_loss: 1.3333 sup_con_loss: 0.7475 contrastive_loss: 4.5819 
2023-11-10 12:53:27.348 | INFO     | __main__:train:108 - Epoch: [90][60/63]	 loss 4.05749	 cls_loss: 0.2138 cluster_loss: 1.2028 sup_con_loss: 0.6459 contrastive_loss: 4.5766 
2023-11-10 12:53:31.169 | INFO     | __main__:train:111 - Train Epoch: 90 Avg Loss: 4.0942 
2023-11-10 12:53:31.169 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:54:22.727 | INFO     | __main__:train:119 - Train Accuracies: All 0.7605 | Old 0.8036 | New 0.7392
2023-11-10 12:54:33.439 | INFO     | __main__:train:108 - Epoch: [91][0/63]	 loss 4.11218	 cls_loss: 0.2072 cluster_loss: 1.2615 sup_con_loss: 0.6978 contrastive_loss: 4.5777 
2023-11-10 12:54:52.608 | INFO     | __main__:train:108 - Epoch: [91][10/63]	 loss 4.12920	 cls_loss: 0.2239 cluster_loss: 1.2873 sup_con_loss: 0.6924 contrastive_loss: 4.5719 
2023-11-10 12:55:11.431 | INFO     | __main__:train:108 - Epoch: [91][20/63]	 loss 4.12353	 cls_loss: 0.2180 cluster_loss: 1.3454 sup_con_loss: 0.5595 contrastive_loss: 4.5798 
2023-11-10 12:55:30.322 | INFO     | __main__:train:108 - Epoch: [91][30/63]	 loss 4.01585	 cls_loss: 0.2076 cluster_loss: 1.1992 sup_con_loss: 0.5463 contrastive_loss: 4.5730 
2023-11-10 12:55:49.119 | INFO     | __main__:train:108 - Epoch: [91][40/63]	 loss 4.01844	 cls_loss: 0.2125 cluster_loss: 1.1794 sup_con_loss: 0.5866 contrastive_loss: 4.5725 
2023-11-10 12:56:07.950 | INFO     | __main__:train:108 - Epoch: [91][50/63]	 loss 4.05351	 cls_loss: 0.2091 cluster_loss: 1.2372 sup_con_loss: 0.5754 contrastive_loss: 4.5766 
2023-11-10 12:56:26.632 | INFO     | __main__:train:108 - Epoch: [91][60/63]	 loss 4.20495	 cls_loss: 0.2166 cluster_loss: 1.3042 sup_con_loss: 0.8771 contrastive_loss: 4.5760 
2023-11-10 12:56:30.430 | INFO     | __main__:train:111 - Train Epoch: 91 Avg Loss: 4.0831 
2023-11-10 12:56:30.431 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 12:57:21.314 | INFO     | __main__:train:119 - Train Accuracies: All 0.7569 | Old 0.8080 | New 0.7317
2023-11-10 12:57:32.561 | INFO     | __main__:train:108 - Epoch: [92][0/63]	 loss 4.07035	 cls_loss: 0.2119 cluster_loss: 1.2550 sup_con_loss: 0.5918 contrastive_loss: 4.5744 
2023-11-10 12:57:51.641 | INFO     | __main__:train:108 - Epoch: [92][10/63]	 loss 3.93392	 cls_loss: 0.2225 cluster_loss: 1.1551 sup_con_loss: 0.3819 contrastive_loss: 4.5717 
2023-11-10 12:58:10.434 | INFO     | __main__:train:108 - Epoch: [92][20/63]	 loss 4.08867	 cls_loss: 0.2037 cluster_loss: 1.2512 sup_con_loss: 0.6585 contrastive_loss: 4.5748 
2023-11-10 12:58:29.260 | INFO     | __main__:train:108 - Epoch: [92][30/63]	 loss 4.11097	 cls_loss: 0.2109 cluster_loss: 1.2755 sup_con_loss: 0.6569 contrastive_loss: 4.5818 
2023-11-10 12:58:48.109 | INFO     | __main__:train:108 - Epoch: [92][40/63]	 loss 4.10364	 cls_loss: 0.2295 cluster_loss: 1.2589 sup_con_loss: 0.6607 contrastive_loss: 4.5751 
2023-11-10 12:59:06.946 | INFO     | __main__:train:108 - Epoch: [92][50/63]	 loss 4.08558	 cls_loss: 0.2342 cluster_loss: 1.2410 sup_con_loss: 0.6385 contrastive_loss: 4.5746 
2023-11-10 12:59:25.664 | INFO     | __main__:train:108 - Epoch: [92][60/63]	 loss 4.00332	 cls_loss: 0.1936 cluster_loss: 1.1735 sup_con_loss: 0.5776 contrastive_loss: 4.5702 
2023-11-10 12:59:29.485 | INFO     | __main__:train:111 - Train Epoch: 92 Avg Loss: 4.0762 
2023-11-10 12:59:29.485 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:00:20.424 | INFO     | __main__:train:119 - Train Accuracies: All 0.7605 | Old 0.8070 | New 0.7375
2023-11-10 13:00:30.124 | INFO     | __main__:train:108 - Epoch: [93][0/63]	 loss 4.03022	 cls_loss: 0.2070 cluster_loss: 1.1846 sup_con_loss: 0.6134 contrastive_loss: 4.5740 
2023-11-10 13:00:49.231 | INFO     | __main__:train:108 - Epoch: [93][10/63]	 loss 4.02086	 cls_loss: 0.2339 cluster_loss: 1.2333 sup_con_loss: 0.4634 contrastive_loss: 4.5772 
2023-11-10 13:01:08.071 | INFO     | __main__:train:108 - Epoch: [93][20/63]	 loss 4.05752	 cls_loss: 0.2071 cluster_loss: 1.2792 sup_con_loss: 0.5019 contrastive_loss: 4.5813 
2023-11-10 13:01:26.912 | INFO     | __main__:train:108 - Epoch: [93][30/63]	 loss 4.02639	 cls_loss: 0.2005 cluster_loss: 1.1958 sup_con_loss: 0.5917 contrastive_loss: 4.5720 
2023-11-10 13:01:45.732 | INFO     | __main__:train:108 - Epoch: [93][40/63]	 loss 4.07058	 cls_loss: 0.2643 cluster_loss: 1.2253 sup_con_loss: 0.5972 contrastive_loss: 4.5732 
2023-11-10 13:02:04.510 | INFO     | __main__:train:108 - Epoch: [93][50/63]	 loss 4.13080	 cls_loss: 0.2212 cluster_loss: 1.2838 sup_con_loss: 0.6966 contrastive_loss: 4.5771 
2023-11-10 13:02:23.234 | INFO     | __main__:train:108 - Epoch: [93][60/63]	 loss 4.16126	 cls_loss: 0.2352 cluster_loss: 1.3186 sup_con_loss: 0.6981 contrastive_loss: 4.5808 
2023-11-10 13:02:26.998 | INFO     | __main__:train:111 - Train Epoch: 93 Avg Loss: 4.0722 
2023-11-10 13:02:26.999 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:03:17.262 | INFO     | __main__:train:119 - Train Accuracies: All 0.7576 | Old 0.8031 | New 0.7351
2023-11-10 13:03:28.139 | INFO     | __main__:train:108 - Epoch: [94][0/63]	 loss 4.02199	 cls_loss: 0.2161 cluster_loss: 1.2189 sup_con_loss: 0.5073 contrastive_loss: 4.5792 
2023-11-10 13:03:47.168 | INFO     | __main__:train:108 - Epoch: [94][10/63]	 loss 4.07304	 cls_loss: 0.2235 cluster_loss: 1.2002 sup_con_loss: 0.6875 contrastive_loss: 4.5755 
2023-11-10 13:04:06.001 | INFO     | __main__:train:108 - Epoch: [94][20/63]	 loss 4.05900	 cls_loss: 0.2069 cluster_loss: 1.2552 sup_con_loss: 0.5645 contrastive_loss: 4.5741 
2023-11-10 13:04:24.868 | INFO     | __main__:train:108 - Epoch: [94][30/63]	 loss 4.10641	 cls_loss: 0.2014 cluster_loss: 1.2864 sup_con_loss: 0.6383 contrastive_loss: 4.5789 
2023-11-10 13:04:43.675 | INFO     | __main__:train:108 - Epoch: [94][40/63]	 loss 4.23184	 cls_loss: 0.2298 cluster_loss: 1.3711 sup_con_loss: 0.8092 contrastive_loss: 4.5799 
2023-11-10 13:05:02.493 | INFO     | __main__:train:108 - Epoch: [94][50/63]	 loss 4.10765	 cls_loss: 0.2055 cluster_loss: 1.2789 sup_con_loss: 0.6603 contrastive_loss: 4.5744 
2023-11-10 13:05:21.134 | INFO     | __main__:train:108 - Epoch: [94][60/63]	 loss 4.18707	 cls_loss: 0.2390 cluster_loss: 1.3102 sup_con_loss: 0.7821 contrastive_loss: 4.5816 
2023-11-10 13:05:24.956 | INFO     | __main__:train:111 - Train Epoch: 94 Avg Loss: 4.0753 
2023-11-10 13:05:24.957 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:06:15.297 | INFO     | __main__:train:119 - Train Accuracies: All 0.7565 | Old 0.8006 | New 0.7346
2023-11-10 13:06:26.052 | INFO     | __main__:train:108 - Epoch: [95][0/63]	 loss 4.07609	 cls_loss: 0.2025 cluster_loss: 1.2372 sup_con_loss: 0.6439 contrastive_loss: 4.5780 
2023-11-10 13:06:45.126 | INFO     | __main__:train:108 - Epoch: [95][10/63]	 loss 4.09048	 cls_loss: 0.2266 cluster_loss: 1.2497 sup_con_loss: 0.6385 contrastive_loss: 4.5775 
2023-11-10 13:07:03.920 | INFO     | __main__:train:108 - Epoch: [95][20/63]	 loss 4.01109	 cls_loss: 0.2206 cluster_loss: 1.2049 sup_con_loss: 0.5047 contrastive_loss: 4.5754 
2023-11-10 13:07:22.708 | INFO     | __main__:train:108 - Epoch: [95][30/63]	 loss 4.02752	 cls_loss: 0.2199 cluster_loss: 1.2059 sup_con_loss: 0.5472 contrastive_loss: 4.5773 
2023-11-10 13:07:41.602 | INFO     | __main__:train:108 - Epoch: [95][40/63]	 loss 4.02687	 cls_loss: 0.2294 cluster_loss: 1.2008 sup_con_loss: 0.5487 contrastive_loss: 4.5753 
2023-11-10 13:08:00.394 | INFO     | __main__:train:108 - Epoch: [95][50/63]	 loss 4.19117	 cls_loss: 0.2226 cluster_loss: 1.3466 sup_con_loss: 0.7522 contrastive_loss: 4.5765 
2023-11-10 13:08:19.049 | INFO     | __main__:train:108 - Epoch: [95][60/63]	 loss 4.00088	 cls_loss: 0.2260 cluster_loss: 1.1863 sup_con_loss: 0.5002 contrastive_loss: 4.5778 
2023-11-10 13:08:22.856 | INFO     | __main__:train:111 - Train Epoch: 95 Avg Loss: 4.0666 
2023-11-10 13:08:22.857 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:09:13.441 | INFO     | __main__:train:119 - Train Accuracies: All 0.7584 | Old 0.8154 | New 0.7302
2023-11-10 13:09:24.291 | INFO     | __main__:train:108 - Epoch: [96][0/63]	 loss 3.97059	 cls_loss: 0.2124 cluster_loss: 1.1886 sup_con_loss: 0.4267 contrastive_loss: 4.5758 
2023-11-10 13:09:43.287 | INFO     | __main__:train:108 - Epoch: [96][10/63]	 loss 4.11966	 cls_loss: 0.2209 cluster_loss: 1.2646 sup_con_loss: 0.7017 contrastive_loss: 4.5766 
2023-11-10 13:10:02.148 | INFO     | __main__:train:108 - Epoch: [96][20/63]	 loss 3.94693	 cls_loss: 0.2191 cluster_loss: 1.1504 sup_con_loss: 0.4281 contrastive_loss: 4.5733 
2023-11-10 13:10:21.012 | INFO     | __main__:train:108 - Epoch: [96][30/63]	 loss 4.06738	 cls_loss: 0.2115 cluster_loss: 1.2496 sup_con_loss: 0.5861 contrastive_loss: 4.5784 
2023-11-10 13:10:39.856 | INFO     | __main__:train:108 - Epoch: [96][40/63]	 loss 4.11508	 cls_loss: 0.2251 cluster_loss: 1.2420 sup_con_loss: 0.7375 contrastive_loss: 4.5706 
2023-11-10 13:10:58.689 | INFO     | __main__:train:108 - Epoch: [96][50/63]	 loss 3.94281	 cls_loss: 0.2144 cluster_loss: 1.1045 sup_con_loss: 0.5136 contrastive_loss: 4.5693 
2023-11-10 13:11:17.375 | INFO     | __main__:train:108 - Epoch: [96][60/63]	 loss 4.12166	 cls_loss: 0.2092 cluster_loss: 1.3286 sup_con_loss: 0.5932 contrastive_loss: 4.5803 
2023-11-10 13:11:21.201 | INFO     | __main__:train:111 - Train Epoch: 96 Avg Loss: 4.0632 
2023-11-10 13:11:21.202 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:12:12.064 | INFO     | __main__:train:119 - Train Accuracies: All 0.7587 | Old 0.8144 | New 0.7312
2023-11-10 13:12:23.206 | INFO     | __main__:train:108 - Epoch: [97][0/63]	 loss 3.97934	 cls_loss: 0.2051 cluster_loss: 1.2142 sup_con_loss: 0.4110 contrastive_loss: 4.5762 
2023-11-10 13:12:42.234 | INFO     | __main__:train:108 - Epoch: [97][10/63]	 loss 4.00146	 cls_loss: 0.2288 cluster_loss: 1.1923 sup_con_loss: 0.4913 contrastive_loss: 4.5760 
2023-11-10 13:13:01.028 | INFO     | __main__:train:108 - Epoch: [97][20/63]	 loss 4.16129	 cls_loss: 0.2131 cluster_loss: 1.2694 sup_con_loss: 0.8276 contrastive_loss: 4.5722 
2023-11-10 13:13:19.841 | INFO     | __main__:train:108 - Epoch: [97][30/63]	 loss 4.03865	 cls_loss: 0.2222 cluster_loss: 1.2323 sup_con_loss: 0.5216 contrastive_loss: 4.5805 
2023-11-10 13:13:38.734 | INFO     | __main__:train:108 - Epoch: [97][40/63]	 loss 4.12235	 cls_loss: 0.2170 cluster_loss: 1.2950 sup_con_loss: 0.6564 contrastive_loss: 4.5768 
2023-11-10 13:13:57.570 | INFO     | __main__:train:108 - Epoch: [97][50/63]	 loss 4.11124	 cls_loss: 0.2039 cluster_loss: 1.2258 sup_con_loss: 0.7767 contrastive_loss: 4.5712 
2023-11-10 13:14:16.295 | INFO     | __main__:train:108 - Epoch: [97][60/63]	 loss 4.02801	 cls_loss: 0.2361 cluster_loss: 1.1979 sup_con_loss: 0.5524 contrastive_loss: 4.5745 
2023-11-10 13:14:20.097 | INFO     | __main__:train:111 - Train Epoch: 97 Avg Loss: 4.0628 
2023-11-10 13:14:20.097 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:15:10.172 | INFO     | __main__:train:119 - Train Accuracies: All 0.7542 | Old 0.8016 | New 0.7307
2023-11-10 13:15:19.489 | INFO     | __main__:train:108 - Epoch: [98][0/63]	 loss 4.01354	 cls_loss: 0.2197 cluster_loss: 1.1967 sup_con_loss: 0.5186 contrastive_loss: 4.5805 
2023-11-10 13:15:38.574 | INFO     | __main__:train:108 - Epoch: [98][10/63]	 loss 3.98026	 cls_loss: 0.2320 cluster_loss: 1.1479 sup_con_loss: 0.5217 contrastive_loss: 4.5697 
2023-11-10 13:15:57.377 | INFO     | __main__:train:108 - Epoch: [98][20/63]	 loss 4.01854	 cls_loss: 0.2078 cluster_loss: 1.2237 sup_con_loss: 0.5036 contrastive_loss: 4.5756 
2023-11-10 13:16:16.221 | INFO     | __main__:train:108 - Epoch: [98][30/63]	 loss 4.13919	 cls_loss: 0.1931 cluster_loss: 1.2720 sup_con_loss: 0.7699 contrastive_loss: 4.5774 
2023-11-10 13:16:35.057 | INFO     | __main__:train:108 - Epoch: [98][40/63]	 loss 4.09330	 cls_loss: 0.2142 cluster_loss: 1.2668 sup_con_loss: 0.6332 contrastive_loss: 4.5743 
2023-11-10 13:16:53.901 | INFO     | __main__:train:108 - Epoch: [98][50/63]	 loss 3.98151	 cls_loss: 0.2002 cluster_loss: 1.1848 sup_con_loss: 0.4830 contrastive_loss: 4.5727 
2023-11-10 13:17:12.650 | INFO     | __main__:train:108 - Epoch: [98][60/63]	 loss 4.02337	 cls_loss: 0.2140 cluster_loss: 1.2624 sup_con_loss: 0.4370 contrastive_loss: 4.5769 
2023-11-10 13:17:16.449 | INFO     | __main__:train:111 - Train Epoch: 98 Avg Loss: 4.0659 
2023-11-10 13:17:16.449 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:18:06.705 | INFO     | __main__:train:119 - Train Accuracies: All 0.7619 | Old 0.8040 | New 0.7410
2023-11-10 13:18:16.125 | INFO     | __main__:train:108 - Epoch: [99][0/63]	 loss 4.06418	 cls_loss: 0.2084 cluster_loss: 1.1942 sup_con_loss: 0.6893 contrastive_loss: 4.5750 
2023-11-10 13:18:35.396 | INFO     | __main__:train:108 - Epoch: [99][10/63]	 loss 4.06250	 cls_loss: 0.2188 cluster_loss: 1.2154 sup_con_loss: 0.6271 contrastive_loss: 4.5791 
2023-11-10 13:18:54.214 | INFO     | __main__:train:108 - Epoch: [99][20/63]	 loss 4.20982	 cls_loss: 0.2199 cluster_loss: 1.3885 sup_con_loss: 0.7156 contrastive_loss: 4.5845 
2023-11-10 13:19:13.054 | INFO     | __main__:train:108 - Epoch: [99][30/63]	 loss 4.01707	 cls_loss: 0.1982 cluster_loss: 1.2162 sup_con_loss: 0.5301 contrastive_loss: 4.5717 
2023-11-10 13:19:31.866 | INFO     | __main__:train:108 - Epoch: [99][40/63]	 loss 4.12282	 cls_loss: 0.2301 cluster_loss: 1.2847 sup_con_loss: 0.6555 contrastive_loss: 4.5813 
2023-11-10 13:19:50.682 | INFO     | __main__:train:108 - Epoch: [99][50/63]	 loss 4.14993	 cls_loss: 0.1860 cluster_loss: 1.3343 sup_con_loss: 0.6948 contrastive_loss: 4.5760 
2023-11-10 13:20:09.364 | INFO     | __main__:train:108 - Epoch: [99][60/63]	 loss 4.02164	 cls_loss: 0.1989 cluster_loss: 1.2237 sup_con_loss: 0.5164 contrastive_loss: 4.5784 
2023-11-10 13:20:13.132 | INFO     | __main__:train:111 - Train Epoch: 99 Avg Loss: 4.0610 
2023-11-10 13:20:13.132 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:21:03.721 | INFO     | __main__:train:119 - Train Accuracies: All 0.7601 | Old 0.8075 | New 0.7366
2023-11-10 13:21:14.016 | INFO     | __main__:train:108 - Epoch: [100][0/63]	 loss 3.91958	 cls_loss: 0.2256 cluster_loss: 1.1527 sup_con_loss: 0.3395 contrastive_loss: 4.5732 
2023-11-10 13:21:33.236 | INFO     | __main__:train:108 - Epoch: [100][10/63]	 loss 3.97767	 cls_loss: 0.2183 cluster_loss: 1.1474 sup_con_loss: 0.5239 contrastive_loss: 4.5724 
2023-11-10 13:21:52.063 | INFO     | __main__:train:108 - Epoch: [100][20/63]	 loss 4.06444	 cls_loss: 0.2078 cluster_loss: 1.2295 sup_con_loss: 0.6296 contrastive_loss: 4.5726 
2023-11-10 13:22:10.924 | INFO     | __main__:train:108 - Epoch: [100][30/63]	 loss 4.15615	 cls_loss: 0.2155 cluster_loss: 1.2776 sup_con_loss: 0.7915 contrastive_loss: 4.5743 
2023-11-10 13:22:29.747 | INFO     | __main__:train:108 - Epoch: [100][40/63]	 loss 4.06559	 cls_loss: 0.2008 cluster_loss: 1.2497 sup_con_loss: 0.5985 contrastive_loss: 4.5746 
2023-11-10 13:22:48.543 | INFO     | __main__:train:108 - Epoch: [100][50/63]	 loss 4.02546	 cls_loss: 0.1996 cluster_loss: 1.1681 sup_con_loss: 0.6486 contrastive_loss: 4.5682 
2023-11-10 13:23:07.223 | INFO     | __main__:train:108 - Epoch: [100][60/63]	 loss 4.00918	 cls_loss: 0.1943 cluster_loss: 1.2134 sup_con_loss: 0.5114 contrastive_loss: 4.5747 
2023-11-10 13:23:11.012 | INFO     | __main__:train:111 - Train Epoch: 100 Avg Loss: 4.0537 
2023-11-10 13:23:11.013 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:24:01.441 | INFO     | __main__:train:119 - Train Accuracies: All 0.7630 | Old 0.8065 | New 0.7414
2023-11-10 13:24:11.671 | INFO     | __main__:train:108 - Epoch: [101][0/63]	 loss 3.96799	 cls_loss: 0.2064 cluster_loss: 1.1517 sup_con_loss: 0.5023 contrastive_loss: 4.5713 
2023-11-10 13:24:30.808 | INFO     | __main__:train:108 - Epoch: [101][10/63]	 loss 4.07615	 cls_loss: 0.2010 cluster_loss: 1.2049 sup_con_loss: 0.7126 contrastive_loss: 4.5742 
2023-11-10 13:24:49.653 | INFO     | __main__:train:108 - Epoch: [101][20/63]	 loss 4.15192	 cls_loss: 0.2100 cluster_loss: 1.2672 sup_con_loss: 0.8117 contrastive_loss: 4.5702 
2023-11-10 13:25:08.479 | INFO     | __main__:train:108 - Epoch: [101][30/63]	 loss 4.04356	 cls_loss: 0.2083 cluster_loss: 1.1896 sup_con_loss: 0.6409 contrastive_loss: 4.5741 
2023-11-10 13:25:27.293 | INFO     | __main__:train:108 - Epoch: [101][40/63]	 loss 3.93735	 cls_loss: 0.2025 cluster_loss: 1.1672 sup_con_loss: 0.3825 contrastive_loss: 4.5753 
2023-11-10 13:25:46.053 | INFO     | __main__:train:108 - Epoch: [101][50/63]	 loss 4.19627	 cls_loss: 0.2141 cluster_loss: 1.3084 sup_con_loss: 0.8413 contrastive_loss: 4.5791 
2023-11-10 13:26:04.691 | INFO     | __main__:train:108 - Epoch: [101][60/63]	 loss 4.04035	 cls_loss: 0.2151 cluster_loss: 1.1997 sup_con_loss: 0.6076 contrastive_loss: 4.5732 
2023-11-10 13:26:08.513 | INFO     | __main__:train:111 - Train Epoch: 101 Avg Loss: 4.0483 
2023-11-10 13:26:08.513 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:26:59.334 | INFO     | __main__:train:119 - Train Accuracies: All 0.7587 | Old 0.8124 | New 0.7322
2023-11-10 13:27:10.119 | INFO     | __main__:train:108 - Epoch: [102][0/63]	 loss 3.91713	 cls_loss: 0.2267 cluster_loss: 1.0882 sup_con_loss: 0.4549 contrastive_loss: 4.5711 
2023-11-10 13:27:29.052 | INFO     | __main__:train:108 - Epoch: [102][10/63]	 loss 4.09182	 cls_loss: 0.1938 cluster_loss: 1.2502 sup_con_loss: 0.6874 contrastive_loss: 4.5704 
2023-11-10 13:27:47.916 | INFO     | __main__:train:108 - Epoch: [102][20/63]	 loss 4.18474	 cls_loss: 0.2406 cluster_loss: 1.2902 sup_con_loss: 0.8203 contrastive_loss: 4.5766 
2023-11-10 13:28:06.752 | INFO     | __main__:train:108 - Epoch: [102][30/63]	 loss 4.11823	 cls_loss: 0.2028 cluster_loss: 1.3195 sup_con_loss: 0.6203 contrastive_loss: 4.5731 
2023-11-10 13:28:25.628 | INFO     | __main__:train:108 - Epoch: [102][40/63]	 loss 4.16118	 cls_loss: 0.2282 cluster_loss: 1.2826 sup_con_loss: 0.7698 contrastive_loss: 4.5818 
2023-11-10 13:28:44.478 | INFO     | __main__:train:108 - Epoch: [102][50/63]	 loss 4.02945	 cls_loss: 0.2161 cluster_loss: 1.1962 sup_con_loss: 0.5841 contrastive_loss: 4.5721 
2023-11-10 13:29:03.177 | INFO     | __main__:train:108 - Epoch: [102][60/63]	 loss 4.09782	 cls_loss: 0.2370 cluster_loss: 1.2378 sup_con_loss: 0.6732 contrastive_loss: 4.5764 
2023-11-10 13:29:06.978 | INFO     | __main__:train:111 - Train Epoch: 102 Avg Loss: 4.0656 
2023-11-10 13:29:06.979 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:29:57.628 | INFO     | __main__:train:119 - Train Accuracies: All 0.7636 | Old 0.8110 | New 0.7402
2023-11-10 13:30:08.112 | INFO     | __main__:train:108 - Epoch: [103][0/63]	 loss 4.03948	 cls_loss: 0.2270 cluster_loss: 1.1846 sup_con_loss: 0.6259 contrastive_loss: 4.5708 
2023-11-10 13:30:27.034 | INFO     | __main__:train:108 - Epoch: [103][10/63]	 loss 4.02443	 cls_loss: 0.1997 cluster_loss: 1.2549 sup_con_loss: 0.4757 contrastive_loss: 4.5729 
2023-11-10 13:30:45.821 | INFO     | __main__:train:108 - Epoch: [103][20/63]	 loss 4.05564	 cls_loss: 0.2038 cluster_loss: 1.2653 sup_con_loss: 0.5368 contrastive_loss: 4.5754 
2023-11-10 13:31:04.695 | INFO     | __main__:train:108 - Epoch: [103][30/63]	 loss 4.03242	 cls_loss: 0.2173 cluster_loss: 1.2330 sup_con_loss: 0.4984 contrastive_loss: 4.5854 
2023-11-10 13:31:23.616 | INFO     | __main__:train:108 - Epoch: [103][40/63]	 loss 4.07444	 cls_loss: 0.1962 cluster_loss: 1.2729 sup_con_loss: 0.5943 contrastive_loss: 4.5698 
2023-11-10 13:31:42.383 | INFO     | __main__:train:108 - Epoch: [103][50/63]	 loss 4.06323	 cls_loss: 0.2011 cluster_loss: 1.2412 sup_con_loss: 0.6113 contrastive_loss: 4.5725 
2023-11-10 13:32:01.084 | INFO     | __main__:train:108 - Epoch: [103][60/63]	 loss 4.06833	 cls_loss: 0.2225 cluster_loss: 1.2111 sup_con_loss: 0.6566 contrastive_loss: 4.5744 
2023-11-10 13:32:04.895 | INFO     | __main__:train:111 - Train Epoch: 103 Avg Loss: 4.0695 
2023-11-10 13:32:04.896 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:32:55.594 | INFO     | __main__:train:119 - Train Accuracies: All 0.7610 | Old 0.8090 | New 0.7373
2023-11-10 13:33:04.471 | INFO     | __main__:train:108 - Epoch: [104][0/63]	 loss 4.09971	 cls_loss: 0.2383 cluster_loss: 1.2385 sup_con_loss: 0.6708 contrastive_loss: 4.5792 
2023-11-10 13:33:23.634 | INFO     | __main__:train:108 - Epoch: [104][10/63]	 loss 4.03314	 cls_loss: 0.2106 cluster_loss: 1.2182 sup_con_loss: 0.5534 contrastive_loss: 4.5752 
2023-11-10 13:33:42.435 | INFO     | __main__:train:108 - Epoch: [104][20/63]	 loss 4.09724	 cls_loss: 0.2028 cluster_loss: 1.2239 sup_con_loss: 0.7378 contrastive_loss: 4.5731 
2023-11-10 13:34:01.274 | INFO     | __main__:train:108 - Epoch: [104][30/63]	 loss 4.16502	 cls_loss: 0.2009 cluster_loss: 1.2920 sup_con_loss: 0.8180 contrastive_loss: 4.5671 
2023-11-10 13:34:20.191 | INFO     | __main__:train:108 - Epoch: [104][40/63]	 loss 4.08874	 cls_loss: 0.2219 cluster_loss: 1.2234 sup_con_loss: 0.6978 contrastive_loss: 4.5718 
2023-11-10 13:34:39.016 | INFO     | __main__:train:108 - Epoch: [104][50/63]	 loss 4.01203	 cls_loss: 0.2059 cluster_loss: 1.1946 sup_con_loss: 0.5404 contrastive_loss: 4.5759 
2023-11-10 13:34:57.677 | INFO     | __main__:train:108 - Epoch: [104][60/63]	 loss 4.07290	 cls_loss: 0.2389 cluster_loss: 1.2552 sup_con_loss: 0.5636 contrastive_loss: 4.5787 
2023-11-10 13:35:01.482 | INFO     | __main__:train:111 - Train Epoch: 104 Avg Loss: 4.0359 
2023-11-10 13:35:01.482 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:35:52.066 | INFO     | __main__:train:119 - Train Accuracies: All 0.7632 | Old 0.8040 | New 0.7429
2023-11-10 13:36:01.724 | INFO     | __main__:train:108 - Epoch: [105][0/63]	 loss 4.10353	 cls_loss: 0.2171 cluster_loss: 1.2501 sup_con_loss: 0.7004 contrastive_loss: 4.5689 
2023-11-10 13:36:20.908 | INFO     | __main__:train:108 - Epoch: [105][10/63]	 loss 4.06891	 cls_loss: 0.2211 cluster_loss: 1.2737 sup_con_loss: 0.5448 contrastive_loss: 4.5738 
2023-11-10 13:36:39.743 | INFO     | __main__:train:108 - Epoch: [105][20/63]	 loss 4.03911	 cls_loss: 0.2064 cluster_loss: 1.1825 sup_con_loss: 0.6554 contrastive_loss: 4.5675 
2023-11-10 13:36:58.582 | INFO     | __main__:train:108 - Epoch: [105][30/63]	 loss 3.94416	 cls_loss: 0.2133 cluster_loss: 1.1642 sup_con_loss: 0.4004 contrastive_loss: 4.5733 
2023-11-10 13:37:17.429 | INFO     | __main__:train:108 - Epoch: [105][40/63]	 loss 4.04679	 cls_loss: 0.1991 cluster_loss: 1.2384 sup_con_loss: 0.5600 contrastive_loss: 4.5787 
2023-11-10 13:37:36.256 | INFO     | __main__:train:108 - Epoch: [105][50/63]	 loss 4.05371	 cls_loss: 0.2134 cluster_loss: 1.2297 sup_con_loss: 0.5966 contrastive_loss: 4.5706 
2023-11-10 13:37:55.001 | INFO     | __main__:train:108 - Epoch: [105][60/63]	 loss 4.13850	 cls_loss: 0.1959 cluster_loss: 1.2659 sup_con_loss: 0.7853 contrastive_loss: 4.5726 
2023-11-10 13:37:58.802 | INFO     | __main__:train:111 - Train Epoch: 105 Avg Loss: 4.0609 
2023-11-10 13:37:58.803 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:38:48.829 | INFO     | __main__:train:119 - Train Accuracies: All 0.7601 | Old 0.8129 | New 0.7339
2023-11-10 13:39:01.128 | INFO     | __main__:train:108 - Epoch: [106][0/63]	 loss 4.19118	 cls_loss: 0.2073 cluster_loss: 1.3348 sup_con_loss: 0.7873 contrastive_loss: 4.5776 
2023-11-10 13:39:20.106 | INFO     | __main__:train:108 - Epoch: [106][10/63]	 loss 3.99026	 cls_loss: 0.2024 cluster_loss: 1.2046 sup_con_loss: 0.4752 contrastive_loss: 4.5694 
2023-11-10 13:39:38.906 | INFO     | __main__:train:108 - Epoch: [106][20/63]	 loss 4.19805	 cls_loss: 0.2208 cluster_loss: 1.3488 sup_con_loss: 0.7760 contrastive_loss: 4.5730 
2023-11-10 13:39:57.795 | INFO     | __main__:train:108 - Epoch: [106][30/63]	 loss 4.00335	 cls_loss: 0.2096 cluster_loss: 1.1869 sup_con_loss: 0.5334 contrastive_loss: 4.5720 
2023-11-10 13:40:16.656 | INFO     | __main__:train:108 - Epoch: [106][40/63]	 loss 4.03490	 cls_loss: 0.2136 cluster_loss: 1.2245 sup_con_loss: 0.5476 contrastive_loss: 4.5732 
2023-11-10 13:40:35.496 | INFO     | __main__:train:108 - Epoch: [106][50/63]	 loss 4.06147	 cls_loss: 0.2128 cluster_loss: 1.2124 sup_con_loss: 0.6503 contrastive_loss: 4.5713 
2023-11-10 13:40:54.167 | INFO     | __main__:train:108 - Epoch: [106][60/63]	 loss 4.02882	 cls_loss: 0.2159 cluster_loss: 1.2019 sup_con_loss: 0.5695 contrastive_loss: 4.5733 
2023-11-10 13:40:57.975 | INFO     | __main__:train:111 - Train Epoch: 106 Avg Loss: 4.0605 
2023-11-10 13:40:57.975 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:41:48.733 | INFO     | __main__:train:119 - Train Accuracies: All 0.7648 | Old 0.8169 | New 0.7390
2023-11-10 13:41:59.785 | INFO     | __main__:train:108 - Epoch: [107][0/63]	 loss 4.03596	 cls_loss: 0.2162 cluster_loss: 1.2098 sup_con_loss: 0.5760 contrastive_loss: 4.5728 
2023-11-10 13:42:18.855 | INFO     | __main__:train:108 - Epoch: [107][10/63]	 loss 4.14834	 cls_loss: 0.2129 cluster_loss: 1.3184 sup_con_loss: 0.6926 contrastive_loss: 4.5761 
2023-11-10 13:42:37.750 | INFO     | __main__:train:108 - Epoch: [107][20/63]	 loss 3.88390	 cls_loss: 0.2226 cluster_loss: 1.1296 sup_con_loss: 0.2740 contrastive_loss: 4.5782 
2023-11-10 13:42:56.598 | INFO     | __main__:train:108 - Epoch: [107][30/63]	 loss 4.26499	 cls_loss: 0.2148 cluster_loss: 1.4231 sup_con_loss: 0.8196 contrastive_loss: 4.5814 
2023-11-10 13:43:15.436 | INFO     | __main__:train:108 - Epoch: [107][40/63]	 loss 4.09261	 cls_loss: 0.2099 cluster_loss: 1.2540 sup_con_loss: 0.6673 contrastive_loss: 4.5701 
2023-11-10 13:43:34.256 | INFO     | __main__:train:108 - Epoch: [107][50/63]	 loss 3.94564	 cls_loss: 0.2177 cluster_loss: 1.1578 sup_con_loss: 0.4125 contrastive_loss: 4.5731 
2023-11-10 13:43:52.935 | INFO     | __main__:train:108 - Epoch: [107][60/63]	 loss 3.94722	 cls_loss: 0.2238 cluster_loss: 1.1131 sup_con_loss: 0.4997 contrastive_loss: 4.5700 
2023-11-10 13:43:56.703 | INFO     | __main__:train:111 - Train Epoch: 107 Avg Loss: 4.0468 
2023-11-10 13:43:56.704 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:44:47.587 | INFO     | __main__:train:119 - Train Accuracies: All 0.7610 | Old 0.8060 | New 0.7388
2023-11-10 13:44:57.736 | INFO     | __main__:train:108 - Epoch: [108][0/63]	 loss 3.96619	 cls_loss: 0.2402 cluster_loss: 1.1122 sup_con_loss: 0.5378 contrastive_loss: 4.5708 
2023-11-10 13:45:16.763 | INFO     | __main__:train:108 - Epoch: [108][10/63]	 loss 3.99889	 cls_loss: 0.2268 cluster_loss: 1.1647 sup_con_loss: 0.5456 contrastive_loss: 4.5715 
2023-11-10 13:45:35.646 | INFO     | __main__:train:108 - Epoch: [108][20/63]	 loss 4.08138	 cls_loss: 0.2342 cluster_loss: 1.2157 sup_con_loss: 0.6848 contrastive_loss: 4.5685 
2023-11-10 13:45:54.474 | INFO     | __main__:train:108 - Epoch: [108][30/63]	 loss 4.07127	 cls_loss: 0.2191 cluster_loss: 1.1615 sup_con_loss: 0.7791 contrastive_loss: 4.5645 
2023-11-10 13:46:13.359 | INFO     | __main__:train:108 - Epoch: [108][40/63]	 loss 4.12889	 cls_loss: 0.2037 cluster_loss: 1.3265 sup_con_loss: 0.6306 contrastive_loss: 4.5764 
2023-11-10 13:46:32.206 | INFO     | __main__:train:108 - Epoch: [108][50/63]	 loss 4.03697	 cls_loss: 0.2379 cluster_loss: 1.1878 sup_con_loss: 0.6020 contrastive_loss: 4.5707 
2023-11-10 13:46:50.908 | INFO     | __main__:train:108 - Epoch: [108][60/63]	 loss 4.04707	 cls_loss: 0.2450 cluster_loss: 1.2069 sup_con_loss: 0.5793 contrastive_loss: 4.5755 
2023-11-10 13:46:54.687 | INFO     | __main__:train:111 - Train Epoch: 108 Avg Loss: 4.0696 
2023-11-10 13:46:54.688 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:47:45.112 | INFO     | __main__:train:119 - Train Accuracies: All 0.7612 | Old 0.8115 | New 0.7363
2023-11-10 13:47:55.158 | INFO     | __main__:train:108 - Epoch: [109][0/63]	 loss 4.00896	 cls_loss: 0.2235 cluster_loss: 1.1917 sup_con_loss: 0.5283 contrastive_loss: 4.5711 
2023-11-10 13:48:14.212 | INFO     | __main__:train:108 - Epoch: [109][10/63]	 loss 4.04752	 cls_loss: 0.2161 cluster_loss: 1.2014 sup_con_loss: 0.6301 contrastive_loss: 4.5699 
2023-11-10 13:48:33.052 | INFO     | __main__:train:108 - Epoch: [109][20/63]	 loss 4.17333	 cls_loss: 0.2015 cluster_loss: 1.3252 sup_con_loss: 0.7624 contrastive_loss: 4.5763 
2023-11-10 13:48:51.899 | INFO     | __main__:train:108 - Epoch: [109][30/63]	 loss 3.96040	 cls_loss: 0.2073 cluster_loss: 1.1813 sup_con_loss: 0.4189 contrastive_loss: 4.5744 
2023-11-10 13:49:10.819 | INFO     | __main__:train:108 - Epoch: [109][40/63]	 loss 4.26264	 cls_loss: 0.1992 cluster_loss: 1.4215 sup_con_loss: 0.8316 contrastive_loss: 4.5814 
2023-11-10 13:49:29.708 | INFO     | __main__:train:108 - Epoch: [109][50/63]	 loss 4.06899	 cls_loss: 0.2077 cluster_loss: 1.2093 sup_con_loss: 0.6833 contrastive_loss: 4.5709 
2023-11-10 13:49:48.454 | INFO     | __main__:train:108 - Epoch: [109][60/63]	 loss 4.09178	 cls_loss: 0.2139 cluster_loss: 1.2386 sup_con_loss: 0.6883 contrastive_loss: 4.5707 
2023-11-10 13:49:52.234 | INFO     | __main__:train:111 - Train Epoch: 109 Avg Loss: 4.0696 
2023-11-10 13:49:52.235 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:50:43.208 | INFO     | __main__:train:119 - Train Accuracies: All 0.7574 | Old 0.8011 | New 0.7358
2023-11-10 13:50:52.787 | INFO     | __main__:train:108 - Epoch: [110][0/63]	 loss 3.97699	 cls_loss: 0.2161 cluster_loss: 1.1588 sup_con_loss: 0.5070 contrastive_loss: 4.5703 
2023-11-10 13:51:11.980 | INFO     | __main__:train:108 - Epoch: [110][10/63]	 loss 4.17091	 cls_loss: 0.2407 cluster_loss: 1.2854 sup_con_loss: 0.8009 contrastive_loss: 4.5705 
2023-11-10 13:51:30.824 | INFO     | __main__:train:108 - Epoch: [110][20/63]	 loss 3.99959	 cls_loss: 0.2266 cluster_loss: 1.2205 sup_con_loss: 0.4481 contrastive_loss: 4.5694 
2023-11-10 13:51:49.735 | INFO     | __main__:train:108 - Epoch: [110][30/63]	 loss 4.07817	 cls_loss: 0.2009 cluster_loss: 1.2237 sup_con_loss: 0.6927 contrastive_loss: 4.5692 
2023-11-10 13:52:08.594 | INFO     | __main__:train:108 - Epoch: [110][40/63]	 loss 4.10011	 cls_loss: 0.2131 cluster_loss: 1.2534 sup_con_loss: 0.6734 contrastive_loss: 4.5772 
2023-11-10 13:52:27.399 | INFO     | __main__:train:108 - Epoch: [110][50/63]	 loss 4.14742	 cls_loss: 0.2528 cluster_loss: 1.2906 sup_con_loss: 0.6969 contrastive_loss: 4.5787 
2023-11-10 13:52:46.165 | INFO     | __main__:train:108 - Epoch: [110][60/63]	 loss 4.09516	 cls_loss: 0.2187 cluster_loss: 1.2500 sup_con_loss: 0.6687 contrastive_loss: 4.5724 
2023-11-10 13:52:49.962 | INFO     | __main__:train:111 - Train Epoch: 110 Avg Loss: 4.0562 
2023-11-10 13:52:49.963 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:53:40.458 | INFO     | __main__:train:119 - Train Accuracies: All 0.7625 | Old 0.8006 | New 0.7436
2023-11-10 13:53:51.412 | INFO     | __main__:train:108 - Epoch: [111][0/63]	 loss 4.19793	 cls_loss: 0.1945 cluster_loss: 1.3822 sup_con_loss: 0.7283 contrastive_loss: 4.5793 
2023-11-10 13:54:10.548 | INFO     | __main__:train:108 - Epoch: [111][10/63]	 loss 4.14846	 cls_loss: 0.2072 cluster_loss: 1.3018 sup_con_loss: 0.7283 contrastive_loss: 4.5767 
2023-11-10 13:54:29.376 | INFO     | __main__:train:108 - Epoch: [111][20/63]	 loss 4.04636	 cls_loss: 0.2204 cluster_loss: 1.1794 sup_con_loss: 0.6704 contrastive_loss: 4.5661 
2023-11-10 13:54:48.247 | INFO     | __main__:train:108 - Epoch: [111][30/63]	 loss 4.09378	 cls_loss: 0.2275 cluster_loss: 1.1998 sup_con_loss: 0.7526 contrastive_loss: 4.5706 
2023-11-10 13:55:07.132 | INFO     | __main__:train:108 - Epoch: [111][40/63]	 loss 3.96564	 cls_loss: 0.2158 cluster_loss: 1.0869 sup_con_loss: 0.6158 contrastive_loss: 4.5663 
2023-11-10 13:55:26.026 | INFO     | __main__:train:108 - Epoch: [111][50/63]	 loss 3.97206	 cls_loss: 0.1908 cluster_loss: 1.1500 sup_con_loss: 0.5351 contrastive_loss: 4.5700 
2023-11-10 13:55:44.743 | INFO     | __main__:train:108 - Epoch: [111][60/63]	 loss 4.05798	 cls_loss: 0.2039 cluster_loss: 1.2163 sup_con_loss: 0.6398 contrastive_loss: 4.5724 
2023-11-10 13:55:48.586 | INFO     | __main__:train:111 - Train Epoch: 111 Avg Loss: 4.0670 
2023-11-10 13:55:48.587 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:56:39.892 | INFO     | __main__:train:119 - Train Accuracies: All 0.7615 | Old 0.8045 | New 0.7402
2023-11-10 13:56:50.095 | INFO     | __main__:train:108 - Epoch: [112][0/63]	 loss 4.14750	 cls_loss: 0.2317 cluster_loss: 1.3035 sup_con_loss: 0.6986 contrastive_loss: 4.5763 
2023-11-10 13:57:09.200 | INFO     | __main__:train:108 - Epoch: [112][10/63]	 loss 3.93802	 cls_loss: 0.2154 cluster_loss: 1.1022 sup_con_loss: 0.5031 contrastive_loss: 4.5694 
2023-11-10 13:57:28.062 | INFO     | __main__:train:108 - Epoch: [112][20/63]	 loss 4.03755	 cls_loss: 0.2049 cluster_loss: 1.1830 sup_con_loss: 0.6448 contrastive_loss: 4.5711 
2023-11-10 13:57:46.925 | INFO     | __main__:train:108 - Epoch: [112][30/63]	 loss 3.96890	 cls_loss: 0.2052 cluster_loss: 1.1699 sup_con_loss: 0.4750 contrastive_loss: 4.5698 
2023-11-10 13:58:05.869 | INFO     | __main__:train:108 - Epoch: [112][40/63]	 loss 4.03121	 cls_loss: 0.2419 cluster_loss: 1.1632 sup_con_loss: 0.6248 contrastive_loss: 4.5719 
2023-11-10 13:58:24.763 | INFO     | __main__:train:108 - Epoch: [112][50/63]	 loss 4.10290	 cls_loss: 0.2099 cluster_loss: 1.2140 sup_con_loss: 0.7726 contrastive_loss: 4.5692 
2023-11-10 13:58:43.548 | INFO     | __main__:train:108 - Epoch: [112][60/63]	 loss 3.92103	 cls_loss: 0.2104 cluster_loss: 1.1057 sup_con_loss: 0.4600 contrastive_loss: 4.5656 
2023-11-10 13:58:47.314 | INFO     | __main__:train:111 - Train Epoch: 112 Avg Loss: 4.0361 
2023-11-10 13:58:47.315 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 13:59:38.099 | INFO     | __main__:train:119 - Train Accuracies: All 0.7636 | Old 0.8100 | New 0.7407
2023-11-10 13:59:47.304 | INFO     | __main__:train:108 - Epoch: [113][0/63]	 loss 4.02365	 cls_loss: 0.2291 cluster_loss: 1.1648 sup_con_loss: 0.6214 contrastive_loss: 4.5675 
2023-11-10 14:00:06.408 | INFO     | __main__:train:108 - Epoch: [113][10/63]	 loss 4.16040	 cls_loss: 0.2034 cluster_loss: 1.3343 sup_con_loss: 0.7037 contrastive_loss: 4.5779 
2023-11-10 14:00:25.264 | INFO     | __main__:train:108 - Epoch: [113][20/63]	 loss 4.07571	 cls_loss: 0.2138 cluster_loss: 1.2380 sup_con_loss: 0.6472 contrastive_loss: 4.5687 
2023-11-10 14:00:44.211 | INFO     | __main__:train:108 - Epoch: [113][30/63]	 loss 3.93918	 cls_loss: 0.2069 cluster_loss: 1.1359 sup_con_loss: 0.4537 contrastive_loss: 4.5687 
2023-11-10 14:01:03.098 | INFO     | __main__:train:108 - Epoch: [113][40/63]	 loss 3.95287	 cls_loss: 0.2000 cluster_loss: 1.1350 sup_con_loss: 0.5006 contrastive_loss: 4.5691 
2023-11-10 14:01:21.938 | INFO     | __main__:train:108 - Epoch: [113][50/63]	 loss 3.97228	 cls_loss: 0.2162 cluster_loss: 1.1844 sup_con_loss: 0.4252 contrastive_loss: 4.5814 
2023-11-10 14:01:40.662 | INFO     | __main__:train:108 - Epoch: [113][60/63]	 loss 4.01160	 cls_loss: 0.2006 cluster_loss: 1.1995 sup_con_loss: 0.5461 contrastive_loss: 4.5701 
2023-11-10 14:01:44.451 | INFO     | __main__:train:111 - Train Epoch: 113 Avg Loss: 4.0517 
2023-11-10 14:01:44.452 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:02:34.391 | INFO     | __main__:train:119 - Train Accuracies: All 0.7615 | Old 0.7952 | New 0.7449
2023-11-10 14:02:43.923 | INFO     | __main__:train:108 - Epoch: [114][0/63]	 loss 3.98685	 cls_loss: 0.1892 cluster_loss: 1.1705 sup_con_loss: 0.5411 contrastive_loss: 4.5699 
2023-11-10 14:03:03.023 | INFO     | __main__:train:108 - Epoch: [114][10/63]	 loss 3.99368	 cls_loss: 0.2407 cluster_loss: 1.1070 sup_con_loss: 0.6325 contrastive_loss: 4.5669 
2023-11-10 14:03:21.927 | INFO     | __main__:train:108 - Epoch: [114][20/63]	 loss 3.99734	 cls_loss: 0.2244 cluster_loss: 1.1842 sup_con_loss: 0.5127 contrastive_loss: 4.5687 
2023-11-10 14:03:40.769 | INFO     | __main__:train:108 - Epoch: [114][30/63]	 loss 4.11571	 cls_loss: 0.2056 cluster_loss: 1.3071 sup_con_loss: 0.6344 contrastive_loss: 4.5724 
2023-11-10 14:03:59.681 | INFO     | __main__:train:108 - Epoch: [114][40/63]	 loss 4.05967	 cls_loss: 0.2154 cluster_loss: 1.1752 sup_con_loss: 0.7121 contrastive_loss: 4.5711 
2023-11-10 14:04:18.602 | INFO     | __main__:train:108 - Epoch: [114][50/63]	 loss 4.11423	 cls_loss: 0.2111 cluster_loss: 1.2792 sup_con_loss: 0.6642 contrastive_loss: 4.5790 
2023-11-10 14:04:37.408 | INFO     | __main__:train:108 - Epoch: [114][60/63]	 loss 4.04317	 cls_loss: 0.2035 cluster_loss: 1.1995 sup_con_loss: 0.6360 contrastive_loss: 4.5687 
2023-11-10 14:04:41.185 | INFO     | __main__:train:111 - Train Epoch: 114 Avg Loss: 4.0439 
2023-11-10 14:04:41.186 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:05:31.693 | INFO     | __main__:train:119 - Train Accuracies: All 0.7632 | Old 0.8124 | New 0.7388
2023-11-10 14:05:40.850 | INFO     | __main__:train:108 - Epoch: [115][0/63]	 loss 4.00591	 cls_loss: 0.1958 cluster_loss: 1.2104 sup_con_loss: 0.5149 contrastive_loss: 4.5698 
2023-11-10 14:06:00.003 | INFO     | __main__:train:108 - Epoch: [115][10/63]	 loss 3.93656	 cls_loss: 0.2091 cluster_loss: 1.1308 sup_con_loss: 0.4400 contrastive_loss: 4.5760 
2023-11-10 14:06:18.864 | INFO     | __main__:train:108 - Epoch: [115][20/63]	 loss 4.11966	 cls_loss: 0.2142 cluster_loss: 1.2589 sup_con_loss: 0.7251 contrastive_loss: 4.5733 
2023-11-10 14:06:37.779 | INFO     | __main__:train:108 - Epoch: [115][30/63]	 loss 4.03697	 cls_loss: 0.2134 cluster_loss: 1.2235 sup_con_loss: 0.5498 contrastive_loss: 4.5763 
2023-11-10 14:06:56.687 | INFO     | __main__:train:108 - Epoch: [115][40/63]	 loss 4.04165	 cls_loss: 0.1999 cluster_loss: 1.2561 sup_con_loss: 0.5202 contrastive_loss: 4.5741 
2023-11-10 14:07:15.569 | INFO     | __main__:train:108 - Epoch: [115][50/63]	 loss 3.91834	 cls_loss: 0.2027 cluster_loss: 1.0860 sup_con_loss: 0.4954 contrastive_loss: 4.5663 
2023-11-10 14:07:34.305 | INFO     | __main__:train:108 - Epoch: [115][60/63]	 loss 3.98166	 cls_loss: 0.2174 cluster_loss: 1.1375 sup_con_loss: 0.5542 contrastive_loss: 4.5727 
2023-11-10 14:07:38.075 | INFO     | __main__:train:111 - Train Epoch: 115 Avg Loss: 4.0635 
2023-11-10 14:07:38.076 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:08:28.372 | INFO     | __main__:train:119 - Train Accuracies: All 0.7646 | Old 0.8169 | New 0.7388
2023-11-10 14:08:39.280 | INFO     | __main__:train:108 - Epoch: [116][0/63]	 loss 4.07721	 cls_loss: 0.2068 cluster_loss: 1.1923 sup_con_loss: 0.7403 contrastive_loss: 4.5703 
2023-11-10 14:08:58.394 | INFO     | __main__:train:108 - Epoch: [116][10/63]	 loss 4.00708	 cls_loss: 0.2016 cluster_loss: 1.1877 sup_con_loss: 0.5570 contrastive_loss: 4.5685 
2023-11-10 14:09:17.241 | INFO     | __main__:train:108 - Epoch: [116][20/63]	 loss 3.98069	 cls_loss: 0.1930 cluster_loss: 1.1577 sup_con_loss: 0.5371 contrastive_loss: 4.5734 
2023-11-10 14:09:36.147 | INFO     | __main__:train:108 - Epoch: [116][30/63]	 loss 3.98432	 cls_loss: 0.2016 cluster_loss: 1.1682 sup_con_loss: 0.5307 contrastive_loss: 4.5672 
2023-11-10 14:09:55.068 | INFO     | __main__:train:108 - Epoch: [116][40/63]	 loss 4.04788	 cls_loss: 0.2537 cluster_loss: 1.1782 sup_con_loss: 0.6270 contrastive_loss: 4.5751 
2023-11-10 14:10:13.947 | INFO     | __main__:train:108 - Epoch: [116][50/63]	 loss 4.05662	 cls_loss: 0.2163 cluster_loss: 1.2801 sup_con_loss: 0.4919 contrastive_loss: 4.5795 
2023-11-10 14:10:32.660 | INFO     | __main__:train:108 - Epoch: [116][60/63]	 loss 4.07299	 cls_loss: 0.1910 cluster_loss: 1.2365 sup_con_loss: 0.6613 contrastive_loss: 4.5707 
2023-11-10 14:10:36.459 | INFO     | __main__:train:111 - Train Epoch: 116 Avg Loss: 4.0364 
2023-11-10 14:10:36.461 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:11:27.006 | INFO     | __main__:train:119 - Train Accuracies: All 0.7604 | Old 0.8134 | New 0.7341
2023-11-10 14:11:36.433 | INFO     | __main__:train:108 - Epoch: [117][0/63]	 loss 4.15079	 cls_loss: 0.1986 cluster_loss: 1.3295 sup_con_loss: 0.6913 contrastive_loss: 4.5772 
2023-11-10 14:11:55.472 | INFO     | __main__:train:108 - Epoch: [117][10/63]	 loss 4.00143	 cls_loss: 0.2113 cluster_loss: 1.1753 sup_con_loss: 0.5458 contrastive_loss: 4.5731 
2023-11-10 14:12:14.360 | INFO     | __main__:train:108 - Epoch: [117][20/63]	 loss 4.13996	 cls_loss: 0.1994 cluster_loss: 1.2877 sup_con_loss: 0.7466 contrastive_loss: 4.5720 
2023-11-10 14:12:33.234 | INFO     | __main__:train:108 - Epoch: [117][30/63]	 loss 4.14677	 cls_loss: 0.2143 cluster_loss: 1.2698 sup_con_loss: 0.7808 contrastive_loss: 4.5740 
2023-11-10 14:12:52.106 | INFO     | __main__:train:108 - Epoch: [117][40/63]	 loss 4.03380	 cls_loss: 0.2310 cluster_loss: 1.1629 sup_con_loss: 0.6499 contrastive_loss: 4.5686 
2023-11-10 14:13:10.968 | INFO     | __main__:train:108 - Epoch: [117][50/63]	 loss 4.06846	 cls_loss: 0.2242 cluster_loss: 1.1803 sup_con_loss: 0.7178 contrastive_loss: 4.5716 
2023-11-10 14:13:29.744 | INFO     | __main__:train:108 - Epoch: [117][60/63]	 loss 4.08758	 cls_loss: 0.2201 cluster_loss: 1.2316 sup_con_loss: 0.6853 contrastive_loss: 4.5695 
2023-11-10 14:13:33.528 | INFO     | __main__:train:111 - Train Epoch: 117 Avg Loss: 4.0718 
2023-11-10 14:13:33.529 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:14:24.237 | INFO     | __main__:train:119 - Train Accuracies: All 0.7677 | Old 0.8045 | New 0.7495
2023-11-10 14:14:33.033 | INFO     | __main__:train:108 - Epoch: [118][0/63]	 loss 4.05861	 cls_loss: 0.2016 cluster_loss: 1.2219 sup_con_loss: 0.6321 contrastive_loss: 4.5732 
2023-11-10 14:14:52.133 | INFO     | __main__:train:108 - Epoch: [118][10/63]	 loss 4.03458	 cls_loss: 0.2263 cluster_loss: 1.1966 sup_con_loss: 0.5728 contrastive_loss: 4.5802 
2023-11-10 14:15:11.039 | INFO     | __main__:train:108 - Epoch: [118][20/63]	 loss 4.04419	 cls_loss: 0.1944 cluster_loss: 1.2160 sup_con_loss: 0.6113 contrastive_loss: 4.5720 
2023-11-10 14:15:29.931 | INFO     | __main__:train:108 - Epoch: [118][30/63]	 loss 4.03107	 cls_loss: 0.1915 cluster_loss: 1.1786 sup_con_loss: 0.6521 contrastive_loss: 4.5688 
2023-11-10 14:15:48.882 | INFO     | __main__:train:108 - Epoch: [118][40/63]	 loss 4.01588	 cls_loss: 0.2265 cluster_loss: 1.1650 sup_con_loss: 0.6015 contrastive_loss: 4.5675 
2023-11-10 14:16:07.681 | INFO     | __main__:train:108 - Epoch: [118][50/63]	 loss 4.02335	 cls_loss: 0.2145 cluster_loss: 1.2266 sup_con_loss: 0.5107 contrastive_loss: 4.5727 
2023-11-10 14:16:26.397 | INFO     | __main__:train:108 - Epoch: [118][60/63]	 loss 3.94373	 cls_loss: 0.2021 cluster_loss: 1.1420 sup_con_loss: 0.4616 contrastive_loss: 4.5680 
2023-11-10 14:16:30.283 | INFO     | __main__:train:111 - Train Epoch: 118 Avg Loss: 4.0417 
2023-11-10 14:16:30.283 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:17:20.339 | INFO     | __main__:train:119 - Train Accuracies: All 0.7653 | Old 0.8164 | New 0.7400
2023-11-10 14:17:30.799 | INFO     | __main__:train:108 - Epoch: [119][0/63]	 loss 4.01333	 cls_loss: 0.2172 cluster_loss: 1.1712 sup_con_loss: 0.5847 contrastive_loss: 4.5713 
2023-11-10 14:17:49.937 | INFO     | __main__:train:108 - Epoch: [119][10/63]	 loss 4.05016	 cls_loss: 0.2056 cluster_loss: 1.2087 sup_con_loss: 0.6284 contrastive_loss: 4.5733 
2023-11-10 14:18:08.779 | INFO     | __main__:train:108 - Epoch: [119][20/63]	 loss 4.09609	 cls_loss: 0.1988 cluster_loss: 1.2321 sup_con_loss: 0.7370 contrastive_loss: 4.5658 
2023-11-10 14:18:27.619 | INFO     | __main__:train:108 - Epoch: [119][30/63]	 loss 4.09348	 cls_loss: 0.2224 cluster_loss: 1.2118 sup_con_loss: 0.7312 contrastive_loss: 4.5724 
2023-11-10 14:18:46.518 | INFO     | __main__:train:108 - Epoch: [119][40/63]	 loss 3.99388	 cls_loss: 0.2105 cluster_loss: 1.1314 sup_con_loss: 0.6090 contrastive_loss: 4.5718 
2023-11-10 14:19:05.350 | INFO     | __main__:train:108 - Epoch: [119][50/63]	 loss 3.95658	 cls_loss: 0.2018 cluster_loss: 1.1647 sup_con_loss: 0.4548 contrastive_loss: 4.5688 
2023-11-10 14:19:24.109 | INFO     | __main__:train:108 - Epoch: [119][60/63]	 loss 3.89053	 cls_loss: 0.2115 cluster_loss: 1.1072 sup_con_loss: 0.3623 contrastive_loss: 4.5693 
2023-11-10 14:19:27.890 | INFO     | __main__:train:111 - Train Epoch: 119 Avg Loss: 4.0206 
2023-11-10 14:19:27.890 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:20:18.285 | INFO     | __main__:train:119 - Train Accuracies: All 0.7614 | Old 0.8055 | New 0.7395
2023-11-10 14:20:29.337 | INFO     | __main__:train:108 - Epoch: [120][0/63]	 loss 4.06176	 cls_loss: 0.2218 cluster_loss: 1.2218 sup_con_loss: 0.6127 contrastive_loss: 4.5777 
2023-11-10 14:20:48.400 | INFO     | __main__:train:108 - Epoch: [120][10/63]	 loss 3.93866	 cls_loss: 0.2212 cluster_loss: 1.1103 sup_con_loss: 0.4927 contrastive_loss: 4.5648 
2023-11-10 14:21:07.216 | INFO     | __main__:train:108 - Epoch: [120][20/63]	 loss 4.02970	 cls_loss: 0.2078 cluster_loss: 1.2175 sup_con_loss: 0.5462 contrastive_loss: 4.5761 
2023-11-10 14:21:26.124 | INFO     | __main__:train:108 - Epoch: [120][30/63]	 loss 4.25248	 cls_loss: 0.2243 cluster_loss: 1.2591 sup_con_loss: 1.0991 contrastive_loss: 4.5705 
2023-11-10 14:21:45.021 | INFO     | __main__:train:108 - Epoch: [120][40/63]	 loss 4.13713	 cls_loss: 0.2458 cluster_loss: 1.2317 sup_con_loss: 0.7945 contrastive_loss: 4.5730 
2023-11-10 14:22:03.887 | INFO     | __main__:train:108 - Epoch: [120][50/63]	 loss 4.05736	 cls_loss: 0.2185 cluster_loss: 1.2102 sup_con_loss: 0.6399 contrastive_loss: 4.5697 
2023-11-10 14:22:22.595 | INFO     | __main__:train:108 - Epoch: [120][60/63]	 loss 3.91786	 cls_loss: 0.2282 cluster_loss: 1.0951 sup_con_loss: 0.4471 contrastive_loss: 4.5688 
2023-11-10 14:22:26.382 | INFO     | __main__:train:111 - Train Epoch: 120 Avg Loss: 4.0544 
2023-11-10 14:22:26.383 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:23:16.234 | INFO     | __main__:train:119 - Train Accuracies: All 0.7659 | Old 0.8100 | New 0.7441
2023-11-10 14:23:26.898 | INFO     | __main__:train:108 - Epoch: [121][0/63]	 loss 4.03850	 cls_loss: 0.2126 cluster_loss: 1.1632 sup_con_loss: 0.6839 contrastive_loss: 4.5671 
2023-11-10 14:23:45.861 | INFO     | __main__:train:108 - Epoch: [121][10/63]	 loss 4.12074	 cls_loss: 0.2044 cluster_loss: 1.2428 sup_con_loss: 0.7691 contrastive_loss: 4.5726 
2023-11-10 14:24:04.723 | INFO     | __main__:train:108 - Epoch: [121][20/63]	 loss 4.01836	 cls_loss: 0.2060 cluster_loss: 1.1695 sup_con_loss: 0.6207 contrastive_loss: 4.5675 
2023-11-10 14:24:23.635 | INFO     | __main__:train:108 - Epoch: [121][30/63]	 loss 4.15143	 cls_loss: 0.2304 cluster_loss: 1.3146 sup_con_loss: 0.7019 contrastive_loss: 4.5701 
2023-11-10 14:24:42.536 | INFO     | __main__:train:108 - Epoch: [121][40/63]	 loss 4.13578	 cls_loss: 0.2174 cluster_loss: 1.2563 sup_con_loss: 0.7701 contrastive_loss: 4.5747 
2023-11-10 14:25:01.406 | INFO     | __main__:train:108 - Epoch: [121][50/63]	 loss 4.10338	 cls_loss: 0.2269 cluster_loss: 1.2598 sup_con_loss: 0.6665 contrastive_loss: 4.5721 
2023-11-10 14:25:20.119 | INFO     | __main__:train:108 - Epoch: [121][60/63]	 loss 4.03952	 cls_loss: 0.2155 cluster_loss: 1.1894 sup_con_loss: 0.6266 contrastive_loss: 4.5718 
2023-11-10 14:25:23.927 | INFO     | __main__:train:111 - Train Epoch: 121 Avg Loss: 4.0513 
2023-11-10 14:25:23.928 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:26:14.851 | INFO     | __main__:train:119 - Train Accuracies: All 0.7658 | Old 0.8090 | New 0.7444
2023-11-10 14:26:24.754 | INFO     | __main__:train:108 - Epoch: [122][0/63]	 loss 4.22475	 cls_loss: 0.1974 cluster_loss: 1.3462 sup_con_loss: 0.8848 contrastive_loss: 4.5708 
2023-11-10 14:26:43.746 | INFO     | __main__:train:108 - Epoch: [122][10/63]	 loss 4.06789	 cls_loss: 0.2049 cluster_loss: 1.2401 sup_con_loss: 0.6121 contrastive_loss: 4.5782 
2023-11-10 14:27:02.642 | INFO     | __main__:train:108 - Epoch: [122][20/63]	 loss 3.87571	 cls_loss: 0.2130 cluster_loss: 1.0622 sup_con_loss: 0.4041 contrastive_loss: 4.5682 
2023-11-10 14:27:21.516 | INFO     | __main__:train:108 - Epoch: [122][30/63]	 loss 4.02118	 cls_loss: 0.2047 cluster_loss: 1.1597 sup_con_loss: 0.6452 contrastive_loss: 4.5691 
2023-11-10 14:27:40.437 | INFO     | __main__:train:108 - Epoch: [122][40/63]	 loss 4.20384	 cls_loss: 0.2032 cluster_loss: 1.3405 sup_con_loss: 0.8222 contrastive_loss: 4.5748 
2023-11-10 14:27:59.360 | INFO     | __main__:train:108 - Epoch: [122][50/63]	 loss 3.93841	 cls_loss: 0.2345 cluster_loss: 1.1277 sup_con_loss: 0.4337 contrastive_loss: 4.5717 
2023-11-10 14:28:18.130 | INFO     | __main__:train:108 - Epoch: [122][60/63]	 loss 4.05516	 cls_loss: 0.1989 cluster_loss: 1.2436 sup_con_loss: 0.5857 contrastive_loss: 4.5726 
2023-11-10 14:28:21.949 | INFO     | __main__:train:111 - Train Epoch: 122 Avg Loss: 4.0391 
2023-11-10 14:28:21.950 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:29:12.519 | INFO     | __main__:train:119 - Train Accuracies: All 0.7648 | Old 0.8070 | New 0.7439
2023-11-10 14:29:22.507 | INFO     | __main__:train:108 - Epoch: [123][0/63]	 loss 4.18762	 cls_loss: 0.2027 cluster_loss: 1.3176 sup_con_loss: 0.8238 contrastive_loss: 4.5721 
2023-11-10 14:29:41.512 | INFO     | __main__:train:108 - Epoch: [123][10/63]	 loss 3.98545	 cls_loss: 0.2271 cluster_loss: 1.2245 sup_con_loss: 0.3801 contrastive_loss: 4.5800 
2023-11-10 14:30:00.332 | INFO     | __main__:train:108 - Epoch: [123][20/63]	 loss 4.11177	 cls_loss: 0.2117 cluster_loss: 1.2358 sup_con_loss: 0.7514 contrastive_loss: 4.5714 
2023-11-10 14:30:19.222 | INFO     | __main__:train:108 - Epoch: [123][30/63]	 loss 3.91965	 cls_loss: 0.2274 cluster_loss: 1.1235 sup_con_loss: 0.4028 contrastive_loss: 4.5674 
2023-11-10 14:30:38.079 | INFO     | __main__:train:108 - Epoch: [123][40/63]	 loss 4.04228	 cls_loss: 0.2224 cluster_loss: 1.2676 sup_con_loss: 0.4792 contrastive_loss: 4.5735 
2023-11-10 14:30:56.948 | INFO     | __main__:train:108 - Epoch: [123][50/63]	 loss 4.05555	 cls_loss: 0.2081 cluster_loss: 1.1733 sup_con_loss: 0.7175 contrastive_loss: 4.5676 
2023-11-10 14:31:15.788 | INFO     | __main__:train:108 - Epoch: [123][60/63]	 loss 4.00141	 cls_loss: 0.2015 cluster_loss: 1.1803 sup_con_loss: 0.5558 contrastive_loss: 4.5680 
2023-11-10 14:31:19.581 | INFO     | __main__:train:111 - Train Epoch: 123 Avg Loss: 4.0358 
2023-11-10 14:31:19.582 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:32:09.360 | INFO     | __main__:train:119 - Train Accuracies: All 0.7643 | Old 0.8075 | New 0.7429
2023-11-10 14:32:20.871 | INFO     | __main__:train:108 - Epoch: [124][0/63]	 loss 4.05131	 cls_loss: 0.2302 cluster_loss: 1.2144 sup_con_loss: 0.5992 contrastive_loss: 4.5718 
2023-11-10 14:32:39.796 | INFO     | __main__:train:108 - Epoch: [124][10/63]	 loss 4.06364	 cls_loss: 0.1916 cluster_loss: 1.2221 sup_con_loss: 0.6641 contrastive_loss: 4.5689 
2023-11-10 14:32:58.693 | INFO     | __main__:train:108 - Epoch: [124][20/63]	 loss 3.99577	 cls_loss: 0.2114 cluster_loss: 1.1676 sup_con_loss: 0.5467 contrastive_loss: 4.5715 
2023-11-10 14:33:17.540 | INFO     | __main__:train:108 - Epoch: [124][30/63]	 loss 4.10001	 cls_loss: 0.2022 cluster_loss: 1.2679 sup_con_loss: 0.6677 contrastive_loss: 4.5714 
2023-11-10 14:33:36.441 | INFO     | __main__:train:108 - Epoch: [124][40/63]	 loss 4.08030	 cls_loss: 0.2318 cluster_loss: 1.2135 sup_con_loss: 0.6820 contrastive_loss: 4.5719 
2023-11-10 14:33:55.252 | INFO     | __main__:train:108 - Epoch: [124][50/63]	 loss 4.03275	 cls_loss: 0.1988 cluster_loss: 1.2201 sup_con_loss: 0.5657 contrastive_loss: 4.5725 
2023-11-10 14:34:13.937 | INFO     | __main__:train:108 - Epoch: [124][60/63]	 loss 4.06236	 cls_loss: 0.1962 cluster_loss: 1.2477 sup_con_loss: 0.5980 contrastive_loss: 4.5744 
2023-11-10 14:34:17.743 | INFO     | __main__:train:111 - Train Epoch: 124 Avg Loss: 4.0261 
2023-11-10 14:34:17.744 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:35:08.072 | INFO     | __main__:train:119 - Train Accuracies: All 0.7681 | Old 0.8169 | New 0.7439
2023-11-10 14:35:17.884 | INFO     | __main__:train:108 - Epoch: [125][0/63]	 loss 4.00515	 cls_loss: 0.2029 cluster_loss: 1.1449 sup_con_loss: 0.6247 contrastive_loss: 4.5712 
2023-11-10 14:35:36.974 | INFO     | __main__:train:108 - Epoch: [125][10/63]	 loss 4.13754	 cls_loss: 0.2054 cluster_loss: 1.2530 sup_con_loss: 0.7994 contrastive_loss: 4.5714 
2023-11-10 14:35:55.789 | INFO     | __main__:train:108 - Epoch: [125][20/63]	 loss 4.02311	 cls_loss: 0.2138 cluster_loss: 1.2161 sup_con_loss: 0.5203 contrastive_loss: 4.5780 
2023-11-10 14:36:14.656 | INFO     | __main__:train:108 - Epoch: [125][30/63]	 loss 4.05884	 cls_loss: 0.1959 cluster_loss: 1.2505 sup_con_loss: 0.5836 contrastive_loss: 4.5741 
2023-11-10 14:36:33.594 | INFO     | __main__:train:108 - Epoch: [125][40/63]	 loss 4.01093	 cls_loss: 0.1949 cluster_loss: 1.1877 sup_con_loss: 0.5717 contrastive_loss: 4.5701 
2023-11-10 14:36:52.418 | INFO     | __main__:train:108 - Epoch: [125][50/63]	 loss 4.08099	 cls_loss: 0.2218 cluster_loss: 1.2016 sup_con_loss: 0.7078 contrastive_loss: 4.5763 
2023-11-10 14:37:11.077 | INFO     | __main__:train:108 - Epoch: [125][60/63]	 loss 3.93368	 cls_loss: 0.2218 cluster_loss: 1.1266 sup_con_loss: 0.4463 contrastive_loss: 4.5655 
2023-11-10 14:37:14.853 | INFO     | __main__:train:111 - Train Epoch: 125 Avg Loss: 4.0323 
2023-11-10 14:37:14.854 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:38:05.103 | INFO     | __main__:train:119 - Train Accuracies: All 0.7625 | Old 0.8090 | New 0.7395
2023-11-10 14:38:14.979 | INFO     | __main__:train:108 - Epoch: [126][0/63]	 loss 4.00799	 cls_loss: 0.2088 cluster_loss: 1.2034 sup_con_loss: 0.5125 contrastive_loss: 4.5744 
2023-11-10 14:38:33.974 | INFO     | __main__:train:108 - Epoch: [126][10/63]	 loss 3.99169	 cls_loss: 0.2028 cluster_loss: 1.1688 sup_con_loss: 0.5460 contrastive_loss: 4.5690 
2023-11-10 14:38:52.818 | INFO     | __main__:train:108 - Epoch: [126][20/63]	 loss 4.20445	 cls_loss: 0.2055 cluster_loss: 1.3436 sup_con_loss: 0.8205 contrastive_loss: 4.5723 
2023-11-10 14:39:11.670 | INFO     | __main__:train:108 - Epoch: [126][30/63]	 loss 4.07374	 cls_loss: 0.2163 cluster_loss: 1.2145 sup_con_loss: 0.6673 contrastive_loss: 4.5770 
2023-11-10 14:39:30.550 | INFO     | __main__:train:108 - Epoch: [126][40/63]	 loss 3.97699	 cls_loss: 0.2186 cluster_loss: 1.0915 sup_con_loss: 0.6362 contrastive_loss: 4.5666 
2023-11-10 14:39:49.420 | INFO     | __main__:train:108 - Epoch: [126][50/63]	 loss 4.03817	 cls_loss: 0.2191 cluster_loss: 1.2138 sup_con_loss: 0.5675 contrastive_loss: 4.5753 
2023-11-10 14:40:08.124 | INFO     | __main__:train:108 - Epoch: [126][60/63]	 loss 4.03527	 cls_loss: 0.1983 cluster_loss: 1.1737 sup_con_loss: 0.6680 contrastive_loss: 4.5680 
2023-11-10 14:40:11.913 | INFO     | __main__:train:111 - Train Epoch: 126 Avg Loss: 4.0423 
2023-11-10 14:40:11.914 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:41:02.356 | INFO     | __main__:train:119 - Train Accuracies: All 0.7643 | Old 0.8110 | New 0.7412
2023-11-10 14:41:13.172 | INFO     | __main__:train:108 - Epoch: [127][0/63]	 loss 4.06526	 cls_loss: 0.2247 cluster_loss: 1.2311 sup_con_loss: 0.6046 contrastive_loss: 4.5767 
2023-11-10 14:41:32.168 | INFO     | __main__:train:108 - Epoch: [127][10/63]	 loss 3.99614	 cls_loss: 0.1932 cluster_loss: 1.1650 sup_con_loss: 0.5783 contrastive_loss: 4.5676 
2023-11-10 14:41:51.006 | INFO     | __main__:train:108 - Epoch: [127][20/63]	 loss 3.96290	 cls_loss: 0.2004 cluster_loss: 1.1318 sup_con_loss: 0.5379 contrastive_loss: 4.5674 
2023-11-10 14:42:09.891 | INFO     | __main__:train:108 - Epoch: [127][30/63]	 loss 4.13926	 cls_loss: 0.2166 cluster_loss: 1.3138 sup_con_loss: 0.6802 contrastive_loss: 4.5715 
2023-11-10 14:42:28.732 | INFO     | __main__:train:108 - Epoch: [127][40/63]	 loss 3.95978	 cls_loss: 0.2333 cluster_loss: 1.1011 sup_con_loss: 0.5560 contrastive_loss: 4.5658 
2023-11-10 14:42:47.613 | INFO     | __main__:train:108 - Epoch: [127][50/63]	 loss 3.87257	 cls_loss: 0.2176 cluster_loss: 1.0522 sup_con_loss: 0.4108 contrastive_loss: 4.5672 
2023-11-10 14:43:06.315 | INFO     | __main__:train:108 - Epoch: [127][60/63]	 loss 4.06708	 cls_loss: 0.2348 cluster_loss: 1.2163 sup_con_loss: 0.6388 contrastive_loss: 4.5703 
2023-11-10 14:43:10.100 | INFO     | __main__:train:111 - Train Epoch: 127 Avg Loss: 4.0449 
2023-11-10 14:43:10.101 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:44:00.476 | INFO     | __main__:train:119 - Train Accuracies: All 0.7632 | Old 0.8006 | New 0.7446
2023-11-10 14:44:10.161 | INFO     | __main__:train:108 - Epoch: [128][0/63]	 loss 4.01886	 cls_loss: 0.2323 cluster_loss: 1.1817 sup_con_loss: 0.5664 contrastive_loss: 4.5711 
2023-11-10 14:44:29.235 | INFO     | __main__:train:108 - Epoch: [128][10/63]	 loss 4.04294	 cls_loss: 0.2037 cluster_loss: 1.2060 sup_con_loss: 0.6200 contrastive_loss: 4.5704 
2023-11-10 14:44:48.139 | INFO     | __main__:train:108 - Epoch: [128][20/63]	 loss 3.98136	 cls_loss: 0.1949 cluster_loss: 1.1461 sup_con_loss: 0.5652 contrastive_loss: 4.5698 
2023-11-10 14:45:07.062 | INFO     | __main__:train:108 - Epoch: [128][30/63]	 loss 4.11870	 cls_loss: 0.2195 cluster_loss: 1.2370 sup_con_loss: 0.7621 contrastive_loss: 4.5709 
2023-11-10 14:45:25.918 | INFO     | __main__:train:108 - Epoch: [128][40/63]	 loss 4.02481	 cls_loss: 0.2031 cluster_loss: 1.1532 sup_con_loss: 0.6726 contrastive_loss: 4.5673 
2023-11-10 14:45:44.786 | INFO     | __main__:train:108 - Epoch: [128][50/63]	 loss 4.05455	 cls_loss: 0.2083 cluster_loss: 1.1848 sup_con_loss: 0.6911 contrastive_loss: 4.5688 
2023-11-10 14:46:03.481 | INFO     | __main__:train:108 - Epoch: [128][60/63]	 loss 3.97799	 cls_loss: 0.2202 cluster_loss: 1.1459 sup_con_loss: 0.5438 contrastive_loss: 4.5627 
2023-11-10 14:46:07.300 | INFO     | __main__:train:111 - Train Epoch: 128 Avg Loss: 4.0207 
2023-11-10 14:46:07.300 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:46:57.455 | INFO     | __main__:train:119 - Train Accuracies: All 0.7650 | Old 0.8134 | New 0.7410
2023-11-10 14:47:06.331 | INFO     | __main__:train:108 - Epoch: [129][0/63]	 loss 3.95113	 cls_loss: 0.1932 cluster_loss: 1.1413 sup_con_loss: 0.4914 contrastive_loss: 4.5688 
2023-11-10 14:47:25.704 | INFO     | __main__:train:108 - Epoch: [129][10/63]	 loss 4.07382	 cls_loss: 0.2238 cluster_loss: 1.2700 sup_con_loss: 0.5707 contrastive_loss: 4.5696 
2023-11-10 14:47:44.595 | INFO     | __main__:train:108 - Epoch: [129][20/63]	 loss 4.03302	 cls_loss: 0.2198 cluster_loss: 1.1801 sup_con_loss: 0.6261 contrastive_loss: 4.5690 
2023-11-10 14:48:03.454 | INFO     | __main__:train:108 - Epoch: [129][30/63]	 loss 4.04671	 cls_loss: 0.1972 cluster_loss: 1.2206 sup_con_loss: 0.6086 contrastive_loss: 4.5712 
2023-11-10 14:48:22.421 | INFO     | __main__:train:108 - Epoch: [129][40/63]	 loss 3.99927	 cls_loss: 0.2093 cluster_loss: 1.1301 sup_con_loss: 0.6396 contrastive_loss: 4.5655 
2023-11-10 14:48:41.290 | INFO     | __main__:train:108 - Epoch: [129][50/63]	 loss 3.92179	 cls_loss: 0.2161 cluster_loss: 1.1058 sup_con_loss: 0.4549 contrastive_loss: 4.5664 
2023-11-10 14:48:59.994 | INFO     | __main__:train:108 - Epoch: [129][60/63]	 loss 3.91187	 cls_loss: 0.2082 cluster_loss: 1.0866 sup_con_loss: 0.4646 contrastive_loss: 4.5694 
2023-11-10 14:49:03.791 | INFO     | __main__:train:111 - Train Epoch: 129 Avg Loss: 4.0303 
2023-11-10 14:49:03.791 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:49:54.302 | INFO     | __main__:train:119 - Train Accuracies: All 0.7658 | Old 0.8100 | New 0.7439
2023-11-10 14:50:02.581 | INFO     | __main__:train:108 - Epoch: [130][0/63]	 loss 3.97851	 cls_loss: 0.2171 cluster_loss: 1.1249 sup_con_loss: 0.5850 contrastive_loss: 4.5640 
2023-11-10 14:50:21.713 | INFO     | __main__:train:108 - Epoch: [130][10/63]	 loss 4.06122	 cls_loss: 0.2298 cluster_loss: 1.1845 sup_con_loss: 0.6887 contrastive_loss: 4.5690 
2023-11-10 14:50:40.577 | INFO     | __main__:train:108 - Epoch: [130][20/63]	 loss 4.12201	 cls_loss: 0.1965 cluster_loss: 1.2544 sup_con_loss: 0.7658 contrastive_loss: 4.5689 
2023-11-10 14:50:59.471 | INFO     | __main__:train:108 - Epoch: [130][30/63]	 loss 3.86665	 cls_loss: 0.2194 cluster_loss: 1.0637 sup_con_loss: 0.3693 contrastive_loss: 4.5680 
2023-11-10 14:51:18.425 | INFO     | __main__:train:108 - Epoch: [130][40/63]	 loss 3.99029	 cls_loss: 0.2079 cluster_loss: 1.1547 sup_con_loss: 0.5638 contrastive_loss: 4.5687 
2023-11-10 14:51:37.302 | INFO     | __main__:train:108 - Epoch: [130][50/63]	 loss 3.97125	 cls_loss: 0.2121 cluster_loss: 1.1309 sup_con_loss: 0.5501 contrastive_loss: 4.5683 
2023-11-10 14:51:56.063 | INFO     | __main__:train:108 - Epoch: [130][60/63]	 loss 3.99424	 cls_loss: 0.2103 cluster_loss: 1.1563 sup_con_loss: 0.5684 contrastive_loss: 4.5694 
2023-11-10 14:51:59.835 | INFO     | __main__:train:111 - Train Epoch: 130 Avg Loss: 4.0357 
2023-11-10 14:51:59.835 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:52:49.770 | INFO     | __main__:train:119 - Train Accuracies: All 0.7679 | Old 0.8124 | New 0.7458
2023-11-10 14:52:58.727 | INFO     | __main__:train:108 - Epoch: [131][0/63]	 loss 3.97891	 cls_loss: 0.2016 cluster_loss: 1.1186 sup_con_loss: 0.6115 contrastive_loss: 4.5650 
2023-11-10 14:53:17.902 | INFO     | __main__:train:108 - Epoch: [131][10/63]	 loss 4.00071	 cls_loss: 0.1898 cluster_loss: 1.1774 sup_con_loss: 0.5679 contrastive_loss: 4.5696 
2023-11-10 14:53:36.773 | INFO     | __main__:train:108 - Epoch: [131][20/63]	 loss 3.93583	 cls_loss: 0.2005 cluster_loss: 1.1096 sup_con_loss: 0.5004 contrastive_loss: 4.5681 
2023-11-10 14:53:55.674 | INFO     | __main__:train:108 - Epoch: [131][30/63]	 loss 4.09846	 cls_loss: 0.2246 cluster_loss: 1.2184 sup_con_loss: 0.7399 contrastive_loss: 4.5675 
2023-11-10 14:54:14.618 | INFO     | __main__:train:108 - Epoch: [131][40/63]	 loss 4.00148	 cls_loss: 0.1971 cluster_loss: 1.1961 sup_con_loss: 0.5200 contrastive_loss: 4.5738 
2023-11-10 14:54:33.492 | INFO     | __main__:train:108 - Epoch: [131][50/63]	 loss 3.93819	 cls_loss: 0.2209 cluster_loss: 1.1279 sup_con_loss: 0.4475 contrastive_loss: 4.5709 
2023-11-10 14:54:52.256 | INFO     | __main__:train:108 - Epoch: [131][60/63]	 loss 4.12311	 cls_loss: 0.2065 cluster_loss: 1.2573 sup_con_loss: 0.7540 contrastive_loss: 4.5687 
2023-11-10 14:54:56.014 | INFO     | __main__:train:111 - Train Epoch: 131 Avg Loss: 4.0320 
2023-11-10 14:54:56.015 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:55:46.952 | INFO     | __main__:train:119 - Train Accuracies: All 0.7703 | Old 0.8149 | New 0.7483
2023-11-10 14:55:57.535 | INFO     | __main__:train:108 - Epoch: [132][0/63]	 loss 4.12471	 cls_loss: 0.2076 cluster_loss: 1.2733 sup_con_loss: 0.7215 contrastive_loss: 4.5722 
2023-11-10 14:56:16.591 | INFO     | __main__:train:108 - Epoch: [132][10/63]	 loss 4.03084	 cls_loss: 0.2074 cluster_loss: 1.2003 sup_con_loss: 0.5976 contrastive_loss: 4.5675 
2023-11-10 14:56:35.410 | INFO     | __main__:train:108 - Epoch: [132][20/63]	 loss 3.95632	 cls_loss: 0.2158 cluster_loss: 1.1149 sup_con_loss: 0.5335 contrastive_loss: 4.5683 
2023-11-10 14:56:54.264 | INFO     | __main__:train:108 - Epoch: [132][30/63]	 loss 4.07786	 cls_loss: 0.2234 cluster_loss: 1.2156 sup_con_loss: 0.6844 contrastive_loss: 4.5692 
2023-11-10 14:57:13.192 | INFO     | __main__:train:108 - Epoch: [132][40/63]	 loss 4.15975	 cls_loss: 0.2028 cluster_loss: 1.2823 sup_con_loss: 0.8059 contrastive_loss: 4.5742 
2023-11-10 14:57:32.034 | INFO     | __main__:train:108 - Epoch: [132][50/63]	 loss 3.98241	 cls_loss: 0.2127 cluster_loss: 1.1254 sup_con_loss: 0.5964 contrastive_loss: 4.5657 
2023-11-10 14:57:50.737 | INFO     | __main__:train:108 - Epoch: [132][60/63]	 loss 4.02771	 cls_loss: 0.2107 cluster_loss: 1.1813 sup_con_loss: 0.6209 contrastive_loss: 4.5673 
2023-11-10 14:57:54.531 | INFO     | __main__:train:111 - Train Epoch: 132 Avg Loss: 4.0456 
2023-11-10 14:57:54.531 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 14:58:45.379 | INFO     | __main__:train:119 - Train Accuracies: All 0.7695 | Old 0.8198 | New 0.7446
2023-11-10 14:58:55.446 | INFO     | __main__:train:108 - Epoch: [133][0/63]	 loss 4.05979	 cls_loss: 0.1982 cluster_loss: 1.2329 sup_con_loss: 0.6312 contrastive_loss: 4.5664 
2023-11-10 14:59:14.506 | INFO     | __main__:train:108 - Epoch: [133][10/63]	 loss 3.93280	 cls_loss: 0.1990 cluster_loss: 1.1055 sup_con_loss: 0.5069 contrastive_loss: 4.5648 
2023-11-10 14:59:33.363 | INFO     | __main__:train:108 - Epoch: [133][20/63]	 loss 4.02216	 cls_loss: 0.1890 cluster_loss: 1.1964 sup_con_loss: 0.6013 contrastive_loss: 4.5660 
2023-11-10 14:59:52.229 | INFO     | __main__:train:108 - Epoch: [133][30/63]	 loss 4.10717	 cls_loss: 0.2141 cluster_loss: 1.1976 sup_con_loss: 0.8136 contrastive_loss: 4.5677 
2023-11-10 15:00:11.083 | INFO     | __main__:train:108 - Epoch: [133][40/63]	 loss 4.11737	 cls_loss: 0.2228 cluster_loss: 1.2291 sup_con_loss: 0.7687 contrastive_loss: 4.5714 
2023-11-10 15:00:29.945 | INFO     | __main__:train:108 - Epoch: [133][50/63]	 loss 4.09914	 cls_loss: 0.2304 cluster_loss: 1.2060 sup_con_loss: 0.7525 contrastive_loss: 4.5711 
2023-11-10 15:00:48.625 | INFO     | __main__:train:108 - Epoch: [133][60/63]	 loss 3.96635	 cls_loss: 0.2055 cluster_loss: 1.1309 sup_con_loss: 0.5479 contrastive_loss: 4.5656 
2023-11-10 15:00:52.418 | INFO     | __main__:train:111 - Train Epoch: 133 Avg Loss: 4.0440 
2023-11-10 15:00:52.419 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:01:43.168 | INFO     | __main__:train:119 - Train Accuracies: All 0.7672 | Old 0.8105 | New 0.7458
2023-11-10 15:01:52.690 | INFO     | __main__:train:108 - Epoch: [134][0/63]	 loss 4.10420	 cls_loss: 0.2154 cluster_loss: 1.2380 sup_con_loss: 0.7258 contrastive_loss: 4.5694 
2023-11-10 15:02:11.946 | INFO     | __main__:train:108 - Epoch: [134][10/63]	 loss 4.12225	 cls_loss: 0.1925 cluster_loss: 1.2775 sup_con_loss: 0.7234 contrastive_loss: 4.5712 
2023-11-10 15:02:30.795 | INFO     | __main__:train:108 - Epoch: [134][20/63]	 loss 4.01178	 cls_loss: 0.2356 cluster_loss: 1.1455 sup_con_loss: 0.6228 contrastive_loss: 4.5643 
2023-11-10 15:02:49.677 | INFO     | __main__:train:108 - Epoch: [134][30/63]	 loss 4.19099	 cls_loss: 0.2109 cluster_loss: 1.2722 sup_con_loss: 0.9146 contrastive_loss: 4.5695 
2023-11-10 15:03:08.596 | INFO     | __main__:train:108 - Epoch: [134][40/63]	 loss 3.96114	 cls_loss: 0.2099 cluster_loss: 1.1399 sup_con_loss: 0.5036 contrastive_loss: 4.5700 
2023-11-10 15:03:27.444 | INFO     | __main__:train:108 - Epoch: [134][50/63]	 loss 4.01940	 cls_loss: 0.2180 cluster_loss: 1.2367 sup_con_loss: 0.4706 contrastive_loss: 4.5762 
2023-11-10 15:03:46.242 | INFO     | __main__:train:108 - Epoch: [134][60/63]	 loss 3.96196	 cls_loss: 0.2007 cluster_loss: 1.1264 sup_con_loss: 0.5448 contrastive_loss: 4.5675 
2023-11-10 15:03:50.000 | INFO     | __main__:train:111 - Train Epoch: 134 Avg Loss: 4.0329 
2023-11-10 15:03:50.001 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:04:40.641 | INFO     | __main__:train:119 - Train Accuracies: All 0.7713 | Old 0.8233 | New 0.7456
2023-11-10 15:04:51.436 | INFO     | __main__:train:108 - Epoch: [135][0/63]	 loss 4.02132	 cls_loss: 0.1965 cluster_loss: 1.1806 sup_con_loss: 0.6175 contrastive_loss: 4.5677 
2023-11-10 15:05:10.523 | INFO     | __main__:train:108 - Epoch: [135][10/63]	 loss 4.18493	 cls_loss: 0.2041 cluster_loss: 1.3147 sup_con_loss: 0.8136 contrastive_loss: 4.5757 
2023-11-10 15:05:29.338 | INFO     | __main__:train:108 - Epoch: [135][20/63]	 loss 3.95758	 cls_loss: 0.2035 cluster_loss: 1.1233 sup_con_loss: 0.5384 contrastive_loss: 4.5658 
2023-11-10 15:05:48.233 | INFO     | __main__:train:108 - Epoch: [135][30/63]	 loss 4.05274	 cls_loss: 0.2033 cluster_loss: 1.1986 sup_con_loss: 0.6716 contrastive_loss: 4.5653 
2023-11-10 15:06:07.160 | INFO     | __main__:train:108 - Epoch: [135][40/63]	 loss 4.09413	 cls_loss: 0.2082 cluster_loss: 1.2646 sup_con_loss: 0.6517 contrastive_loss: 4.5710 
2023-11-10 15:06:26.017 | INFO     | __main__:train:108 - Epoch: [135][50/63]	 loss 3.95583	 cls_loss: 0.2080 cluster_loss: 1.0921 sup_con_loss: 0.5927 contrastive_loss: 4.5626 
2023-11-10 15:06:44.710 | INFO     | __main__:train:108 - Epoch: [135][60/63]	 loss 4.04578	 cls_loss: 0.2107 cluster_loss: 1.1896 sup_con_loss: 0.6611 contrastive_loss: 4.5652 
2023-11-10 15:06:48.453 | INFO     | __main__:train:111 - Train Epoch: 135 Avg Loss: 4.0237 
2023-11-10 15:06:48.454 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:07:38.523 | INFO     | __main__:train:119 - Train Accuracies: All 0.7708 | Old 0.8159 | New 0.7485
2023-11-10 15:07:48.157 | INFO     | __main__:train:108 - Epoch: [136][0/63]	 loss 4.00339	 cls_loss: 0.2017 cluster_loss: 1.1769 sup_con_loss: 0.5626 contrastive_loss: 4.5706 
2023-11-10 15:08:07.450 | INFO     | __main__:train:108 - Epoch: [136][10/63]	 loss 3.93611	 cls_loss: 0.2003 cluster_loss: 1.0793 sup_con_loss: 0.5673 contrastive_loss: 4.5629 
2023-11-10 15:08:26.296 | INFO     | __main__:train:108 - Epoch: [136][20/63]	 loss 3.93752	 cls_loss: 0.1945 cluster_loss: 1.1265 sup_con_loss: 0.4839 contrastive_loss: 4.5659 
2023-11-10 15:08:45.132 | INFO     | __main__:train:108 - Epoch: [136][30/63]	 loss 4.09605	 cls_loss: 0.2102 cluster_loss: 1.2400 sup_con_loss: 0.7063 contrastive_loss: 4.5681 
2023-11-10 15:09:03.998 | INFO     | __main__:train:108 - Epoch: [136][40/63]	 loss 3.95365	 cls_loss: 0.2091 cluster_loss: 1.1375 sup_con_loss: 0.4937 contrastive_loss: 4.5667 
2023-11-10 15:09:22.839 | INFO     | __main__:train:108 - Epoch: [136][50/63]	 loss 4.10196	 cls_loss: 0.2163 cluster_loss: 1.2734 sup_con_loss: 0.6478 contrastive_loss: 4.5720 
2023-11-10 15:09:41.498 | INFO     | __main__:train:108 - Epoch: [136][60/63]	 loss 4.04265	 cls_loss: 0.2221 cluster_loss: 1.1839 sup_con_loss: 0.6475 contrastive_loss: 4.5673 
2023-11-10 15:09:45.267 | INFO     | __main__:train:111 - Train Epoch: 136 Avg Loss: 4.0420 
2023-11-10 15:09:45.268 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:10:35.896 | INFO     | __main__:train:119 - Train Accuracies: All 0.7687 | Old 0.8115 | New 0.7476
2023-11-10 15:10:46.140 | INFO     | __main__:train:108 - Epoch: [137][0/63]	 loss 3.99814	 cls_loss: 0.2141 cluster_loss: 1.1399 sup_con_loss: 0.6098 contrastive_loss: 4.5675 
2023-11-10 15:11:05.150 | INFO     | __main__:train:108 - Epoch: [137][10/63]	 loss 3.97473	 cls_loss: 0.1963 cluster_loss: 1.1513 sup_con_loss: 0.5373 contrastive_loss: 4.5687 
2023-11-10 15:11:24.014 | INFO     | __main__:train:108 - Epoch: [137][20/63]	 loss 4.02030	 cls_loss: 0.2090 cluster_loss: 1.2268 sup_con_loss: 0.5130 contrastive_loss: 4.5696 
2023-11-10 15:11:42.873 | INFO     | __main__:train:108 - Epoch: [137][30/63]	 loss 4.10302	 cls_loss: 0.2144 cluster_loss: 1.2133 sup_con_loss: 0.7692 contrastive_loss: 4.5694 
2023-11-10 15:12:01.754 | INFO     | __main__:train:108 - Epoch: [137][40/63]	 loss 3.98002	 cls_loss: 0.2092 cluster_loss: 1.1589 sup_con_loss: 0.5314 contrastive_loss: 4.5654 
2023-11-10 15:12:20.635 | INFO     | __main__:train:108 - Epoch: [137][50/63]	 loss 4.07477	 cls_loss: 0.2059 cluster_loss: 1.2348 sup_con_loss: 0.6622 contrastive_loss: 4.5667 
2023-11-10 15:12:39.365 | INFO     | __main__:train:108 - Epoch: [137][60/63]	 loss 3.97052	 cls_loss: 0.2090 cluster_loss: 1.1976 sup_con_loss: 0.4261 contrastive_loss: 4.5689 
2023-11-10 15:12:43.165 | INFO     | __main__:train:111 - Train Epoch: 137 Avg Loss: 4.0245 
2023-11-10 15:12:43.166 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:13:33.655 | INFO     | __main__:train:119 - Train Accuracies: All 0.7686 | Old 0.8139 | New 0.7461
2023-11-10 15:13:43.713 | INFO     | __main__:train:108 - Epoch: [138][0/63]	 loss 4.16995	 cls_loss: 0.2246 cluster_loss: 1.2901 sup_con_loss: 0.8082 contrastive_loss: 4.5691 
2023-11-10 15:14:02.802 | INFO     | __main__:train:108 - Epoch: [138][10/63]	 loss 4.09364	 cls_loss: 0.2136 cluster_loss: 1.2244 sup_con_loss: 0.7203 contrastive_loss: 4.5706 
2023-11-10 15:14:21.676 | INFO     | __main__:train:108 - Epoch: [138][20/63]	 loss 3.94074	 cls_loss: 0.2123 cluster_loss: 1.1453 sup_con_loss: 0.4285 contrastive_loss: 4.5723 
2023-11-10 15:14:40.529 | INFO     | __main__:train:108 - Epoch: [138][30/63]	 loss 4.07007	 cls_loss: 0.2252 cluster_loss: 1.1996 sup_con_loss: 0.6826 contrastive_loss: 4.5732 
2023-11-10 15:14:59.499 | INFO     | __main__:train:108 - Epoch: [138][40/63]	 loss 4.00414	 cls_loss: 0.2180 cluster_loss: 1.1819 sup_con_loss: 0.5335 contrastive_loss: 4.5736 
2023-11-10 15:15:18.330 | INFO     | __main__:train:108 - Epoch: [138][50/63]	 loss 4.06621	 cls_loss: 0.2165 cluster_loss: 1.2352 sup_con_loss: 0.6189 contrastive_loss: 4.5706 
2023-11-10 15:15:37.048 | INFO     | __main__:train:108 - Epoch: [138][60/63]	 loss 4.21084	 cls_loss: 0.2034 cluster_loss: 1.3453 sup_con_loss: 0.8327 contrastive_loss: 4.5750 
2023-11-10 15:15:40.872 | INFO     | __main__:train:111 - Train Epoch: 138 Avg Loss: 4.0260 
2023-11-10 15:15:40.872 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:16:30.856 | INFO     | __main__:train:119 - Train Accuracies: All 0.7681 | Old 0.8134 | New 0.7456
2023-11-10 15:16:42.179 | INFO     | __main__:train:108 - Epoch: [139][0/63]	 loss 4.06855	 cls_loss: 0.2160 cluster_loss: 1.2280 sup_con_loss: 0.6466 contrastive_loss: 4.5669 
2023-11-10 15:17:01.117 | INFO     | __main__:train:108 - Epoch: [139][10/63]	 loss 4.15572	 cls_loss: 0.2164 cluster_loss: 1.2928 sup_con_loss: 0.7618 contrastive_loss: 4.5738 
2023-11-10 15:17:19.968 | INFO     | __main__:train:108 - Epoch: [139][20/63]	 loss 3.92353	 cls_loss: 0.2054 cluster_loss: 1.1196 sup_con_loss: 0.4396 contrastive_loss: 4.5693 
2023-11-10 15:17:38.788 | INFO     | __main__:train:108 - Epoch: [139][30/63]	 loss 4.01174	 cls_loss: 0.2084 cluster_loss: 1.1559 sup_con_loss: 0.6280 contrastive_loss: 4.5656 
2023-11-10 15:17:57.709 | INFO     | __main__:train:108 - Epoch: [139][40/63]	 loss 3.89945	 cls_loss: 0.2171 cluster_loss: 1.0519 sup_con_loss: 0.4947 contrastive_loss: 4.5640 
2023-11-10 15:18:16.541 | INFO     | __main__:train:108 - Epoch: [139][50/63]	 loss 3.92709	 cls_loss: 0.2068 cluster_loss: 1.1062 sup_con_loss: 0.4812 contrastive_loss: 4.5650 
2023-11-10 15:18:35.238 | INFO     | __main__:train:108 - Epoch: [139][60/63]	 loss 4.06414	 cls_loss: 0.2248 cluster_loss: 1.2220 sup_con_loss: 0.6327 contrastive_loss: 4.5688 
2023-11-10 15:18:39.050 | INFO     | __main__:train:111 - Train Epoch: 139 Avg Loss: 4.0160 
2023-11-10 15:18:39.050 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:19:29.425 | INFO     | __main__:train:119 - Train Accuracies: All 0.7705 | Old 0.8159 | New 0.7480
2023-11-10 15:19:38.254 | INFO     | __main__:train:108 - Epoch: [140][0/63]	 loss 3.98626	 cls_loss: 0.2060 cluster_loss: 1.1325 sup_con_loss: 0.5991 contrastive_loss: 4.5667 
2023-11-10 15:19:57.462 | INFO     | __main__:train:108 - Epoch: [140][10/63]	 loss 3.98095	 cls_loss: 0.2004 cluster_loss: 1.1980 sup_con_loss: 0.4687 contrastive_loss: 4.5662 
2023-11-10 15:20:16.334 | INFO     | __main__:train:108 - Epoch: [140][20/63]	 loss 4.00377	 cls_loss: 0.2155 cluster_loss: 1.1511 sup_con_loss: 0.6040 contrastive_loss: 4.5673 
2023-11-10 15:20:35.221 | INFO     | __main__:train:108 - Epoch: [140][30/63]	 loss 4.08255	 cls_loss: 0.2160 cluster_loss: 1.2569 sup_con_loss: 0.6266 contrastive_loss: 4.5702 
2023-11-10 15:20:54.133 | INFO     | __main__:train:108 - Epoch: [140][40/63]	 loss 4.02782	 cls_loss: 0.2262 cluster_loss: 1.1505 sup_con_loss: 0.6658 contrastive_loss: 4.5659 
2023-11-10 15:21:13.019 | INFO     | __main__:train:108 - Epoch: [140][50/63]	 loss 3.91369	 cls_loss: 0.2106 cluster_loss: 1.0719 sup_con_loss: 0.4959 contrastive_loss: 4.5687 
2023-11-10 15:21:31.735 | INFO     | __main__:train:108 - Epoch: [140][60/63]	 loss 4.03839	 cls_loss: 0.1902 cluster_loss: 1.2177 sup_con_loss: 0.6009 contrastive_loss: 4.5692 
2023-11-10 15:21:35.519 | INFO     | __main__:train:111 - Train Epoch: 140 Avg Loss: 4.0237 
2023-11-10 15:21:35.519 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:22:25.378 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8189 | New 0.7476
2023-11-10 15:22:35.057 | INFO     | __main__:train:108 - Epoch: [141][0/63]	 loss 3.97563	 cls_loss: 0.2019 cluster_loss: 1.1602 sup_con_loss: 0.5099 contrastive_loss: 4.5729 
2023-11-10 15:22:54.143 | INFO     | __main__:train:108 - Epoch: [141][10/63]	 loss 4.06188	 cls_loss: 0.1987 cluster_loss: 1.1760 sup_con_loss: 0.7434 contrastive_loss: 4.5658 
2023-11-10 15:23:12.986 | INFO     | __main__:train:108 - Epoch: [141][20/63]	 loss 4.12239	 cls_loss: 0.2022 cluster_loss: 1.2272 sup_con_loss: 0.8146 contrastive_loss: 4.5675 
2023-11-10 15:23:31.878 | INFO     | __main__:train:108 - Epoch: [141][30/63]	 loss 4.03190	 cls_loss: 0.2121 cluster_loss: 1.1967 sup_con_loss: 0.6012 contrastive_loss: 4.5683 
2023-11-10 15:23:50.755 | INFO     | __main__:train:108 - Epoch: [141][40/63]	 loss 3.91609	 cls_loss: 0.1910 cluster_loss: 1.0924 sup_con_loss: 0.4966 contrastive_loss: 4.5622 
2023-11-10 15:24:09.666 | INFO     | __main__:train:108 - Epoch: [141][50/63]	 loss 4.07104	 cls_loss: 0.1977 cluster_loss: 1.2155 sup_con_loss: 0.6894 contrastive_loss: 4.5700 
2023-11-10 15:24:28.408 | INFO     | __main__:train:108 - Epoch: [141][60/63]	 loss 3.94196	 cls_loss: 0.2047 cluster_loss: 1.1547 sup_con_loss: 0.4250 contrastive_loss: 4.5708 
2023-11-10 15:24:32.201 | INFO     | __main__:train:111 - Train Epoch: 141 Avg Loss: 4.0316 
2023-11-10 15:24:32.201 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:25:23.426 | INFO     | __main__:train:119 - Train Accuracies: All 0.7697 | Old 0.8154 | New 0.7471
2023-11-10 15:25:33.016 | INFO     | __main__:train:108 - Epoch: [142][0/63]	 loss 3.90616	 cls_loss: 0.2117 cluster_loss: 1.1238 sup_con_loss: 0.3742 contrastive_loss: 4.5702 
2023-11-10 15:25:52.130 | INFO     | __main__:train:108 - Epoch: [142][10/63]	 loss 3.94295	 cls_loss: 0.1975 cluster_loss: 1.1731 sup_con_loss: 0.4006 contrastive_loss: 4.5709 
2023-11-10 15:26:10.993 | INFO     | __main__:train:108 - Epoch: [142][20/63]	 loss 3.86392	 cls_loss: 0.2165 cluster_loss: 1.0534 sup_con_loss: 0.3921 contrastive_loss: 4.5634 
2023-11-10 15:26:29.908 | INFO     | __main__:train:108 - Epoch: [142][30/63]	 loss 3.97186	 cls_loss: 0.1936 cluster_loss: 1.1407 sup_con_loss: 0.5500 contrastive_loss: 4.5695 
2023-11-10 15:26:48.823 | INFO     | __main__:train:108 - Epoch: [142][40/63]	 loss 4.02285	 cls_loss: 0.2063 cluster_loss: 1.1624 sup_con_loss: 0.6439 contrastive_loss: 4.5688 
2023-11-10 15:27:07.702 | INFO     | __main__:train:108 - Epoch: [142][50/63]	 loss 4.02398	 cls_loss: 0.1967 cluster_loss: 1.1923 sup_con_loss: 0.6009 contrastive_loss: 4.5690 
2023-11-10 15:27:26.465 | INFO     | __main__:train:108 - Epoch: [142][60/63]	 loss 4.00990	 cls_loss: 0.2079 cluster_loss: 1.1685 sup_con_loss: 0.5962 contrastive_loss: 4.5676 
2023-11-10 15:27:30.262 | INFO     | __main__:train:111 - Train Epoch: 142 Avg Loss: 4.0203 
2023-11-10 15:27:30.263 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:28:20.959 | INFO     | __main__:train:119 - Train Accuracies: All 0.7725 | Old 0.8129 | New 0.7524
2023-11-10 15:28:32.632 | INFO     | __main__:train:108 - Epoch: [143][0/63]	 loss 3.95609	 cls_loss: 0.2134 cluster_loss: 1.1994 sup_con_loss: 0.3693 contrastive_loss: 4.5731 
2023-11-10 15:28:51.653 | INFO     | __main__:train:108 - Epoch: [143][10/63]	 loss 3.92517	 cls_loss: 0.2091 cluster_loss: 1.1183 sup_con_loss: 0.4398 contrastive_loss: 4.5711 
2023-11-10 15:29:10.522 | INFO     | __main__:train:108 - Epoch: [143][20/63]	 loss 3.98341	 cls_loss: 0.1993 cluster_loss: 1.1484 sup_con_loss: 0.5644 contrastive_loss: 4.5686 
2023-11-10 15:29:29.430 | INFO     | __main__:train:108 - Epoch: [143][30/63]	 loss 3.99145	 cls_loss: 0.1945 cluster_loss: 1.1463 sup_con_loss: 0.6007 contrastive_loss: 4.5663 
2023-11-10 15:29:48.340 | INFO     | __main__:train:108 - Epoch: [143][40/63]	 loss 3.98859	 cls_loss: 0.2058 cluster_loss: 1.1599 sup_con_loss: 0.5493 contrastive_loss: 4.5698 
2023-11-10 15:30:07.214 | INFO     | __main__:train:108 - Epoch: [143][50/63]	 loss 4.22471	 cls_loss: 0.2021 cluster_loss: 1.3731 sup_con_loss: 0.8219 contrastive_loss: 4.5751 
2023-11-10 15:30:25.935 | INFO     | __main__:train:108 - Epoch: [143][60/63]	 loss 4.11812	 cls_loss: 0.2108 cluster_loss: 1.2881 sup_con_loss: 0.6760 contrastive_loss: 4.5700 
2023-11-10 15:30:29.772 | INFO     | __main__:train:111 - Train Epoch: 143 Avg Loss: 4.0347 
2023-11-10 15:30:29.773 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:31:20.058 | INFO     | __main__:train:119 - Train Accuracies: All 0.7687 | Old 0.8110 | New 0.7478
2023-11-10 15:31:30.298 | INFO     | __main__:train:108 - Epoch: [144][0/63]	 loss 4.06624	 cls_loss: 0.2150 cluster_loss: 1.2218 sup_con_loss: 0.6462 contrastive_loss: 4.5703 
2023-11-10 15:31:49.444 | INFO     | __main__:train:108 - Epoch: [144][10/63]	 loss 3.99641	 cls_loss: 0.2174 cluster_loss: 1.1597 sup_con_loss: 0.5683 contrastive_loss: 4.5655 
2023-11-10 15:32:08.280 | INFO     | __main__:train:108 - Epoch: [144][20/63]	 loss 3.98559	 cls_loss: 0.2163 cluster_loss: 1.1219 sup_con_loss: 0.6114 contrastive_loss: 4.5641 
2023-11-10 15:32:27.163 | INFO     | __main__:train:108 - Epoch: [144][30/63]	 loss 4.08773	 cls_loss: 0.2176 cluster_loss: 1.2340 sup_con_loss: 0.6837 contrastive_loss: 4.5695 
2023-11-10 15:32:46.079 | INFO     | __main__:train:108 - Epoch: [144][40/63]	 loss 3.89348	 cls_loss: 0.2111 cluster_loss: 1.0888 sup_con_loss: 0.4113 contrastive_loss: 4.5660 
2023-11-10 15:33:04.881 | INFO     | __main__:train:108 - Epoch: [144][50/63]	 loss 4.00580	 cls_loss: 0.2038 cluster_loss: 1.1462 sup_con_loss: 0.6378 contrastive_loss: 4.5634 
2023-11-10 15:33:23.665 | INFO     | __main__:train:108 - Epoch: [144][60/63]	 loss 4.03868	 cls_loss: 0.2191 cluster_loss: 1.1753 sup_con_loss: 0.6593 contrastive_loss: 4.5651 
2023-11-10 15:33:27.465 | INFO     | __main__:train:111 - Train Epoch: 144 Avg Loss: 4.0331 
2023-11-10 15:33:27.466 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:34:17.572 | INFO     | __main__:train:119 - Train Accuracies: All 0.7699 | Old 0.8095 | New 0.7502
2023-11-10 15:34:27.059 | INFO     | __main__:train:108 - Epoch: [145][0/63]	 loss 4.05641	 cls_loss: 0.2071 cluster_loss: 1.1942 sup_con_loss: 0.6800 contrastive_loss: 4.5687 
2023-11-10 15:34:46.118 | INFO     | __main__:train:108 - Epoch: [145][10/63]	 loss 4.00239	 cls_loss: 0.2156 cluster_loss: 1.1578 sup_con_loss: 0.5928 contrastive_loss: 4.5644 
2023-11-10 15:35:04.991 | INFO     | __main__:train:108 - Epoch: [145][20/63]	 loss 4.11685	 cls_loss: 0.2058 cluster_loss: 1.2223 sup_con_loss: 0.7969 contrastive_loss: 4.5714 
2023-11-10 15:35:23.843 | INFO     | __main__:train:108 - Epoch: [145][30/63]	 loss 4.13249	 cls_loss: 0.2084 cluster_loss: 1.2822 sup_con_loss: 0.7290 contrastive_loss: 4.5708 
2023-11-10 15:35:42.726 | INFO     | __main__:train:108 - Epoch: [145][40/63]	 loss 4.17171	 cls_loss: 0.2092 cluster_loss: 1.2644 sup_con_loss: 0.8741 contrastive_loss: 4.5703 
2023-11-10 15:36:01.615 | INFO     | __main__:train:108 - Epoch: [145][50/63]	 loss 4.02369	 cls_loss: 0.2075 cluster_loss: 1.1619 sup_con_loss: 0.6489 contrastive_loss: 4.5673 
2023-11-10 15:36:20.350 | INFO     | __main__:train:108 - Epoch: [145][60/63]	 loss 3.93795	 cls_loss: 0.2008 cluster_loss: 1.1322 sup_con_loss: 0.4636 contrastive_loss: 4.5684 
2023-11-10 15:36:24.111 | INFO     | __main__:train:111 - Train Epoch: 145 Avg Loss: 4.0339 
2023-11-10 15:36:24.112 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:37:13.795 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8144 | New 0.7498
2023-11-10 15:37:23.082 | INFO     | __main__:train:108 - Epoch: [146][0/63]	 loss 4.05677	 cls_loss: 0.2081 cluster_loss: 1.1899 sup_con_loss: 0.6767 contrastive_loss: 4.5749 
2023-11-10 15:37:42.209 | INFO     | __main__:train:108 - Epoch: [146][10/63]	 loss 4.09970	 cls_loss: 0.2165 cluster_loss: 1.2345 sup_con_loss: 0.7082 contrastive_loss: 4.5748 
2023-11-10 15:38:01.041 | INFO     | __main__:train:108 - Epoch: [146][20/63]	 loss 3.98777	 cls_loss: 0.1977 cluster_loss: 1.1409 sup_con_loss: 0.5948 contrastive_loss: 4.5674 
2023-11-10 15:38:19.857 | INFO     | __main__:train:108 - Epoch: [146][30/63]	 loss 4.11630	 cls_loss: 0.2129 cluster_loss: 1.2177 sup_con_loss: 0.7972 contrastive_loss: 4.5712 
2023-11-10 15:38:38.702 | INFO     | __main__:train:108 - Epoch: [146][40/63]	 loss 4.01354	 cls_loss: 0.2170 cluster_loss: 1.1560 sup_con_loss: 0.6136 contrastive_loss: 4.5715 
2023-11-10 15:38:57.544 | INFO     | __main__:train:108 - Epoch: [146][50/63]	 loss 4.15489	 cls_loss: 0.2096 cluster_loss: 1.2603 sup_con_loss: 0.8388 contrastive_loss: 4.5673 
2023-11-10 15:39:16.202 | INFO     | __main__:train:108 - Epoch: [146][60/63]	 loss 4.06725	 cls_loss: 0.2196 cluster_loss: 1.1948 sup_con_loss: 0.6982 contrastive_loss: 4.5683 
2023-11-10 15:39:19.992 | INFO     | __main__:train:111 - Train Epoch: 146 Avg Loss: 4.0203 
2023-11-10 15:39:19.993 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:40:10.134 | INFO     | __main__:train:119 - Train Accuracies: All 0.7705 | Old 0.8110 | New 0.7505
2023-11-10 15:40:19.657 | INFO     | __main__:train:108 - Epoch: [147][0/63]	 loss 4.05574	 cls_loss: 0.2349 cluster_loss: 1.2132 sup_con_loss: 0.6101 contrastive_loss: 4.5714 
2023-11-10 15:40:38.676 | INFO     | __main__:train:108 - Epoch: [147][10/63]	 loss 4.05509	 cls_loss: 0.1969 cluster_loss: 1.2346 sup_con_loss: 0.6105 contrastive_loss: 4.5693 
2023-11-10 15:40:57.493 | INFO     | __main__:train:108 - Epoch: [147][20/63]	 loss 3.91300	 cls_loss: 0.2104 cluster_loss: 1.1313 sup_con_loss: 0.3818 contrastive_loss: 4.5698 
2023-11-10 15:41:16.346 | INFO     | __main__:train:108 - Epoch: [147][30/63]	 loss 4.06283	 cls_loss: 0.2054 cluster_loss: 1.1864 sup_con_loss: 0.7216 contrastive_loss: 4.5650 
2023-11-10 15:41:35.223 | INFO     | __main__:train:108 - Epoch: [147][40/63]	 loss 3.94177	 cls_loss: 0.2014 cluster_loss: 1.0895 sup_con_loss: 0.5644 contrastive_loss: 4.5624 
2023-11-10 15:41:54.057 | INFO     | __main__:train:108 - Epoch: [147][50/63]	 loss 3.96938	 cls_loss: 0.2081 cluster_loss: 1.1014 sup_con_loss: 0.6126 contrastive_loss: 4.5634 
2023-11-10 15:42:12.792 | INFO     | __main__:train:108 - Epoch: [147][60/63]	 loss 3.95740	 cls_loss: 0.1943 cluster_loss: 1.1255 sup_con_loss: 0.5375 contrastive_loss: 4.5687 
2023-11-10 15:42:16.594 | INFO     | __main__:train:111 - Train Epoch: 147 Avg Loss: 4.0150 
2023-11-10 15:42:16.594 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:43:06.170 | INFO     | __main__:train:119 - Train Accuracies: All 0.7723 | Old 0.8208 | New 0.7483
2023-11-10 15:43:15.248 | INFO     | __main__:train:108 - Epoch: [148][0/63]	 loss 4.07196	 cls_loss: 0.1987 cluster_loss: 1.2192 sup_con_loss: 0.6901 contrastive_loss: 4.5668 
2023-11-10 15:43:34.351 | INFO     | __main__:train:108 - Epoch: [148][10/63]	 loss 3.94845	 cls_loss: 0.1983 cluster_loss: 1.1486 sup_con_loss: 0.4738 contrastive_loss: 4.5641 
2023-11-10 15:43:53.175 | INFO     | __main__:train:108 - Epoch: [148][20/63]	 loss 3.92295	 cls_loss: 0.2011 cluster_loss: 1.1285 sup_con_loss: 0.4329 contrastive_loss: 4.5655 
2023-11-10 15:44:12.030 | INFO     | __main__:train:108 - Epoch: [148][30/63]	 loss 4.03794	 cls_loss: 0.2035 cluster_loss: 1.1988 sup_con_loss: 0.6240 contrastive_loss: 4.5679 
2023-11-10 15:44:30.979 | INFO     | __main__:train:108 - Epoch: [148][40/63]	 loss 3.96957	 cls_loss: 0.1956 cluster_loss: 1.1158 sup_con_loss: 0.5935 contrastive_loss: 4.5663 
2023-11-10 15:44:49.786 | INFO     | __main__:train:108 - Epoch: [148][50/63]	 loss 4.12698	 cls_loss: 0.2079 cluster_loss: 1.3014 sup_con_loss: 0.6774 contrastive_loss: 4.5711 
2023-11-10 15:45:08.444 | INFO     | __main__:train:108 - Epoch: [148][60/63]	 loss 4.03546	 cls_loss: 0.2042 cluster_loss: 1.1754 sup_con_loss: 0.6664 contrastive_loss: 4.5642 
2023-11-10 15:45:12.187 | INFO     | __main__:train:111 - Train Epoch: 148 Avg Loss: 4.0161 
2023-11-10 15:45:12.187 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:46:01.667 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8124 | New 0.7507
2023-11-10 15:46:10.097 | INFO     | __main__:train:108 - Epoch: [149][0/63]	 loss 4.07076	 cls_loss: 0.2382 cluster_loss: 1.1678 sup_con_loss: 0.7399 contrastive_loss: 4.5682 
2023-11-10 15:46:29.311 | INFO     | __main__:train:108 - Epoch: [149][10/63]	 loss 4.06745	 cls_loss: 0.2109 cluster_loss: 1.2291 sup_con_loss: 0.6430 contrastive_loss: 4.5687 
2023-11-10 15:46:48.153 | INFO     | __main__:train:108 - Epoch: [149][20/63]	 loss 4.01404	 cls_loss: 0.1959 cluster_loss: 1.1743 sup_con_loss: 0.6155 contrastive_loss: 4.5642 
2023-11-10 15:47:07.052 | INFO     | __main__:train:108 - Epoch: [149][30/63]	 loss 3.99892	 cls_loss: 0.2087 cluster_loss: 1.1928 sup_con_loss: 0.5140 contrastive_loss: 4.5703 
2023-11-10 15:47:25.923 | INFO     | __main__:train:108 - Epoch: [149][40/63]	 loss 4.10739	 cls_loss: 0.1967 cluster_loss: 1.2272 sup_con_loss: 0.7795 contrastive_loss: 4.5662 
2023-11-10 15:47:44.760 | INFO     | __main__:train:108 - Epoch: [149][50/63]	 loss 3.98267	 cls_loss: 0.2006 cluster_loss: 1.1748 sup_con_loss: 0.5096 contrastive_loss: 4.5700 
2023-11-10 15:48:03.508 | INFO     | __main__:train:108 - Epoch: [149][60/63]	 loss 4.09550	 cls_loss: 0.2067 cluster_loss: 1.2471 sup_con_loss: 0.6875 contrastive_loss: 4.5722 
2023-11-10 15:48:07.296 | INFO     | __main__:train:111 - Train Epoch: 149 Avg Loss: 4.0289 
2023-11-10 15:48:07.296 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:48:57.026 | INFO     | __main__:train:119 - Train Accuracies: All 0.7710 | Old 0.8139 | New 0.7498
2023-11-10 15:49:08.129 | INFO     | __main__:train:108 - Epoch: [150][0/63]	 loss 4.11385	 cls_loss: 0.1977 cluster_loss: 1.2205 sup_con_loss: 0.8077 contrastive_loss: 4.5672 
2023-11-10 15:49:27.025 | INFO     | __main__:train:108 - Epoch: [150][10/63]	 loss 3.97483	 cls_loss: 0.2182 cluster_loss: 1.1407 sup_con_loss: 0.5377 contrastive_loss: 4.5674 
2023-11-10 15:49:46.071 | INFO     | __main__:train:108 - Epoch: [150][20/63]	 loss 4.02593	 cls_loss: 0.2034 cluster_loss: 1.1761 sup_con_loss: 0.6382 contrastive_loss: 4.5645 
2023-11-10 15:50:05.081 | INFO     | __main__:train:108 - Epoch: [150][30/63]	 loss 3.99506	 cls_loss: 0.1994 cluster_loss: 1.1655 sup_con_loss: 0.5728 contrastive_loss: 4.5650 
2023-11-10 15:50:24.028 | INFO     | __main__:train:108 - Epoch: [150][40/63]	 loss 3.99350	 cls_loss: 0.1985 cluster_loss: 1.1986 sup_con_loss: 0.5000 contrastive_loss: 4.5692 
2023-11-10 15:50:43.024 | INFO     | __main__:train:108 - Epoch: [150][50/63]	 loss 4.05463	 cls_loss: 0.2167 cluster_loss: 1.1819 sup_con_loss: 0.6888 contrastive_loss: 4.5685 
2023-11-10 15:51:01.783 | INFO     | __main__:train:108 - Epoch: [150][60/63]	 loss 4.12212	 cls_loss: 0.2100 cluster_loss: 1.2777 sup_con_loss: 0.6996 contrastive_loss: 4.5743 
2023-11-10 15:51:05.570 | INFO     | __main__:train:111 - Train Epoch: 150 Avg Loss: 4.0249 
2023-11-10 15:51:05.571 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:51:55.816 | INFO     | __main__:train:119 - Train Accuracies: All 0.7708 | Old 0.8124 | New 0.7502
2023-11-10 15:52:05.614 | INFO     | __main__:train:108 - Epoch: [151][0/63]	 loss 4.18966	 cls_loss: 0.2398 cluster_loss: 1.2679 sup_con_loss: 0.8879 contrastive_loss: 4.5705 
2023-11-10 15:52:24.603 | INFO     | __main__:train:108 - Epoch: [151][10/63]	 loss 3.90713	 cls_loss: 0.2052 cluster_loss: 1.1154 sup_con_loss: 0.4111 contrastive_loss: 4.5637 
2023-11-10 15:52:43.477 | INFO     | __main__:train:108 - Epoch: [151][20/63]	 loss 4.01558	 cls_loss: 0.2047 cluster_loss: 1.1208 sup_con_loss: 0.7113 contrastive_loss: 4.5638 
2023-11-10 15:53:02.413 | INFO     | __main__:train:108 - Epoch: [151][30/63]	 loss 4.03078	 cls_loss: 0.2016 cluster_loss: 1.2148 sup_con_loss: 0.5686 contrastive_loss: 4.5717 
2023-11-10 15:53:21.377 | INFO     | __main__:train:108 - Epoch: [151][40/63]	 loss 4.05134	 cls_loss: 0.1983 cluster_loss: 1.2177 sup_con_loss: 0.6341 contrastive_loss: 4.5669 
2023-11-10 15:53:40.259 | INFO     | __main__:train:108 - Epoch: [151][50/63]	 loss 3.97547	 cls_loss: 0.2083 cluster_loss: 1.1318 sup_con_loss: 0.5613 contrastive_loss: 4.5700 
2023-11-10 15:53:59.000 | INFO     | __main__:train:108 - Epoch: [151][60/63]	 loss 4.08156	 cls_loss: 0.2089 cluster_loss: 1.1887 sup_con_loss: 0.7702 contrastive_loss: 4.5634 
2023-11-10 15:54:02.773 | INFO     | __main__:train:111 - Train Epoch: 151 Avg Loss: 4.0122 
2023-11-10 15:54:02.774 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:54:52.382 | INFO     | __main__:train:119 - Train Accuracies: All 0.7713 | Old 0.8174 | New 0.7485
2023-11-10 15:55:02.016 | INFO     | __main__:train:108 - Epoch: [152][0/63]	 loss 4.05681	 cls_loss: 0.2078 cluster_loss: 1.2026 sup_con_loss: 0.6698 contrastive_loss: 4.5660 
2023-11-10 15:55:21.107 | INFO     | __main__:train:108 - Epoch: [152][10/63]	 loss 4.08063	 cls_loss: 0.2047 cluster_loss: 1.2183 sup_con_loss: 0.7098 contrastive_loss: 4.5672 
2023-11-10 15:55:39.987 | INFO     | __main__:train:108 - Epoch: [152][20/63]	 loss 4.14760	 cls_loss: 0.2072 cluster_loss: 1.2537 sup_con_loss: 0.8313 contrastive_loss: 4.5680 
2023-11-10 15:55:58.860 | INFO     | __main__:train:108 - Epoch: [152][30/63]	 loss 4.05812	 cls_loss: 0.2283 cluster_loss: 1.1990 sup_con_loss: 0.6528 contrastive_loss: 4.5699 
2023-11-10 15:56:17.797 | INFO     | __main__:train:108 - Epoch: [152][40/63]	 loss 4.07565	 cls_loss: 0.2188 cluster_loss: 1.2338 sup_con_loss: 0.6464 contrastive_loss: 4.5705 
2023-11-10 15:56:36.613 | INFO     | __main__:train:108 - Epoch: [152][50/63]	 loss 3.98738	 cls_loss: 0.2141 cluster_loss: 1.1173 sup_con_loss: 0.6226 contrastive_loss: 4.5666 
2023-11-10 15:56:55.306 | INFO     | __main__:train:108 - Epoch: [152][60/63]	 loss 3.97312	 cls_loss: 0.2186 cluster_loss: 1.1613 sup_con_loss: 0.4960 contrastive_loss: 4.5664 
2023-11-10 15:56:59.094 | INFO     | __main__:train:111 - Train Epoch: 152 Avg Loss: 4.0334 
2023-11-10 15:56:59.095 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 15:57:49.079 | INFO     | __main__:train:119 - Train Accuracies: All 0.7715 | Old 0.8149 | New 0.7500
2023-11-10 15:57:58.311 | INFO     | __main__:train:108 - Epoch: [153][0/63]	 loss 3.97249	 cls_loss: 0.2091 cluster_loss: 1.1544 sup_con_loss: 0.5182 contrastive_loss: 4.5655 
2023-11-10 15:58:17.523 | INFO     | __main__:train:108 - Epoch: [153][10/63]	 loss 3.92082	 cls_loss: 0.1901 cluster_loss: 1.1348 sup_con_loss: 0.4174 contrastive_loss: 4.5701 
2023-11-10 15:58:36.459 | INFO     | __main__:train:108 - Epoch: [153][20/63]	 loss 4.11188	 cls_loss: 0.2032 cluster_loss: 1.2598 sup_con_loss: 0.7098 contrastive_loss: 4.5746 
2023-11-10 15:58:55.376 | INFO     | __main__:train:108 - Epoch: [153][30/63]	 loss 4.06691	 cls_loss: 0.2052 cluster_loss: 1.1915 sup_con_loss: 0.7219 contrastive_loss: 4.5660 
2023-11-10 15:59:14.306 | INFO     | __main__:train:108 - Epoch: [153][40/63]	 loss 4.06683	 cls_loss: 0.2056 cluster_loss: 1.2146 sup_con_loss: 0.6807 contrastive_loss: 4.5648 
2023-11-10 15:59:33.169 | INFO     | __main__:train:108 - Epoch: [153][50/63]	 loss 4.07827	 cls_loss: 0.2087 cluster_loss: 1.1774 sup_con_loss: 0.7744 contrastive_loss: 4.5675 
2023-11-10 15:59:51.877 | INFO     | __main__:train:108 - Epoch: [153][60/63]	 loss 4.07518	 cls_loss: 0.2019 cluster_loss: 1.2170 sup_con_loss: 0.6860 contrastive_loss: 4.5744 
2023-11-10 15:59:55.674 | INFO     | __main__:train:111 - Train Epoch: 153 Avg Loss: 4.0195 
2023-11-10 15:59:55.675 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:00:44.947 | INFO     | __main__:train:119 - Train Accuracies: All 0.7708 | Old 0.8139 | New 0.7495
2023-11-10 16:00:54.212 | INFO     | __main__:train:108 - Epoch: [154][0/63]	 loss 4.13972	 cls_loss: 0.2052 cluster_loss: 1.2226 sup_con_loss: 0.8742 contrastive_loss: 4.5650 
2023-11-10 16:01:13.241 | INFO     | __main__:train:108 - Epoch: [154][10/63]	 loss 4.06678	 cls_loss: 0.2046 cluster_loss: 1.2343 sup_con_loss: 0.6309 contrastive_loss: 4.5724 
2023-11-10 16:01:32.115 | INFO     | __main__:train:108 - Epoch: [154][20/63]	 loss 4.00017	 cls_loss: 0.2074 cluster_loss: 1.1293 sup_con_loss: 0.6478 contrastive_loss: 4.5643 
2023-11-10 16:01:51.005 | INFO     | __main__:train:108 - Epoch: [154][30/63]	 loss 3.98566	 cls_loss: 0.2375 cluster_loss: 1.1226 sup_con_loss: 0.5861 contrastive_loss: 4.5657 
2023-11-10 16:02:10.008 | INFO     | __main__:train:108 - Epoch: [154][40/63]	 loss 3.96746	 cls_loss: 0.2019 cluster_loss: 1.1719 sup_con_loss: 0.4753 contrastive_loss: 4.5672 
2023-11-10 16:02:28.865 | INFO     | __main__:train:108 - Epoch: [154][50/63]	 loss 4.01292	 cls_loss: 0.2097 cluster_loss: 1.1726 sup_con_loss: 0.6032 contrastive_loss: 4.5635 
2023-11-10 16:02:47.639 | INFO     | __main__:train:108 - Epoch: [154][60/63]	 loss 3.99324	 cls_loss: 0.2132 cluster_loss: 1.1971 sup_con_loss: 0.4847 contrastive_loss: 4.5706 
2023-11-10 16:02:51.422 | INFO     | __main__:train:111 - Train Epoch: 154 Avg Loss: 4.0220 
2023-11-10 16:02:51.423 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:03:40.995 | INFO     | __main__:train:119 - Train Accuracies: All 0.7707 | Old 0.8144 | New 0.7490
2023-11-10 16:03:50.822 | INFO     | __main__:train:108 - Epoch: [155][0/63]	 loss 4.01494	 cls_loss: 0.2075 cluster_loss: 1.1779 sup_con_loss: 0.5937 contrastive_loss: 4.5675 
2023-11-10 16:04:09.888 | INFO     | __main__:train:108 - Epoch: [155][10/63]	 loss 4.04410	 cls_loss: 0.2170 cluster_loss: 1.1704 sup_con_loss: 0.6892 contrastive_loss: 4.5634 
2023-11-10 16:04:28.707 | INFO     | __main__:train:108 - Epoch: [155][20/63]	 loss 4.01193	 cls_loss: 0.2275 cluster_loss: 1.1476 sup_con_loss: 0.6169 contrastive_loss: 4.5700 
2023-11-10 16:04:47.592 | INFO     | __main__:train:108 - Epoch: [155][30/63]	 loss 3.97548	 cls_loss: 0.2079 cluster_loss: 1.1287 sup_con_loss: 0.5760 contrastive_loss: 4.5653 
2023-11-10 16:05:06.517 | INFO     | __main__:train:108 - Epoch: [155][40/63]	 loss 3.97680	 cls_loss: 0.2052 cluster_loss: 1.1291 sup_con_loss: 0.5770 contrastive_loss: 4.5678 
2023-11-10 16:05:25.404 | INFO     | __main__:train:108 - Epoch: [155][50/63]	 loss 4.05850	 cls_loss: 0.2116 cluster_loss: 1.1602 sup_con_loss: 0.7529 contrastive_loss: 4.5643 
2023-11-10 16:05:44.164 | INFO     | __main__:train:108 - Epoch: [155][60/63]	 loss 3.94814	 cls_loss: 0.2103 cluster_loss: 1.1253 sup_con_loss: 0.5025 contrastive_loss: 4.5649 
2023-11-10 16:05:47.938 | INFO     | __main__:train:111 - Train Epoch: 155 Avg Loss: 4.0303 
2023-11-10 16:05:47.939 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:06:37.789 | INFO     | __main__:train:119 - Train Accuracies: All 0.7700 | Old 0.8110 | New 0.7498
2023-11-10 16:06:46.548 | INFO     | __main__:train:108 - Epoch: [156][0/63]	 loss 4.04913	 cls_loss: 0.2285 cluster_loss: 1.1638 sup_con_loss: 0.6962 contrastive_loss: 4.5678 
2023-11-10 16:07:05.776 | INFO     | __main__:train:108 - Epoch: [156][10/63]	 loss 3.85216	 cls_loss: 0.2088 cluster_loss: 1.0696 sup_con_loss: 0.3301 contrastive_loss: 4.5666 
2023-11-10 16:07:24.650 | INFO     | __main__:train:108 - Epoch: [156][20/63]	 loss 3.87289	 cls_loss: 0.2005 cluster_loss: 1.0978 sup_con_loss: 0.3445 contrastive_loss: 4.5670 
2023-11-10 16:07:43.547 | INFO     | __main__:train:108 - Epoch: [156][30/63]	 loss 3.97297	 cls_loss: 0.1914 cluster_loss: 1.1356 sup_con_loss: 0.5739 contrastive_loss: 4.5645 
2023-11-10 16:08:02.458 | INFO     | __main__:train:108 - Epoch: [156][40/63]	 loss 4.04797	 cls_loss: 0.2114 cluster_loss: 1.2493 sup_con_loss: 0.5423 contrastive_loss: 4.5725 
2023-11-10 16:08:21.312 | INFO     | __main__:train:108 - Epoch: [156][50/63]	 loss 3.91215	 cls_loss: 0.2023 cluster_loss: 1.0890 sup_con_loss: 0.4751 contrastive_loss: 4.5649 
2023-11-10 16:08:40.018 | INFO     | __main__:train:108 - Epoch: [156][60/63]	 loss 4.04364	 cls_loss: 0.1974 cluster_loss: 1.1853 sup_con_loss: 0.6771 contrastive_loss: 4.5648 
2023-11-10 16:08:43.781 | INFO     | __main__:train:111 - Train Epoch: 156 Avg Loss: 4.0078 
2023-11-10 16:08:43.781 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:09:32.940 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8154 | New 0.7493
2023-11-10 16:09:42.670 | INFO     | __main__:train:108 - Epoch: [157][0/63]	 loss 4.05438	 cls_loss: 0.2113 cluster_loss: 1.2194 sup_con_loss: 0.6210 contrastive_loss: 4.5699 
2023-11-10 16:10:01.688 | INFO     | __main__:train:108 - Epoch: [157][10/63]	 loss 4.11981	 cls_loss: 0.1954 cluster_loss: 1.2647 sup_con_loss: 0.7406 contrastive_loss: 4.5695 
2023-11-10 16:10:20.548 | INFO     | __main__:train:108 - Epoch: [157][20/63]	 loss 4.08849	 cls_loss: 0.2101 cluster_loss: 1.2919 sup_con_loss: 0.5799 contrastive_loss: 4.5727 
2023-11-10 16:10:39.404 | INFO     | __main__:train:108 - Epoch: [157][30/63]	 loss 4.09791	 cls_loss: 0.2276 cluster_loss: 1.1876 sup_con_loss: 0.7960 contrastive_loss: 4.5657 
2023-11-10 16:10:58.291 | INFO     | __main__:train:108 - Epoch: [157][40/63]	 loss 3.97611	 cls_loss: 0.2092 cluster_loss: 1.1384 sup_con_loss: 0.5569 contrastive_loss: 4.5662 
2023-11-10 16:11:17.162 | INFO     | __main__:train:108 - Epoch: [157][50/63]	 loss 3.95184	 cls_loss: 0.2040 cluster_loss: 1.1025 sup_con_loss: 0.5631 contrastive_loss: 4.5642 
2023-11-10 16:11:35.832 | INFO     | __main__:train:108 - Epoch: [157][60/63]	 loss 4.07254	 cls_loss: 0.2035 cluster_loss: 1.2021 sup_con_loss: 0.7217 contrastive_loss: 4.5652 
2023-11-10 16:11:39.627 | INFO     | __main__:train:111 - Train Epoch: 157 Avg Loss: 4.0345 
2023-11-10 16:11:39.627 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:12:29.450 | INFO     | __main__:train:119 - Train Accuracies: All 0.7718 | Old 0.8154 | New 0.7502
2023-11-10 16:12:38.856 | INFO     | __main__:train:108 - Epoch: [158][0/63]	 loss 3.96535	 cls_loss: 0.2024 cluster_loss: 1.1647 sup_con_loss: 0.4781 contrastive_loss: 4.5694 
2023-11-10 16:12:57.943 | INFO     | __main__:train:108 - Epoch: [158][10/63]	 loss 4.02123	 cls_loss: 0.2022 cluster_loss: 1.1579 sup_con_loss: 0.6594 contrastive_loss: 4.5647 
2023-11-10 16:13:16.812 | INFO     | __main__:train:108 - Epoch: [158][20/63]	 loss 4.09134	 cls_loss: 0.1894 cluster_loss: 1.2158 sup_con_loss: 0.7648 contrastive_loss: 4.5648 
2023-11-10 16:13:35.713 | INFO     | __main__:train:108 - Epoch: [158][30/63]	 loss 4.12566	 cls_loss: 0.2113 cluster_loss: 1.2320 sup_con_loss: 0.8062 contrastive_loss: 4.5672 
2023-11-10 16:13:54.611 | INFO     | __main__:train:108 - Epoch: [158][40/63]	 loss 4.01150	 cls_loss: 0.2140 cluster_loss: 1.1516 sup_con_loss: 0.6291 contrastive_loss: 4.5660 
2023-11-10 16:14:13.422 | INFO     | __main__:train:108 - Epoch: [158][50/63]	 loss 3.89419	 cls_loss: 0.2093 cluster_loss: 1.0713 sup_con_loss: 0.4468 contrastive_loss: 4.5665 
2023-11-10 16:14:32.179 | INFO     | __main__:train:108 - Epoch: [158][60/63]	 loss 3.92722	 cls_loss: 0.2191 cluster_loss: 1.0860 sup_con_loss: 0.5011 contrastive_loss: 4.5681 
2023-11-10 16:14:35.955 | INFO     | __main__:train:111 - Train Epoch: 158 Avg Loss: 4.0099 
2023-11-10 16:14:35.955 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:15:26.253 | INFO     | __main__:train:119 - Train Accuracies: All 0.7697 | Old 0.8095 | New 0.7500
2023-11-10 16:15:35.508 | INFO     | __main__:train:108 - Epoch: [159][0/63]	 loss 3.99325	 cls_loss: 0.2237 cluster_loss: 1.1294 sup_con_loss: 0.6037 contrastive_loss: 4.5685 
2023-11-10 16:15:54.605 | INFO     | __main__:train:108 - Epoch: [159][10/63]	 loss 4.04161	 cls_loss: 0.2071 cluster_loss: 1.1746 sup_con_loss: 0.6815 contrastive_loss: 4.5648 
2023-11-10 16:16:13.502 | INFO     | __main__:train:108 - Epoch: [159][20/63]	 loss 4.00812	 cls_loss: 0.2251 cluster_loss: 1.1684 sup_con_loss: 0.5799 contrastive_loss: 4.5645 
2023-11-10 16:16:32.410 | INFO     | __main__:train:108 - Epoch: [159][30/63]	 loss 4.05238	 cls_loss: 0.1970 cluster_loss: 1.2030 sup_con_loss: 0.6629 contrastive_loss: 4.5684 
2023-11-10 16:16:51.325 | INFO     | __main__:train:108 - Epoch: [159][40/63]	 loss 4.02006	 cls_loss: 0.2021 cluster_loss: 1.1615 sup_con_loss: 0.6528 contrastive_loss: 4.5629 
2023-11-10 16:17:10.200 | INFO     | __main__:train:108 - Epoch: [159][50/63]	 loss 4.09491	 cls_loss: 0.2135 cluster_loss: 1.2147 sup_con_loss: 0.7430 contrastive_loss: 4.5701 
2023-11-10 16:17:28.898 | INFO     | __main__:train:108 - Epoch: [159][60/63]	 loss 4.06664	 cls_loss: 0.2216 cluster_loss: 1.2002 sup_con_loss: 0.6880 contrastive_loss: 4.5664 
2023-11-10 16:17:32.668 | INFO     | __main__:train:111 - Train Epoch: 159 Avg Loss: 4.0167 
2023-11-10 16:17:32.668 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:18:22.767 | INFO     | __main__:train:119 - Train Accuracies: All 0.7713 | Old 0.8124 | New 0.7510
2023-11-10 16:18:32.971 | INFO     | __main__:train:108 - Epoch: [160][0/63]	 loss 3.88251	 cls_loss: 0.2049 cluster_loss: 1.0482 sup_con_loss: 0.4675 contrastive_loss: 4.5628 
2023-11-10 16:18:51.931 | INFO     | __main__:train:108 - Epoch: [160][10/63]	 loss 4.02051	 cls_loss: 0.2036 cluster_loss: 1.1676 sup_con_loss: 0.6333 contrastive_loss: 4.5671 
2023-11-10 16:19:10.795 | INFO     | __main__:train:108 - Epoch: [160][20/63]	 loss 4.03375	 cls_loss: 0.2137 cluster_loss: 1.1894 sup_con_loss: 0.6197 contrastive_loss: 4.5676 
2023-11-10 16:19:29.660 | INFO     | __main__:train:108 - Epoch: [160][30/63]	 loss 4.03683	 cls_loss: 0.2083 cluster_loss: 1.1922 sup_con_loss: 0.6199 contrastive_loss: 4.5723 
2023-11-10 16:19:48.492 | INFO     | __main__:train:108 - Epoch: [160][40/63]	 loss 3.99601	 cls_loss: 0.2092 cluster_loss: 1.1247 sup_con_loss: 0.6368 contrastive_loss: 4.5675 
2023-11-10 16:20:07.367 | INFO     | __main__:train:108 - Epoch: [160][50/63]	 loss 3.92127	 cls_loss: 0.1969 cluster_loss: 1.1096 sup_con_loss: 0.4666 contrastive_loss: 4.5658 
2023-11-10 16:20:26.002 | INFO     | __main__:train:108 - Epoch: [160][60/63]	 loss 4.08845	 cls_loss: 0.2246 cluster_loss: 1.2221 sup_con_loss: 0.6978 contrastive_loss: 4.5711 
2023-11-10 16:20:29.751 | INFO     | __main__:train:111 - Train Epoch: 160 Avg Loss: 3.9953 
2023-11-10 16:20:29.751 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:21:18.676 | INFO     | __main__:train:119 - Train Accuracies: All 0.7731 | Old 0.8179 | New 0.7510
2023-11-10 16:21:27.969 | INFO     | __main__:train:108 - Epoch: [161][0/63]	 loss 4.08217	 cls_loss: 0.2088 cluster_loss: 1.2247 sup_con_loss: 0.6976 contrastive_loss: 4.5675 
2023-11-10 16:21:46.941 | INFO     | __main__:train:108 - Epoch: [161][10/63]	 loss 4.01353	 cls_loss: 0.2040 cluster_loss: 1.1736 sup_con_loss: 0.6007 contrastive_loss: 4.5678 
2023-11-10 16:22:05.796 | INFO     | __main__:train:108 - Epoch: [161][20/63]	 loss 4.02004	 cls_loss: 0.2002 cluster_loss: 1.1694 sup_con_loss: 0.6337 contrastive_loss: 4.5663 
2023-11-10 16:22:24.647 | INFO     | __main__:train:108 - Epoch: [161][30/63]	 loss 4.05901	 cls_loss: 0.2181 cluster_loss: 1.1746 sup_con_loss: 0.7115 contrastive_loss: 4.5695 
2023-11-10 16:22:43.556 | INFO     | __main__:train:108 - Epoch: [161][40/63]	 loss 4.03355	 cls_loss: 0.2090 cluster_loss: 1.1700 sup_con_loss: 0.6594 contrastive_loss: 4.5678 
2023-11-10 16:23:02.418 | INFO     | __main__:train:108 - Epoch: [161][50/63]	 loss 3.94084	 cls_loss: 0.2090 cluster_loss: 1.1315 sup_con_loss: 0.4721 contrastive_loss: 4.5645 
2023-11-10 16:23:21.121 | INFO     | __main__:train:108 - Epoch: [161][60/63]	 loss 4.02744	 cls_loss: 0.2039 cluster_loss: 1.2035 sup_con_loss: 0.5836 contrastive_loss: 4.5685 
2023-11-10 16:23:24.890 | INFO     | __main__:train:111 - Train Epoch: 161 Avg Loss: 4.0242 
2023-11-10 16:23:24.891 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:24:14.042 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8159 | New 0.7490
2023-11-10 16:24:23.186 | INFO     | __main__:train:108 - Epoch: [162][0/63]	 loss 4.06691	 cls_loss: 0.2223 cluster_loss: 1.1668 sup_con_loss: 0.7521 contrastive_loss: 4.5653 
2023-11-10 16:24:42.318 | INFO     | __main__:train:108 - Epoch: [162][10/63]	 loss 3.98251	 cls_loss: 0.2120 cluster_loss: 1.1511 sup_con_loss: 0.5447 contrastive_loss: 4.5684 
2023-11-10 16:25:01.120 | INFO     | __main__:train:108 - Epoch: [162][20/63]	 loss 4.08114	 cls_loss: 0.2097 cluster_loss: 1.2503 sup_con_loss: 0.6386 contrastive_loss: 4.5716 
2023-11-10 16:25:20.019 | INFO     | __main__:train:108 - Epoch: [162][30/63]	 loss 3.92633	 cls_loss: 0.2074 cluster_loss: 1.1140 sup_con_loss: 0.4616 contrastive_loss: 4.5663 
2023-11-10 16:25:38.927 | INFO     | __main__:train:108 - Epoch: [162][40/63]	 loss 4.03158	 cls_loss: 0.2141 cluster_loss: 1.2176 sup_con_loss: 0.5620 contrastive_loss: 4.5669 
2023-11-10 16:25:57.783 | INFO     | __main__:train:108 - Epoch: [162][50/63]	 loss 4.08016	 cls_loss: 0.1949 cluster_loss: 1.2329 sup_con_loss: 0.6951 contrastive_loss: 4.5650 
2023-11-10 16:26:16.535 | INFO     | __main__:train:108 - Epoch: [162][60/63]	 loss 3.97774	 cls_loss: 0.1926 cluster_loss: 1.1609 sup_con_loss: 0.5386 contrastive_loss: 4.5650 
2023-11-10 16:26:20.301 | INFO     | __main__:train:111 - Train Epoch: 162 Avg Loss: 4.0231 
2023-11-10 16:26:20.301 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:27:10.481 | INFO     | __main__:train:119 - Train Accuracies: All 0.7721 | Old 0.8169 | New 0.7500
2023-11-10 16:27:19.724 | INFO     | __main__:train:108 - Epoch: [163][0/63]	 loss 4.02676	 cls_loss: 0.1979 cluster_loss: 1.1386 sup_con_loss: 0.7192 contrastive_loss: 4.5626 
2023-11-10 16:27:38.810 | INFO     | __main__:train:108 - Epoch: [163][10/63]	 loss 4.12181	 cls_loss: 0.2072 cluster_loss: 1.2601 sup_con_loss: 0.7387 contrastive_loss: 4.5717 
2023-11-10 16:27:57.661 | INFO     | __main__:train:108 - Epoch: [163][20/63]	 loss 3.90296	 cls_loss: 0.2235 cluster_loss: 1.0863 sup_con_loss: 0.4383 contrastive_loss: 4.5620 
2023-11-10 16:28:16.574 | INFO     | __main__:train:108 - Epoch: [163][30/63]	 loss 4.02796	 cls_loss: 0.2141 cluster_loss: 1.1773 sup_con_loss: 0.6264 contrastive_loss: 4.5670 
2023-11-10 16:28:35.544 | INFO     | __main__:train:108 - Epoch: [163][40/63]	 loss 4.02112	 cls_loss: 0.2105 cluster_loss: 1.1574 sup_con_loss: 0.6479 contrastive_loss: 4.5667 
2023-11-10 16:28:54.443 | INFO     | __main__:train:108 - Epoch: [163][50/63]	 loss 4.09274	 cls_loss: 0.2071 cluster_loss: 1.2039 sup_con_loss: 0.7721 contrastive_loss: 4.5654 
2023-11-10 16:29:13.194 | INFO     | __main__:train:108 - Epoch: [163][60/63]	 loss 3.99232	 cls_loss: 0.1969 cluster_loss: 1.1643 sup_con_loss: 0.5629 contrastive_loss: 4.5686 
2023-11-10 16:29:17.012 | INFO     | __main__:train:111 - Train Epoch: 163 Avg Loss: 4.0178 
2023-11-10 16:29:17.012 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:30:06.672 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8139 | New 0.7500
2023-11-10 16:30:15.792 | INFO     | __main__:train:108 - Epoch: [164][0/63]	 loss 4.01308	 cls_loss: 0.2096 cluster_loss: 1.1269 sup_con_loss: 0.6900 contrastive_loss: 4.5626 
2023-11-10 16:30:34.949 | INFO     | __main__:train:108 - Epoch: [164][10/63]	 loss 4.15837	 cls_loss: 0.2145 cluster_loss: 1.3008 sup_con_loss: 0.7645 contrastive_loss: 4.5695 
2023-11-10 16:30:53.793 | INFO     | __main__:train:108 - Epoch: [164][20/63]	 loss 4.02101	 cls_loss: 0.2097 cluster_loss: 1.1710 sup_con_loss: 0.6244 contrastive_loss: 4.5661 
2023-11-10 16:31:12.764 | INFO     | __main__:train:108 - Epoch: [164][30/63]	 loss 4.06669	 cls_loss: 0.2037 cluster_loss: 1.2278 sup_con_loss: 0.6498 contrastive_loss: 4.5691 
2023-11-10 16:31:31.662 | INFO     | __main__:train:108 - Epoch: [164][40/63]	 loss 3.98389	 cls_loss: 0.2123 cluster_loss: 1.1438 sup_con_loss: 0.5652 contrastive_loss: 4.5667 
2023-11-10 16:31:50.498 | INFO     | __main__:train:108 - Epoch: [164][50/63]	 loss 4.02990	 cls_loss: 0.2058 cluster_loss: 1.1610 sup_con_loss: 0.6704 contrastive_loss: 4.5670 
2023-11-10 16:32:09.228 | INFO     | __main__:train:108 - Epoch: [164][60/63]	 loss 3.98464	 cls_loss: 0.2022 cluster_loss: 1.1622 sup_con_loss: 0.5376 contrastive_loss: 4.5696 
2023-11-10 16:32:13.018 | INFO     | __main__:train:111 - Train Epoch: 164 Avg Loss: 4.0163 
2023-11-10 16:32:13.019 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:33:02.951 | INFO     | __main__:train:119 - Train Accuracies: All 0.7717 | Old 0.8154 | New 0.7500
2023-11-10 16:33:12.079 | INFO     | __main__:train:108 - Epoch: [165][0/63]	 loss 3.95573	 cls_loss: 0.2060 cluster_loss: 1.0807 sup_con_loss: 0.6099 contrastive_loss: 4.5657 
2023-11-10 16:33:31.129 | INFO     | __main__:train:108 - Epoch: [165][10/63]	 loss 3.99267	 cls_loss: 0.2146 cluster_loss: 1.1571 sup_con_loss: 0.5687 contrastive_loss: 4.5637 
2023-11-10 16:33:49.944 | INFO     | __main__:train:108 - Epoch: [165][20/63]	 loss 3.99485	 cls_loss: 0.1987 cluster_loss: 1.1209 sup_con_loss: 0.6632 contrastive_loss: 4.5610 
2023-11-10 16:34:08.842 | INFO     | __main__:train:108 - Epoch: [165][30/63]	 loss 3.94660	 cls_loss: 0.2116 cluster_loss: 1.1483 sup_con_loss: 0.4470 contrastive_loss: 4.5688 
2023-11-10 16:34:27.755 | INFO     | __main__:train:108 - Epoch: [165][40/63]	 loss 3.96220	 cls_loss: 0.1983 cluster_loss: 1.1054 sup_con_loss: 0.5956 contrastive_loss: 4.5628 
2023-11-10 16:34:46.545 | INFO     | __main__:train:108 - Epoch: [165][50/63]	 loss 4.08740	 cls_loss: 0.2088 cluster_loss: 1.1944 sup_con_loss: 0.7806 contrastive_loss: 4.5611 
2023-11-10 16:35:05.232 | INFO     | __main__:train:108 - Epoch: [165][60/63]	 loss 4.09183	 cls_loss: 0.2016 cluster_loss: 1.2314 sup_con_loss: 0.7242 contrastive_loss: 4.5653 
2023-11-10 16:35:09.010 | INFO     | __main__:train:111 - Train Epoch: 165 Avg Loss: 4.0007 
2023-11-10 16:35:09.011 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:35:58.089 | INFO     | __main__:train:119 - Train Accuracies: All 0.7735 | Old 0.8189 | New 0.7510
2023-11-10 16:36:07.340 | INFO     | __main__:train:108 - Epoch: [166][0/63]	 loss 3.97760	 cls_loss: 0.2029 cluster_loss: 1.1503 sup_con_loss: 0.5419 contrastive_loss: 4.5681 
2023-11-10 16:36:26.399 | INFO     | __main__:train:108 - Epoch: [166][10/63]	 loss 4.08575	 cls_loss: 0.2095 cluster_loss: 1.1708 sup_con_loss: 0.8119 contrastive_loss: 4.5650 
2023-11-10 16:36:45.231 | INFO     | __main__:train:108 - Epoch: [166][20/63]	 loss 3.93443	 cls_loss: 0.2040 cluster_loss: 1.1231 sup_con_loss: 0.4745 contrastive_loss: 4.5646 
2023-11-10 16:37:04.152 | INFO     | __main__:train:108 - Epoch: [166][30/63]	 loss 4.02152	 cls_loss: 0.2143 cluster_loss: 1.1536 sup_con_loss: 0.6478 contrastive_loss: 4.5692 
2023-11-10 16:37:23.033 | INFO     | __main__:train:108 - Epoch: [166][40/63]	 loss 3.89663	 cls_loss: 0.2044 cluster_loss: 1.0834 sup_con_loss: 0.4456 contrastive_loss: 4.5614 
2023-11-10 16:37:41.837 | INFO     | __main__:train:108 - Epoch: [166][50/63]	 loss 3.95626	 cls_loss: 0.2180 cluster_loss: 1.0858 sup_con_loss: 0.5923 contrastive_loss: 4.5644 
2023-11-10 16:38:00.523 | INFO     | __main__:train:108 - Epoch: [166][60/63]	 loss 4.03504	 cls_loss: 0.1958 cluster_loss: 1.1877 sup_con_loss: 0.6530 contrastive_loss: 4.5630 
2023-11-10 16:38:04.313 | INFO     | __main__:train:111 - Train Epoch: 166 Avg Loss: 4.0191 
2023-11-10 16:38:04.314 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:38:53.333 | INFO     | __main__:train:119 - Train Accuracies: All 0.7723 | Old 0.8159 | New 0.7507
2023-11-10 16:39:03.288 | INFO     | __main__:train:108 - Epoch: [167][0/63]	 loss 3.94683	 cls_loss: 0.1941 cluster_loss: 1.1708 sup_con_loss: 0.4237 contrastive_loss: 4.5685 
2023-11-10 16:39:22.204 | INFO     | __main__:train:108 - Epoch: [167][10/63]	 loss 3.93691	 cls_loss: 0.1968 cluster_loss: 1.0988 sup_con_loss: 0.5350 contrastive_loss: 4.5639 
2023-11-10 16:39:41.123 | INFO     | __main__:train:108 - Epoch: [167][20/63]	 loss 3.98457	 cls_loss: 0.2075 cluster_loss: 1.1486 sup_con_loss: 0.5647 contrastive_loss: 4.5657 
2023-11-10 16:39:59.990 | INFO     | __main__:train:108 - Epoch: [167][30/63]	 loss 3.93511	 cls_loss: 0.2241 cluster_loss: 1.0744 sup_con_loss: 0.5502 contrastive_loss: 4.5627 
2023-11-10 16:40:18.893 | INFO     | __main__:train:108 - Epoch: [167][40/63]	 loss 4.06535	 cls_loss: 0.2113 cluster_loss: 1.2074 sup_con_loss: 0.6765 contrastive_loss: 4.5690 
2023-11-10 16:40:37.726 | INFO     | __main__:train:108 - Epoch: [167][50/63]	 loss 3.95453	 cls_loss: 0.2021 cluster_loss: 1.1144 sup_con_loss: 0.5451 contrastive_loss: 4.5671 
2023-11-10 16:40:56.420 | INFO     | __main__:train:108 - Epoch: [167][60/63]	 loss 3.84264	 cls_loss: 0.1975 cluster_loss: 1.0605 sup_con_loss: 0.3317 contrastive_loss: 4.5663 
2023-11-10 16:41:00.227 | INFO     | __main__:train:111 - Train Epoch: 167 Avg Loss: 4.0052 
2023-11-10 16:41:00.228 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:41:49.912 | INFO     | __main__:train:119 - Train Accuracies: All 0.7720 | Old 0.8169 | New 0.7498
2023-11-10 16:41:58.976 | INFO     | __main__:train:108 - Epoch: [168][0/63]	 loss 4.05829	 cls_loss: 0.2046 cluster_loss: 1.1615 sup_con_loss: 0.7587 contrastive_loss: 4.5633 
2023-11-10 16:42:17.926 | INFO     | __main__:train:108 - Epoch: [168][10/63]	 loss 3.97186	 cls_loss: 0.2023 cluster_loss: 1.1668 sup_con_loss: 0.4970 contrastive_loss: 4.5672 
2023-11-10 16:42:36.709 | INFO     | __main__:train:108 - Epoch: [168][20/63]	 loss 4.02800	 cls_loss: 0.2035 cluster_loss: 1.1883 sup_con_loss: 0.6209 contrastive_loss: 4.5647 
2023-11-10 16:42:55.560 | INFO     | __main__:train:108 - Epoch: [168][30/63]	 loss 4.01293	 cls_loss: 0.2094 cluster_loss: 1.1592 sup_con_loss: 0.6308 contrastive_loss: 4.5622 
2023-11-10 16:43:14.451 | INFO     | __main__:train:108 - Epoch: [168][40/63]	 loss 3.96581	 cls_loss: 0.2196 cluster_loss: 1.1181 sup_con_loss: 0.5406 contrastive_loss: 4.5738 
2023-11-10 16:43:33.319 | INFO     | __main__:train:108 - Epoch: [168][50/63]	 loss 3.88479	 cls_loss: 0.2040 cluster_loss: 1.0627 sup_con_loss: 0.4464 contrastive_loss: 4.5637 
2023-11-10 16:43:52.069 | INFO     | __main__:train:108 - Epoch: [168][60/63]	 loss 3.95522	 cls_loss: 0.2075 cluster_loss: 1.0926 sup_con_loss: 0.5953 contrastive_loss: 4.5601 
2023-11-10 16:43:55.852 | INFO     | __main__:train:111 - Train Epoch: 168 Avg Loss: 4.0160 
2023-11-10 16:43:55.853 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:44:45.344 | INFO     | __main__:train:119 - Train Accuracies: All 0.7710 | Old 0.8129 | New 0.7502
2023-11-10 16:44:55.720 | INFO     | __main__:train:108 - Epoch: [169][0/63]	 loss 4.09612	 cls_loss: 0.2199 cluster_loss: 1.2103 sup_con_loss: 0.7568 contrastive_loss: 4.5655 
2023-11-10 16:45:14.728 | INFO     | __main__:train:108 - Epoch: [169][10/63]	 loss 3.88593	 cls_loss: 0.2206 cluster_loss: 1.0516 sup_con_loss: 0.4543 contrastive_loss: 4.5634 
2023-11-10 16:45:33.606 | INFO     | __main__:train:108 - Epoch: [169][20/63]	 loss 3.92380	 cls_loss: 0.2093 cluster_loss: 1.0942 sup_con_loss: 0.4992 contrastive_loss: 4.5609 
2023-11-10 16:45:52.456 | INFO     | __main__:train:108 - Epoch: [169][30/63]	 loss 3.95121	 cls_loss: 0.2067 cluster_loss: 1.1024 sup_con_loss: 0.5590 contrastive_loss: 4.5641 
2023-11-10 16:46:11.340 | INFO     | __main__:train:108 - Epoch: [169][40/63]	 loss 4.05225	 cls_loss: 0.1972 cluster_loss: 1.2308 sup_con_loss: 0.6080 contrastive_loss: 4.5698 
2023-11-10 16:46:30.238 | INFO     | __main__:train:108 - Epoch: [169][50/63]	 loss 3.94134	 cls_loss: 0.2060 cluster_loss: 1.1270 sup_con_loss: 0.4799 contrastive_loss: 4.5672 
2023-11-10 16:46:49.001 | INFO     | __main__:train:108 - Epoch: [169][60/63]	 loss 3.92474	 cls_loss: 0.2041 cluster_loss: 1.0861 sup_con_loss: 0.5109 contrastive_loss: 4.5670 
2023-11-10 16:46:52.829 | INFO     | __main__:train:111 - Train Epoch: 169 Avg Loss: 4.0100 
2023-11-10 16:46:52.830 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:47:42.670 | INFO     | __main__:train:119 - Train Accuracies: All 0.7712 | Old 0.8159 | New 0.7490
2023-11-10 16:47:50.826 | INFO     | __main__:train:108 - Epoch: [170][0/63]	 loss 4.00831	 cls_loss: 0.2184 cluster_loss: 1.1280 sup_con_loss: 0.6666 contrastive_loss: 4.5622 
2023-11-10 16:48:10.001 | INFO     | __main__:train:108 - Epoch: [170][10/63]	 loss 4.01894	 cls_loss: 0.2103 cluster_loss: 1.1702 sup_con_loss: 0.6232 contrastive_loss: 4.5640 
2023-11-10 16:48:28.868 | INFO     | __main__:train:108 - Epoch: [170][20/63]	 loss 4.01452	 cls_loss: 0.2102 cluster_loss: 1.1393 sup_con_loss: 0.6679 contrastive_loss: 4.5641 
2023-11-10 16:48:47.750 | INFO     | __main__:train:108 - Epoch: [170][30/63]	 loss 3.97302	 cls_loss: 0.2025 cluster_loss: 1.1347 sup_con_loss: 0.5629 contrastive_loss: 4.5655 
2023-11-10 16:49:06.683 | INFO     | __main__:train:108 - Epoch: [170][40/63]	 loss 3.93075	 cls_loss: 0.2047 cluster_loss: 1.1022 sup_con_loss: 0.5005 contrastive_loss: 4.5653 
2023-11-10 16:49:25.604 | INFO     | __main__:train:108 - Epoch: [170][50/63]	 loss 4.03520	 cls_loss: 0.2042 cluster_loss: 1.1817 sup_con_loss: 0.6542 contrastive_loss: 4.5641 
2023-11-10 16:49:44.394 | INFO     | __main__:train:108 - Epoch: [170][60/63]	 loss 4.03110	 cls_loss: 0.2000 cluster_loss: 1.2088 sup_con_loss: 0.5885 contrastive_loss: 4.5683 
2023-11-10 16:49:48.179 | INFO     | __main__:train:111 - Train Epoch: 170 Avg Loss: 4.0041 
2023-11-10 16:49:48.180 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:50:37.962 | INFO     | __main__:train:119 - Train Accuracies: All 0.7718 | Old 0.8164 | New 0.7498
2023-11-10 16:50:47.078 | INFO     | __main__:train:108 - Epoch: [171][0/63]	 loss 3.93732	 cls_loss: 0.2135 cluster_loss: 1.1262 sup_con_loss: 0.4642 contrastive_loss: 4.5663 
2023-11-10 16:51:06.180 | INFO     | __main__:train:108 - Epoch: [171][10/63]	 loss 3.88669	 cls_loss: 0.2095 cluster_loss: 1.0434 sup_con_loss: 0.4860 contrastive_loss: 4.5616 
2023-11-10 16:51:25.032 | INFO     | __main__:train:108 - Epoch: [171][20/63]	 loss 4.05067	 cls_loss: 0.2061 cluster_loss: 1.2068 sup_con_loss: 0.6422 contrastive_loss: 4.5681 
2023-11-10 16:51:43.933 | INFO     | __main__:train:108 - Epoch: [171][30/63]	 loss 3.88100	 cls_loss: 0.2034 cluster_loss: 1.0821 sup_con_loss: 0.4013 contrastive_loss: 4.5631 
2023-11-10 16:52:02.868 | INFO     | __main__:train:108 - Epoch: [171][40/63]	 loss 3.98440	 cls_loss: 0.2088 cluster_loss: 1.1507 sup_con_loss: 0.5609 contrastive_loss: 4.5646 
2023-11-10 16:52:21.694 | INFO     | __main__:train:108 - Epoch: [171][50/63]	 loss 4.03390	 cls_loss: 0.2092 cluster_loss: 1.1861 sup_con_loss: 0.6320 contrastive_loss: 4.5669 
2023-11-10 16:52:40.462 | INFO     | __main__:train:108 - Epoch: [171][60/63]	 loss 4.03174	 cls_loss: 0.2121 cluster_loss: 1.1713 sup_con_loss: 0.6499 contrastive_loss: 4.5673 
2023-11-10 16:52:44.240 | INFO     | __main__:train:111 - Train Epoch: 171 Avg Loss: 3.9943 
2023-11-10 16:52:44.240 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:53:33.707 | INFO     | __main__:train:119 - Train Accuracies: All 0.7717 | Old 0.8139 | New 0.7507
2023-11-10 16:53:43.782 | INFO     | __main__:train:108 - Epoch: [172][0/63]	 loss 3.93454	 cls_loss: 0.2195 cluster_loss: 1.0571 sup_con_loss: 0.5867 contrastive_loss: 4.5619 
2023-11-10 16:54:02.877 | INFO     | __main__:train:108 - Epoch: [172][10/63]	 loss 3.86168	 cls_loss: 0.2157 cluster_loss: 1.0307 sup_con_loss: 0.4310 contrastive_loss: 4.5622 
2023-11-10 16:54:21.748 | INFO     | __main__:train:108 - Epoch: [172][20/63]	 loss 3.87940	 cls_loss: 0.1994 cluster_loss: 1.0728 sup_con_loss: 0.4134 contrastive_loss: 4.5656 
2023-11-10 16:54:40.563 | INFO     | __main__:train:108 - Epoch: [172][30/63]	 loss 4.01304	 cls_loss: 0.2008 cluster_loss: 1.1581 sup_con_loss: 0.6379 contrastive_loss: 4.5641 
2023-11-10 16:54:59.474 | INFO     | __main__:train:108 - Epoch: [172][40/63]	 loss 3.91759	 cls_loss: 0.1978 cluster_loss: 1.0926 sup_con_loss: 0.4907 contrastive_loss: 4.5638 
2023-11-10 16:55:18.337 | INFO     | __main__:train:108 - Epoch: [172][50/63]	 loss 3.94844	 cls_loss: 0.2105 cluster_loss: 1.1436 sup_con_loss: 0.4671 contrastive_loss: 4.5661 
2023-11-10 16:55:37.118 | INFO     | __main__:train:108 - Epoch: [172][60/63]	 loss 3.88041	 cls_loss: 0.2125 cluster_loss: 1.0509 sup_con_loss: 0.4470 contrastive_loss: 4.5639 
2023-11-10 16:55:40.949 | INFO     | __main__:train:111 - Train Epoch: 172 Avg Loss: 3.9928 
2023-11-10 16:55:40.950 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:56:30.813 | INFO     | __main__:train:119 - Train Accuracies: All 0.7715 | Old 0.8144 | New 0.7502
2023-11-10 16:56:40.737 | INFO     | __main__:train:108 - Epoch: [173][0/63]	 loss 3.92810	 cls_loss: 0.1988 cluster_loss: 1.1010 sup_con_loss: 0.5053 contrastive_loss: 4.5631 
2023-11-10 16:56:59.716 | INFO     | __main__:train:108 - Epoch: [173][10/63]	 loss 3.99846	 cls_loss: 0.2087 cluster_loss: 1.1544 sup_con_loss: 0.5851 contrastive_loss: 4.5696 
2023-11-10 16:57:18.530 | INFO     | __main__:train:108 - Epoch: [173][20/63]	 loss 3.97025	 cls_loss: 0.1950 cluster_loss: 1.1308 sup_con_loss: 0.5702 contrastive_loss: 4.5653 
2023-11-10 16:57:37.416 | INFO     | __main__:train:108 - Epoch: [173][30/63]	 loss 4.03472	 cls_loss: 0.2050 cluster_loss: 1.1911 sup_con_loss: 0.6302 contrastive_loss: 4.5664 
2023-11-10 16:57:56.304 | INFO     | __main__:train:108 - Epoch: [173][40/63]	 loss 4.04928	 cls_loss: 0.2230 cluster_loss: 1.1714 sup_con_loss: 0.6981 contrastive_loss: 4.5623 
2023-11-10 16:58:15.107 | INFO     | __main__:train:108 - Epoch: [173][50/63]	 loss 3.95683	 cls_loss: 0.2068 cluster_loss: 1.1188 sup_con_loss: 0.5369 contrastive_loss: 4.5682 
2023-11-10 16:58:33.825 | INFO     | __main__:train:108 - Epoch: [173][60/63]	 loss 4.00706	 cls_loss: 0.2034 cluster_loss: 1.1398 sup_con_loss: 0.6481 contrastive_loss: 4.5664 
2023-11-10 16:58:37.613 | INFO     | __main__:train:111 - Train Epoch: 173 Avg Loss: 4.0137 
2023-11-10 16:58:37.614 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 16:59:26.621 | INFO     | __main__:train:119 - Train Accuracies: All 0.7723 | Old 0.8154 | New 0.7510
2023-11-10 16:59:35.754 | INFO     | __main__:train:108 - Epoch: [174][0/63]	 loss 3.96807	 cls_loss: 0.1943 cluster_loss: 1.1306 sup_con_loss: 0.5703 contrastive_loss: 4.5624 
2023-11-10 16:59:54.793 | INFO     | __main__:train:108 - Epoch: [174][10/63]	 loss 4.05576	 cls_loss: 0.2057 cluster_loss: 1.2144 sup_con_loss: 0.6372 contrastive_loss: 4.5713 
2023-11-10 17:00:13.645 | INFO     | __main__:train:108 - Epoch: [174][20/63]	 loss 4.04654	 cls_loss: 0.2025 cluster_loss: 1.2009 sup_con_loss: 0.6471 contrastive_loss: 4.5671 
2023-11-10 17:00:32.538 | INFO     | __main__:train:108 - Epoch: [174][30/63]	 loss 4.02184	 cls_loss: 0.2008 cluster_loss: 1.1710 sup_con_loss: 0.6411 contrastive_loss: 4.5631 
2023-11-10 17:00:51.462 | INFO     | __main__:train:108 - Epoch: [174][40/63]	 loss 4.03132	 cls_loss: 0.1979 cluster_loss: 1.1817 sup_con_loss: 0.6458 contrastive_loss: 4.5660 
2023-11-10 17:01:10.332 | INFO     | __main__:train:108 - Epoch: [174][50/63]	 loss 3.96260	 cls_loss: 0.2026 cluster_loss: 1.1599 sup_con_loss: 0.4878 contrastive_loss: 4.5647 
2023-11-10 17:01:29.092 | INFO     | __main__:train:108 - Epoch: [174][60/63]	 loss 4.10258	 cls_loss: 0.2102 cluster_loss: 1.2774 sup_con_loss: 0.6530 contrastive_loss: 4.5695 
2023-11-10 17:01:32.857 | INFO     | __main__:train:111 - Train Epoch: 174 Avg Loss: 4.0180 
2023-11-10 17:01:32.858 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:02:22.937 | INFO     | __main__:train:119 - Train Accuracies: All 0.7717 | Old 0.8149 | New 0.7502
2023-11-10 17:02:31.541 | INFO     | __main__:train:108 - Epoch: [175][0/63]	 loss 4.17668	 cls_loss: 0.2011 cluster_loss: 1.3063 sup_con_loss: 0.8252 contrastive_loss: 4.5667 
2023-11-10 17:02:50.780 | INFO     | __main__:train:108 - Epoch: [175][10/63]	 loss 4.01728	 cls_loss: 0.2205 cluster_loss: 1.1320 sup_con_loss: 0.6725 contrastive_loss: 4.5676 
2023-11-10 17:03:09.669 | INFO     | __main__:train:108 - Epoch: [175][20/63]	 loss 4.08183	 cls_loss: 0.2252 cluster_loss: 1.2212 sup_con_loss: 0.6844 contrastive_loss: 4.5688 
2023-11-10 17:03:28.613 | INFO     | __main__:train:108 - Epoch: [175][30/63]	 loss 3.99186	 cls_loss: 0.2204 cluster_loss: 1.1321 sup_con_loss: 0.6089 contrastive_loss: 4.5627 
2023-11-10 17:03:47.516 | INFO     | __main__:train:108 - Epoch: [175][40/63]	 loss 3.93484	 cls_loss: 0.2148 cluster_loss: 1.0795 sup_con_loss: 0.5466 contrastive_loss: 4.5641 
2023-11-10 17:04:06.409 | INFO     | __main__:train:108 - Epoch: [175][50/63]	 loss 4.03217	 cls_loss: 0.2004 cluster_loss: 1.2225 sup_con_loss: 0.5481 contrastive_loss: 4.5777 
2023-11-10 17:04:25.187 | INFO     | __main__:train:108 - Epoch: [175][60/63]	 loss 3.96101	 cls_loss: 0.1949 cluster_loss: 1.1217 sup_con_loss: 0.5529 contrastive_loss: 4.5695 
2023-11-10 17:04:28.983 | INFO     | __main__:train:111 - Train Epoch: 175 Avg Loss: 4.0102 
2023-11-10 17:04:28.983 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:05:18.914 | INFO     | __main__:train:119 - Train Accuracies: All 0.7713 | Old 0.8149 | New 0.7498
2023-11-10 17:05:27.796 | INFO     | __main__:train:108 - Epoch: [176][0/63]	 loss 3.89379	 cls_loss: 0.2102 cluster_loss: 1.0703 sup_con_loss: 0.4469 contrastive_loss: 4.5663 
2023-11-10 17:05:46.855 | INFO     | __main__:train:108 - Epoch: [176][10/63]	 loss 4.01323	 cls_loss: 0.2168 cluster_loss: 1.1669 sup_con_loss: 0.6074 contrastive_loss: 4.5635 
2023-11-10 17:06:05.818 | INFO     | __main__:train:108 - Epoch: [176][20/63]	 loss 3.93192	 cls_loss: 0.2061 cluster_loss: 1.1177 sup_con_loss: 0.4759 contrastive_loss: 4.5642 
2023-11-10 17:06:24.708 | INFO     | __main__:train:108 - Epoch: [176][30/63]	 loss 4.01465	 cls_loss: 0.1992 cluster_loss: 1.1989 sup_con_loss: 0.5626 contrastive_loss: 4.5672 
2023-11-10 17:06:43.634 | INFO     | __main__:train:108 - Epoch: [176][40/63]	 loss 4.09380	 cls_loss: 0.1945 cluster_loss: 1.2388 sup_con_loss: 0.7217 contrastive_loss: 4.5660 
2023-11-10 17:07:02.538 | INFO     | __main__:train:108 - Epoch: [176][50/63]	 loss 3.99198	 cls_loss: 0.1942 cluster_loss: 1.1462 sup_con_loss: 0.6086 contrastive_loss: 4.5631 
2023-11-10 17:07:21.290 | INFO     | __main__:train:108 - Epoch: [176][60/63]	 loss 4.04198	 cls_loss: 0.2069 cluster_loss: 1.1988 sup_con_loss: 0.6385 contrastive_loss: 4.5644 
2023-11-10 17:07:25.093 | INFO     | __main__:train:111 - Train Epoch: 176 Avg Loss: 4.0056 
2023-11-10 17:07:25.093 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:08:14.486 | INFO     | __main__:train:119 - Train Accuracies: All 0.7715 | Old 0.8129 | New 0.7510
2023-11-10 17:08:24.547 | INFO     | __main__:train:108 - Epoch: [177][0/63]	 loss 4.01961	 cls_loss: 0.2034 cluster_loss: 1.1707 sup_con_loss: 0.6290 contrastive_loss: 4.5651 
2023-11-10 17:08:43.627 | INFO     | __main__:train:108 - Epoch: [177][10/63]	 loss 3.97112	 cls_loss: 0.2001 cluster_loss: 1.1359 sup_con_loss: 0.5548 contrastive_loss: 4.5669 
2023-11-10 17:09:02.542 | INFO     | __main__:train:108 - Epoch: [177][20/63]	 loss 3.99533	 cls_loss: 0.2010 cluster_loss: 1.1436 sup_con_loss: 0.6156 contrastive_loss: 4.5634 
2023-11-10 17:09:21.446 | INFO     | __main__:train:108 - Epoch: [177][30/63]	 loss 4.08701	 cls_loss: 0.2064 cluster_loss: 1.2623 sup_con_loss: 0.6396 contrastive_loss: 4.5698 
2023-11-10 17:09:40.392 | INFO     | __main__:train:108 - Epoch: [177][40/63]	 loss 4.06266	 cls_loss: 0.2202 cluster_loss: 1.2390 sup_con_loss: 0.6067 contrastive_loss: 4.5659 
2023-11-10 17:09:59.282 | INFO     | __main__:train:108 - Epoch: [177][50/63]	 loss 4.07450	 cls_loss: 0.2090 cluster_loss: 1.1835 sup_con_loss: 0.7554 contrastive_loss: 4.5657 
2023-11-10 17:10:18.081 | INFO     | __main__:train:108 - Epoch: [177][60/63]	 loss 3.92315	 cls_loss: 0.2116 cluster_loss: 1.1040 sup_con_loss: 0.4621 contrastive_loss: 4.5689 
2023-11-10 17:10:21.866 | INFO     | __main__:train:111 - Train Epoch: 177 Avg Loss: 4.0344 
2023-11-10 17:10:21.867 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:11:11.927 | INFO     | __main__:train:119 - Train Accuracies: All 0.7725 | Old 0.8169 | New 0.7505
2023-11-10 17:11:19.898 | INFO     | __main__:train:108 - Epoch: [178][0/63]	 loss 3.96178	 cls_loss: 0.2067 cluster_loss: 1.1095 sup_con_loss: 0.5731 contrastive_loss: 4.5656 
2023-11-10 17:11:39.133 | INFO     | __main__:train:108 - Epoch: [178][10/63]	 loss 4.06326	 cls_loss: 0.2008 cluster_loss: 1.1814 sup_con_loss: 0.7420 contrastive_loss: 4.5621 
2023-11-10 17:11:58.030 | INFO     | __main__:train:108 - Epoch: [178][20/63]	 loss 4.03432	 cls_loss: 0.1980 cluster_loss: 1.1781 sup_con_loss: 0.6631 contrastive_loss: 4.5649 
2023-11-10 17:12:16.928 | INFO     | __main__:train:108 - Epoch: [178][30/63]	 loss 3.96553	 cls_loss: 0.2034 cluster_loss: 1.1449 sup_con_loss: 0.5183 contrastive_loss: 4.5673 
2023-11-10 17:12:35.808 | INFO     | __main__:train:108 - Epoch: [178][40/63]	 loss 3.81469	 cls_loss: 0.1950 cluster_loss: 1.0030 sup_con_loss: 0.3671 contrastive_loss: 4.5631 
2023-11-10 17:12:54.739 | INFO     | __main__:train:108 - Epoch: [178][50/63]	 loss 3.95288	 cls_loss: 0.1992 cluster_loss: 1.0872 sup_con_loss: 0.6025 contrastive_loss: 4.5625 
2023-11-10 17:13:13.513 | INFO     | __main__:train:108 - Epoch: [178][60/63]	 loss 3.98227	 cls_loss: 0.1996 cluster_loss: 1.0964 sup_con_loss: 0.6711 contrastive_loss: 4.5613 
2023-11-10 17:13:17.299 | INFO     | __main__:train:111 - Train Epoch: 178 Avg Loss: 3.9984 
2023-11-10 17:13:17.299 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:14:06.452 | INFO     | __main__:train:119 - Train Accuracies: All 0.7718 | Old 0.8149 | New 0.7505
2023-11-10 17:14:15.356 | INFO     | __main__:train:108 - Epoch: [179][0/63]	 loss 3.93640	 cls_loss: 0.1966 cluster_loss: 1.1020 sup_con_loss: 0.5317 contrastive_loss: 4.5618 
2023-11-10 17:14:34.441 | INFO     | __main__:train:108 - Epoch: [179][10/63]	 loss 4.13214	 cls_loss: 0.2081 cluster_loss: 1.2505 sup_con_loss: 0.7878 contrastive_loss: 4.5704 
2023-11-10 17:14:53.309 | INFO     | __main__:train:108 - Epoch: [179][20/63]	 loss 4.01139	 cls_loss: 0.1961 cluster_loss: 1.1766 sup_con_loss: 0.6002 contrastive_loss: 4.5660 
2023-11-10 17:15:12.190 | INFO     | __main__:train:108 - Epoch: [179][30/63]	 loss 4.05595	 cls_loss: 0.2165 cluster_loss: 1.2047 sup_con_loss: 0.6548 contrastive_loss: 4.5661 
2023-11-10 17:15:31.061 | INFO     | __main__:train:108 - Epoch: [179][40/63]	 loss 3.99186	 cls_loss: 0.2055 cluster_loss: 1.1635 sup_con_loss: 0.5631 contrastive_loss: 4.5639 
2023-11-10 17:15:49.952 | INFO     | __main__:train:108 - Epoch: [179][50/63]	 loss 4.04072	 cls_loss: 0.1997 cluster_loss: 1.1689 sup_con_loss: 0.6929 contrastive_loss: 4.5670 
2023-11-10 17:16:08.680 | INFO     | __main__:train:108 - Epoch: [179][60/63]	 loss 4.07688	 cls_loss: 0.2012 cluster_loss: 1.2334 sup_con_loss: 0.6737 contrastive_loss: 4.5676 
2023-11-10 17:16:12.464 | INFO     | __main__:train:111 - Train Epoch: 179 Avg Loss: 4.0123 
2023-11-10 17:16:12.464 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:17:02.399 | INFO     | __main__:train:119 - Train Accuracies: All 0.7717 | Old 0.8139 | New 0.7507
2023-11-10 17:17:12.743 | INFO     | __main__:train:108 - Epoch: [180][0/63]	 loss 3.99885	 cls_loss: 0.1978 cluster_loss: 1.1278 sup_con_loss: 0.6576 contrastive_loss: 4.5636 
2023-11-10 17:17:31.730 | INFO     | __main__:train:108 - Epoch: [180][10/63]	 loss 3.99086	 cls_loss: 0.2057 cluster_loss: 1.1263 sup_con_loss: 0.6272 contrastive_loss: 4.5650 
2023-11-10 17:17:50.560 | INFO     | __main__:train:108 - Epoch: [180][20/63]	 loss 3.97294	 cls_loss: 0.2109 cluster_loss: 1.1439 sup_con_loss: 0.5379 contrastive_loss: 4.5651 
2023-11-10 17:18:09.415 | INFO     | __main__:train:108 - Epoch: [180][30/63]	 loss 3.99962	 cls_loss: 0.1937 cluster_loss: 1.1939 sup_con_loss: 0.5365 contrastive_loss: 4.5662 
2023-11-10 17:18:28.286 | INFO     | __main__:train:108 - Epoch: [180][40/63]	 loss 3.93595	 cls_loss: 0.1965 cluster_loss: 1.1136 sup_con_loss: 0.5026 contrastive_loss: 4.5652 
2023-11-10 17:18:47.147 | INFO     | __main__:train:108 - Epoch: [180][50/63]	 loss 4.02470	 cls_loss: 0.2046 cluster_loss: 1.1802 sup_con_loss: 0.6171 contrastive_loss: 4.5692 
2023-11-10 17:19:05.844 | INFO     | __main__:train:108 - Epoch: [180][60/63]	 loss 4.06448	 cls_loss: 0.2110 cluster_loss: 1.2193 sup_con_loss: 0.6624 contrastive_loss: 4.5634 
2023-11-10 17:19:09.609 | INFO     | __main__:train:111 - Train Epoch: 180 Avg Loss: 4.0179 
2023-11-10 17:19:09.609 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:19:58.468 | INFO     | __main__:train:119 - Train Accuracies: All 0.7717 | Old 0.8149 | New 0.7502
2023-11-10 17:20:11.674 | INFO     | __main__:train:108 - Epoch: [181][0/63]	 loss 4.01724	 cls_loss: 0.2013 cluster_loss: 1.2077 sup_con_loss: 0.5478 contrastive_loss: 4.5693 
2023-11-10 17:20:30.469 | INFO     | __main__:train:108 - Epoch: [181][10/63]	 loss 4.01424	 cls_loss: 0.2045 cluster_loss: 1.1797 sup_con_loss: 0.5948 contrastive_loss: 4.5657 
2023-11-10 17:20:49.348 | INFO     | __main__:train:108 - Epoch: [181][20/63]	 loss 4.05349	 cls_loss: 0.2085 cluster_loss: 1.1660 sup_con_loss: 0.7308 contrastive_loss: 4.5643 
2023-11-10 17:21:08.206 | INFO     | __main__:train:108 - Epoch: [181][30/63]	 loss 3.94444	 cls_loss: 0.2075 cluster_loss: 1.0841 sup_con_loss: 0.5756 contrastive_loss: 4.5626 
2023-11-10 17:21:27.105 | INFO     | __main__:train:108 - Epoch: [181][40/63]	 loss 3.98118	 cls_loss: 0.2066 cluster_loss: 1.1323 sup_con_loss: 0.5881 contrastive_loss: 4.5647 
2023-11-10 17:21:45.957 | INFO     | __main__:train:108 - Epoch: [181][50/63]	 loss 4.01485	 cls_loss: 0.2039 cluster_loss: 1.1615 sup_con_loss: 0.6325 contrastive_loss: 4.5648 
2023-11-10 17:22:04.636 | INFO     | __main__:train:108 - Epoch: [181][60/63]	 loss 3.90121	 cls_loss: 0.2016 cluster_loss: 1.0703 sup_con_loss: 0.4837 contrastive_loss: 4.5626 
2023-11-10 17:22:08.404 | INFO     | __main__:train:111 - Train Epoch: 181 Avg Loss: 4.0182 
2023-11-10 17:22:08.405 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:22:57.689 | INFO     | __main__:train:119 - Train Accuracies: All 0.7730 | Old 0.8154 | New 0.7520
2023-11-10 17:23:06.415 | INFO     | __main__:train:108 - Epoch: [182][0/63]	 loss 4.01275	 cls_loss: 0.2046 cluster_loss: 1.1098 sup_con_loss: 0.7245 contrastive_loss: 4.5634 
2023-11-10 17:23:25.439 | INFO     | __main__:train:108 - Epoch: [182][10/63]	 loss 4.02815	 cls_loss: 0.2084 cluster_loss: 1.1598 sup_con_loss: 0.6673 contrastive_loss: 4.5659 
2023-11-10 17:23:44.331 | INFO     | __main__:train:108 - Epoch: [182][20/63]	 loss 4.07702	 cls_loss: 0.2069 cluster_loss: 1.2183 sup_con_loss: 0.6928 contrastive_loss: 4.5696 
2023-11-10 17:24:03.250 | INFO     | __main__:train:108 - Epoch: [182][30/63]	 loss 4.09167	 cls_loss: 0.1971 cluster_loss: 1.2083 sup_con_loss: 0.7723 contrastive_loss: 4.5646 
2023-11-10 17:24:22.202 | INFO     | __main__:train:108 - Epoch: [182][40/63]	 loss 3.98051	 cls_loss: 0.2045 cluster_loss: 1.1485 sup_con_loss: 0.5602 contrastive_loss: 4.5636 
2023-11-10 17:24:41.116 | INFO     | __main__:train:108 - Epoch: [182][50/63]	 loss 3.98163	 cls_loss: 0.2068 cluster_loss: 1.1497 sup_con_loss: 0.5577 contrastive_loss: 4.5643 
2023-11-10 17:24:59.858 | INFO     | __main__:train:108 - Epoch: [182][60/63]	 loss 4.08164	 cls_loss: 0.2026 cluster_loss: 1.2164 sup_con_loss: 0.7251 contrastive_loss: 4.5635 
2023-11-10 17:25:03.625 | INFO     | __main__:train:111 - Train Epoch: 182 Avg Loss: 4.0074 
2023-11-10 17:25:03.625 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:25:53.151 | INFO     | __main__:train:119 - Train Accuracies: All 0.7718 | Old 0.8159 | New 0.7500
2023-11-10 17:26:02.822 | INFO     | __main__:train:108 - Epoch: [183][0/63]	 loss 3.95595	 cls_loss: 0.2057 cluster_loss: 1.1377 sup_con_loss: 0.5077 contrastive_loss: 4.5643 
2023-11-10 17:26:21.923 | INFO     | __main__:train:108 - Epoch: [183][10/63]	 loss 4.08891	 cls_loss: 0.2100 cluster_loss: 1.2025 sup_con_loss: 0.7559 contrastive_loss: 4.5681 
2023-11-10 17:26:40.799 | INFO     | __main__:train:108 - Epoch: [183][20/63]	 loss 3.92674	 cls_loss: 0.1997 cluster_loss: 1.1087 sup_con_loss: 0.4798 contrastive_loss: 4.5665 
2023-11-10 17:26:59.665 | INFO     | __main__:train:108 - Epoch: [183][30/63]	 loss 4.13131	 cls_loss: 0.2140 cluster_loss: 1.2273 sup_con_loss: 0.8332 contrastive_loss: 4.5647 
2023-11-10 17:27:18.571 | INFO     | __main__:train:108 - Epoch: [183][40/63]	 loss 4.02435	 cls_loss: 0.2032 cluster_loss: 1.1829 sup_con_loss: 0.6167 contrastive_loss: 4.5670 
2023-11-10 17:27:37.458 | INFO     | __main__:train:108 - Epoch: [183][50/63]	 loss 3.99265	 cls_loss: 0.2069 cluster_loss: 1.1621 sup_con_loss: 0.5646 contrastive_loss: 4.5651 
2023-11-10 17:27:56.185 | INFO     | __main__:train:108 - Epoch: [183][60/63]	 loss 4.05588	 cls_loss: 0.2042 cluster_loss: 1.1768 sup_con_loss: 0.7260 contrastive_loss: 4.5621 
2023-11-10 17:28:00.013 | INFO     | __main__:train:111 - Train Epoch: 183 Avg Loss: 4.0208 
2023-11-10 17:28:00.013 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:28:49.811 | INFO     | __main__:train:119 - Train Accuracies: All 0.7728 | Old 0.8169 | New 0.7510
2023-11-10 17:29:00.314 | INFO     | __main__:train:108 - Epoch: [184][0/63]	 loss 3.99926	 cls_loss: 0.2066 cluster_loss: 1.1360 sup_con_loss: 0.6320 contrastive_loss: 4.5652 
2023-11-10 17:29:19.304 | INFO     | __main__:train:108 - Epoch: [184][10/63]	 loss 4.09615	 cls_loss: 0.2141 cluster_loss: 1.2009 sup_con_loss: 0.7818 contrastive_loss: 4.5646 
2023-11-10 17:29:38.134 | INFO     | __main__:train:108 - Epoch: [184][20/63]	 loss 4.03965	 cls_loss: 0.1994 cluster_loss: 1.1678 sup_con_loss: 0.6995 contrastive_loss: 4.5630 
2023-11-10 17:29:56.987 | INFO     | __main__:train:108 - Epoch: [184][30/63]	 loss 4.03699	 cls_loss: 0.2043 cluster_loss: 1.1435 sup_con_loss: 0.7311 contrastive_loss: 4.5636 
2023-11-10 17:30:15.889 | INFO     | __main__:train:108 - Epoch: [184][40/63]	 loss 3.96984	 cls_loss: 0.2047 cluster_loss: 1.1687 sup_con_loss: 0.4874 contrastive_loss: 4.5661 
2023-11-10 17:30:34.736 | INFO     | __main__:train:108 - Epoch: [184][50/63]	 loss 3.97173	 cls_loss: 0.1994 cluster_loss: 1.1358 sup_con_loss: 0.5597 contrastive_loss: 4.5658 
2023-11-10 17:30:53.441 | INFO     | __main__:train:108 - Epoch: [184][60/63]	 loss 3.92379	 cls_loss: 0.1989 cluster_loss: 1.0779 sup_con_loss: 0.5359 contrastive_loss: 4.5631 
2023-11-10 17:30:57.228 | INFO     | __main__:train:111 - Train Epoch: 184 Avg Loss: 4.0074 
2023-11-10 17:30:57.228 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:31:47.364 | INFO     | __main__:train:119 - Train Accuracies: All 0.7733 | Old 0.8189 | New 0.7507
2023-11-10 17:31:55.584 | INFO     | __main__:train:108 - Epoch: [185][0/63]	 loss 4.03878	 cls_loss: 0.2065 cluster_loss: 1.1854 sup_con_loss: 0.6492 contrastive_loss: 4.5673 
2023-11-10 17:32:14.728 | INFO     | __main__:train:108 - Epoch: [185][10/63]	 loss 4.06785	 cls_loss: 0.2178 cluster_loss: 1.1996 sup_con_loss: 0.6963 contrastive_loss: 4.5665 
2023-11-10 17:32:33.604 | INFO     | __main__:train:108 - Epoch: [185][20/63]	 loss 3.99028	 cls_loss: 0.2168 cluster_loss: 1.1334 sup_con_loss: 0.5955 contrastive_loss: 4.5681 
2023-11-10 17:32:52.547 | INFO     | __main__:train:108 - Epoch: [185][30/63]	 loss 3.94735	 cls_loss: 0.2072 cluster_loss: 1.0960 sup_con_loss: 0.5597 contrastive_loss: 4.5639 
2023-11-10 17:33:11.530 | INFO     | __main__:train:108 - Epoch: [185][40/63]	 loss 4.14343	 cls_loss: 0.2170 cluster_loss: 1.2394 sup_con_loss: 0.8371 contrastive_loss: 4.5676 
2023-11-10 17:33:30.459 | INFO     | __main__:train:108 - Epoch: [185][50/63]	 loss 4.06130	 cls_loss: 0.2009 cluster_loss: 1.1906 sup_con_loss: 0.7129 contrastive_loss: 4.5654 
2023-11-10 17:33:49.251 | INFO     | __main__:train:108 - Epoch: [185][60/63]	 loss 3.94284	 cls_loss: 0.1920 cluster_loss: 1.1282 sup_con_loss: 0.4988 contrastive_loss: 4.5658 
2023-11-10 17:33:53.027 | INFO     | __main__:train:111 - Train Epoch: 185 Avg Loss: 4.0042 
2023-11-10 17:33:53.027 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:34:42.936 | INFO     | __main__:train:119 - Train Accuracies: All 0.7728 | Old 0.8169 | New 0.7510
2023-11-10 17:34:52.281 | INFO     | __main__:train:108 - Epoch: [186][0/63]	 loss 3.95442	 cls_loss: 0.2047 cluster_loss: 1.1498 sup_con_loss: 0.4806 contrastive_loss: 4.5649 
2023-11-10 17:35:11.433 | INFO     | __main__:train:108 - Epoch: [186][10/63]	 loss 3.94719	 cls_loss: 0.1986 cluster_loss: 1.1075 sup_con_loss: 0.5455 contrastive_loss: 4.5644 
2023-11-10 17:35:30.323 | INFO     | __main__:train:108 - Epoch: [186][20/63]	 loss 3.98708	 cls_loss: 0.1950 cluster_loss: 1.1552 sup_con_loss: 0.5708 contrastive_loss: 4.5664 
2023-11-10 17:35:49.234 | INFO     | __main__:train:108 - Epoch: [186][30/63]	 loss 4.07437	 cls_loss: 0.1872 cluster_loss: 1.1982 sup_con_loss: 0.7450 contrastive_loss: 4.5681 
2023-11-10 17:36:08.159 | INFO     | __main__:train:108 - Epoch: [186][40/63]	 loss 3.93851	 cls_loss: 0.2024 cluster_loss: 1.1128 sup_con_loss: 0.5075 contrastive_loss: 4.5642 
2023-11-10 17:36:27.059 | INFO     | __main__:train:108 - Epoch: [186][50/63]	 loss 4.08831	 cls_loss: 0.2200 cluster_loss: 1.2162 sup_con_loss: 0.7217 contrastive_loss: 4.5665 
2023-11-10 17:36:45.799 | INFO     | __main__:train:108 - Epoch: [186][60/63]	 loss 4.13333	 cls_loss: 0.2029 cluster_loss: 1.2580 sup_con_loss: 0.7909 contrastive_loss: 4.5659 
2023-11-10 17:36:49.573 | INFO     | __main__:train:111 - Train Epoch: 186 Avg Loss: 4.0124 
2023-11-10 17:36:49.574 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:37:39.498 | INFO     | __main__:train:119 - Train Accuracies: All 0.7726 | Old 0.8169 | New 0.7507
2023-11-10 17:37:50.235 | INFO     | __main__:train:108 - Epoch: [187][0/63]	 loss 3.96928	 cls_loss: 0.2053 cluster_loss: 1.1454 sup_con_loss: 0.5306 contrastive_loss: 4.5649 
2023-11-10 17:38:09.285 | INFO     | __main__:train:108 - Epoch: [187][10/63]	 loss 4.04613	 cls_loss: 0.2001 cluster_loss: 1.1539 sup_con_loss: 0.7416 contrastive_loss: 4.5639 
2023-11-10 17:38:28.145 | INFO     | __main__:train:108 - Epoch: [187][20/63]	 loss 4.06760	 cls_loss: 0.2009 cluster_loss: 1.2099 sup_con_loss: 0.6972 contrastive_loss: 4.5644 
2023-11-10 17:38:47.058 | INFO     | __main__:train:108 - Epoch: [187][30/63]	 loss 4.06643	 cls_loss: 0.2026 cluster_loss: 1.1825 sup_con_loss: 0.7372 contrastive_loss: 4.5675 
2023-11-10 17:39:05.963 | INFO     | __main__:train:108 - Epoch: [187][40/63]	 loss 3.98957	 cls_loss: 0.2112 cluster_loss: 1.1265 sup_con_loss: 0.6233 contrastive_loss: 4.5619 
2023-11-10 17:39:24.806 | INFO     | __main__:train:108 - Epoch: [187][50/63]	 loss 4.10401	 cls_loss: 0.1992 cluster_loss: 1.2282 sup_con_loss: 0.7592 contrastive_loss: 4.5696 
2023-11-10 17:39:43.531 | INFO     | __main__:train:108 - Epoch: [187][60/63]	 loss 4.05408	 cls_loss: 0.2001 cluster_loss: 1.2167 sup_con_loss: 0.6387 contrastive_loss: 4.5687 
2023-11-10 17:39:47.328 | INFO     | __main__:train:111 - Train Epoch: 187 Avg Loss: 4.0103 
2023-11-10 17:39:47.329 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:40:37.160 | INFO     | __main__:train:119 - Train Accuracies: All 0.7713 | Old 0.8154 | New 0.7495
2023-11-10 17:40:45.694 | INFO     | __main__:train:108 - Epoch: [188][0/63]	 loss 3.97915	 cls_loss: 0.2008 cluster_loss: 1.1365 sup_con_loss: 0.5796 contrastive_loss: 4.5651 
2023-11-10 17:41:04.824 | INFO     | __main__:train:108 - Epoch: [188][10/63]	 loss 3.93521	 cls_loss: 0.2187 cluster_loss: 1.1102 sup_con_loss: 0.4902 contrastive_loss: 4.5623 
2023-11-10 17:41:23.705 | INFO     | __main__:train:108 - Epoch: [188][20/63]	 loss 3.96102	 cls_loss: 0.1963 cluster_loss: 1.1578 sup_con_loss: 0.4793 contrastive_loss: 4.5723 
2023-11-10 17:41:42.634 | INFO     | __main__:train:108 - Epoch: [188][30/63]	 loss 4.05637	 cls_loss: 0.2172 cluster_loss: 1.1761 sup_con_loss: 0.7125 contrastive_loss: 4.5638 
2023-11-10 17:42:01.546 | INFO     | __main__:train:108 - Epoch: [188][40/63]	 loss 3.97423	 cls_loss: 0.2015 cluster_loss: 1.0960 sup_con_loss: 0.6449 contrastive_loss: 4.5624 
2023-11-10 17:42:20.409 | INFO     | __main__:train:108 - Epoch: [188][50/63]	 loss 4.01768	 cls_loss: 0.2045 cluster_loss: 1.1814 sup_con_loss: 0.6019 contrastive_loss: 4.5654 
2023-11-10 17:42:39.194 | INFO     | __main__:train:108 - Epoch: [188][60/63]	 loss 4.09016	 cls_loss: 0.2131 cluster_loss: 1.2351 sup_con_loss: 0.6966 contrastive_loss: 4.5676 
2023-11-10 17:42:42.934 | INFO     | __main__:train:111 - Train Epoch: 188 Avg Loss: 4.0031 
2023-11-10 17:42:42.935 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:43:32.097 | INFO     | __main__:train:119 - Train Accuracies: All 0.7720 | Old 0.8164 | New 0.7500
2023-11-10 17:43:41.055 | INFO     | __main__:train:108 - Epoch: [189][0/63]	 loss 4.00583	 cls_loss: 0.2058 cluster_loss: 1.1514 sup_con_loss: 0.6194 contrastive_loss: 4.5671 
2023-11-10 17:44:00.197 | INFO     | __main__:train:108 - Epoch: [189][10/63]	 loss 3.94916	 cls_loss: 0.2405 cluster_loss: 1.0893 sup_con_loss: 0.5433 contrastive_loss: 4.5643 
2023-11-10 17:44:19.053 | INFO     | __main__:train:108 - Epoch: [189][20/63]	 loss 4.21504	 cls_loss: 0.2112 cluster_loss: 1.3640 sup_con_loss: 0.8036 contrastive_loss: 4.5743 
2023-11-10 17:44:38.022 | INFO     | __main__:train:108 - Epoch: [189][30/63]	 loss 3.94667	 cls_loss: 0.2046 cluster_loss: 1.1189 sup_con_loss: 0.5213 contrastive_loss: 4.5621 
2023-11-10 17:44:56.994 | INFO     | __main__:train:108 - Epoch: [189][40/63]	 loss 4.06316	 cls_loss: 0.2081 cluster_loss: 1.1944 sup_con_loss: 0.7033 contrastive_loss: 4.5659 
2023-11-10 17:45:15.881 | INFO     | __main__:train:108 - Epoch: [189][50/63]	 loss 4.01082	 cls_loss: 0.2027 cluster_loss: 1.1820 sup_con_loss: 0.5843 contrastive_loss: 4.5647 
2023-11-10 17:45:34.598 | INFO     | __main__:train:108 - Epoch: [189][60/63]	 loss 3.98443	 cls_loss: 0.2082 cluster_loss: 1.1402 sup_con_loss: 0.5822 contrastive_loss: 4.5641 
2023-11-10 17:45:38.427 | INFO     | __main__:train:111 - Train Epoch: 189 Avg Loss: 4.0057 
2023-11-10 17:45:38.428 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:46:28.282 | INFO     | __main__:train:119 - Train Accuracies: All 0.7725 | Old 0.8174 | New 0.7502
2023-11-10 17:46:36.366 | INFO     | __main__:train:108 - Epoch: [190][0/63]	 loss 4.05228	 cls_loss: 0.2048 cluster_loss: 1.1993 sup_con_loss: 0.6630 contrastive_loss: 4.5677 
2023-11-10 17:46:55.616 | INFO     | __main__:train:108 - Epoch: [190][10/63]	 loss 4.06103	 cls_loss: 0.2055 cluster_loss: 1.2255 sup_con_loss: 0.6366 contrastive_loss: 4.5687 
2023-11-10 17:47:14.577 | INFO     | __main__:train:108 - Epoch: [190][20/63]	 loss 4.00300	 cls_loss: 0.2044 cluster_loss: 1.1725 sup_con_loss: 0.5717 contrastive_loss: 4.5681 
2023-11-10 17:47:33.490 | INFO     | __main__:train:108 - Epoch: [190][30/63]	 loss 4.01079	 cls_loss: 0.2007 cluster_loss: 1.1584 sup_con_loss: 0.6260 contrastive_loss: 4.5669 
2023-11-10 17:47:52.448 | INFO     | __main__:train:108 - Epoch: [190][40/63]	 loss 4.07826	 cls_loss: 0.2063 cluster_loss: 1.1854 sup_con_loss: 0.7662 contrastive_loss: 4.5652 
2023-11-10 17:48:11.329 | INFO     | __main__:train:108 - Epoch: [190][50/63]	 loss 4.08257	 cls_loss: 0.2194 cluster_loss: 1.2284 sup_con_loss: 0.6835 contrastive_loss: 4.5663 
2023-11-10 17:48:29.998 | INFO     | __main__:train:108 - Epoch: [190][60/63]	 loss 4.02971	 cls_loss: 0.2019 cluster_loss: 1.2333 sup_con_loss: 0.5425 contrastive_loss: 4.5654 
2023-11-10 17:48:33.799 | INFO     | __main__:train:111 - Train Epoch: 190 Avg Loss: 4.0054 
2023-11-10 17:48:33.800 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:49:23.341 | INFO     | __main__:train:119 - Train Accuracies: All 0.7720 | Old 0.8164 | New 0.7500
2023-11-10 17:49:34.102 | INFO     | __main__:train:108 - Epoch: [191][0/63]	 loss 4.06055	 cls_loss: 0.2019 cluster_loss: 1.1795 sup_con_loss: 0.7307 contrastive_loss: 4.5653 
2023-11-10 17:49:53.043 | INFO     | __main__:train:108 - Epoch: [191][10/63]	 loss 4.05667	 cls_loss: 0.2096 cluster_loss: 1.1710 sup_con_loss: 0.7253 contrastive_loss: 4.5666 
2023-11-10 17:50:11.896 | INFO     | __main__:train:108 - Epoch: [191][20/63]	 loss 4.01068	 cls_loss: 0.1986 cluster_loss: 1.1568 sup_con_loss: 0.6314 contrastive_loss: 4.5665 
2023-11-10 17:50:30.789 | INFO     | __main__:train:108 - Epoch: [191][30/63]	 loss 4.04119	 cls_loss: 0.2145 cluster_loss: 1.1502 sup_con_loss: 0.7229 contrastive_loss: 4.5623 
2023-11-10 17:50:49.752 | INFO     | __main__:train:108 - Epoch: [191][40/63]	 loss 3.89963	 cls_loss: 0.2025 cluster_loss: 1.0596 sup_con_loss: 0.4946 contrastive_loss: 4.5645 
2023-11-10 17:51:08.601 | INFO     | __main__:train:108 - Epoch: [191][50/63]	 loss 4.01363	 cls_loss: 0.2106 cluster_loss: 1.1883 sup_con_loss: 0.5652 contrastive_loss: 4.5688 
2023-11-10 17:51:27.311 | INFO     | __main__:train:108 - Epoch: [191][60/63]	 loss 4.01630	 cls_loss: 0.2017 cluster_loss: 1.1359 sup_con_loss: 0.6864 contrastive_loss: 4.5649 
2023-11-10 17:51:31.090 | INFO     | __main__:train:111 - Train Epoch: 191 Avg Loss: 4.0100 
2023-11-10 17:51:31.090 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:52:20.246 | INFO     | __main__:train:119 - Train Accuracies: All 0.7728 | Old 0.8164 | New 0.7512
2023-11-10 17:52:30.309 | INFO     | __main__:train:108 - Epoch: [192][0/63]	 loss 4.04238	 cls_loss: 0.2017 cluster_loss: 1.2054 sup_con_loss: 0.6280 contrastive_loss: 4.5669 
2023-11-10 17:52:49.330 | INFO     | __main__:train:108 - Epoch: [192][10/63]	 loss 4.06398	 cls_loss: 0.1979 cluster_loss: 1.2181 sup_con_loss: 0.6674 contrastive_loss: 4.5683 
2023-11-10 17:53:08.202 | INFO     | __main__:train:108 - Epoch: [192][20/63]	 loss 4.04303	 cls_loss: 0.2024 cluster_loss: 1.1884 sup_con_loss: 0.6643 contrastive_loss: 4.5649 
2023-11-10 17:53:27.101 | INFO     | __main__:train:108 - Epoch: [192][30/63]	 loss 4.04999	 cls_loss: 0.1963 cluster_loss: 1.1921 sup_con_loss: 0.6813 contrastive_loss: 4.5661 
2023-11-10 17:53:46.011 | INFO     | __main__:train:108 - Epoch: [192][40/63]	 loss 4.14504	 cls_loss: 0.2108 cluster_loss: 1.2503 sup_con_loss: 0.8173 contrastive_loss: 4.5731 
2023-11-10 17:54:04.874 | INFO     | __main__:train:108 - Epoch: [192][50/63]	 loss 4.00604	 cls_loss: 0.2019 cluster_loss: 1.1689 sup_con_loss: 0.5951 contrastive_loss: 4.5650 
2023-11-10 17:54:23.628 | INFO     | __main__:train:108 - Epoch: [192][60/63]	 loss 4.08063	 cls_loss: 0.1942 cluster_loss: 1.2595 sup_con_loss: 0.6401 contrastive_loss: 4.5691 
2023-11-10 17:54:27.426 | INFO     | __main__:train:111 - Train Epoch: 192 Avg Loss: 4.0252 
2023-11-10 17:54:27.426 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:55:17.048 | INFO     | __main__:train:119 - Train Accuracies: All 0.7728 | Old 0.8169 | New 0.7510
2023-11-10 17:55:26.770 | INFO     | __main__:train:108 - Epoch: [193][0/63]	 loss 4.04824	 cls_loss: 0.2026 cluster_loss: 1.1851 sup_con_loss: 0.6777 contrastive_loss: 4.5689 
2023-11-10 17:55:45.824 | INFO     | __main__:train:108 - Epoch: [193][10/63]	 loss 3.90040	 cls_loss: 0.2054 cluster_loss: 1.1178 sup_con_loss: 0.3857 contrastive_loss: 4.5645 
2023-11-10 17:56:04.664 | INFO     | __main__:train:108 - Epoch: [193][20/63]	 loss 3.96749	 cls_loss: 0.2074 cluster_loss: 1.1162 sup_con_loss: 0.5751 contrastive_loss: 4.5663 
2023-11-10 17:56:23.535 | INFO     | __main__:train:108 - Epoch: [193][30/63]	 loss 3.98039	 cls_loss: 0.2111 cluster_loss: 1.1707 sup_con_loss: 0.5093 contrastive_loss: 4.5650 
2023-11-10 17:56:42.464 | INFO     | __main__:train:108 - Epoch: [193][40/63]	 loss 4.08364	 cls_loss: 0.2149 cluster_loss: 1.2020 sup_con_loss: 0.7427 contrastive_loss: 4.5648 
2023-11-10 17:57:01.302 | INFO     | __main__:train:108 - Epoch: [193][50/63]	 loss 3.97266	 cls_loss: 0.2035 cluster_loss: 1.1588 sup_con_loss: 0.5174 contrastive_loss: 4.5648 
2023-11-10 17:57:19.983 | INFO     | __main__:train:108 - Epoch: [193][60/63]	 loss 4.05646	 cls_loss: 0.2071 cluster_loss: 1.1378 sup_con_loss: 0.7917 contrastive_loss: 4.5651 
2023-11-10 17:57:23.767 | INFO     | __main__:train:111 - Train Epoch: 193 Avg Loss: 4.0064 
2023-11-10 17:57:23.769 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 17:58:13.653 | INFO     | __main__:train:119 - Train Accuracies: All 0.7726 | Old 0.8169 | New 0.7507
2023-11-10 17:58:22.120 | INFO     | __main__:train:108 - Epoch: [194][0/63]	 loss 4.04231	 cls_loss: 0.1989 cluster_loss: 1.1984 sup_con_loss: 0.6490 contrastive_loss: 4.5640 
2023-11-10 17:58:41.210 | INFO     | __main__:train:108 - Epoch: [194][10/63]	 loss 4.06710	 cls_loss: 0.2090 cluster_loss: 1.1573 sup_con_loss: 0.7905 contrastive_loss: 4.5616 
2023-11-10 17:59:00.074 | INFO     | __main__:train:108 - Epoch: [194][20/63]	 loss 4.05321	 cls_loss: 0.1999 cluster_loss: 1.1851 sup_con_loss: 0.6978 contrastive_loss: 4.5672 
2023-11-10 17:59:18.968 | INFO     | __main__:train:108 - Epoch: [194][30/63]	 loss 3.95411	 cls_loss: 0.2041 cluster_loss: 1.1176 sup_con_loss: 0.5376 contrastive_loss: 4.5662 
2023-11-10 17:59:37.867 | INFO     | __main__:train:108 - Epoch: [194][40/63]	 loss 3.98896	 cls_loss: 0.2067 cluster_loss: 1.1565 sup_con_loss: 0.5576 contrastive_loss: 4.5688 
2023-11-10 17:59:56.756 | INFO     | __main__:train:108 - Epoch: [194][50/63]	 loss 4.08747	 cls_loss: 0.2137 cluster_loss: 1.2235 sup_con_loss: 0.7098 contrastive_loss: 4.5677 
2023-11-10 18:00:15.476 | INFO     | __main__:train:108 - Epoch: [194][60/63]	 loss 4.02449	 cls_loss: 0.2086 cluster_loss: 1.1663 sup_con_loss: 0.6500 contrastive_loss: 4.5629 
2023-11-10 18:00:19.244 | INFO     | __main__:train:111 - Train Epoch: 194 Avg Loss: 4.0091 
2023-11-10 18:00:19.244 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:01:08.174 | INFO     | __main__:train:119 - Train Accuracies: All 0.7726 | Old 0.8164 | New 0.7510
2023-11-10 18:01:17.832 | INFO     | __main__:train:108 - Epoch: [195][0/63]	 loss 3.85680	 cls_loss: 0.2233 cluster_loss: 1.0392 sup_con_loss: 0.3852 contrastive_loss: 4.5667 
2023-11-10 18:01:36.880 | INFO     | __main__:train:108 - Epoch: [195][10/63]	 loss 4.01955	 cls_loss: 0.1969 cluster_loss: 1.1763 sup_con_loss: 0.6238 contrastive_loss: 4.5657 
2023-11-10 18:01:55.795 | INFO     | __main__:train:108 - Epoch: [195][20/63]	 loss 4.07409	 cls_loss: 0.2061 cluster_loss: 1.1684 sup_con_loss: 0.7821 contrastive_loss: 4.5673 
2023-11-10 18:02:14.700 | INFO     | __main__:train:108 - Epoch: [195][30/63]	 loss 3.98668	 cls_loss: 0.1981 cluster_loss: 1.1509 sup_con_loss: 0.5774 contrastive_loss: 4.5649 
2023-11-10 18:02:33.621 | INFO     | __main__:train:108 - Epoch: [195][40/63]	 loss 3.97739	 cls_loss: 0.2057 cluster_loss: 1.1263 sup_con_loss: 0.5912 contrastive_loss: 4.5636 
2023-11-10 18:02:52.522 | INFO     | __main__:train:108 - Epoch: [195][50/63]	 loss 4.07346	 cls_loss: 0.2109 cluster_loss: 1.1793 sup_con_loss: 0.7586 contrastive_loss: 4.5656 
2023-11-10 18:03:11.283 | INFO     | __main__:train:108 - Epoch: [195][60/63]	 loss 4.07977	 cls_loss: 0.2094 cluster_loss: 1.2247 sup_con_loss: 0.6789 contrastive_loss: 4.5736 
2023-11-10 18:03:15.078 | INFO     | __main__:train:111 - Train Epoch: 195 Avg Loss: 4.0036 
2023-11-10 18:03:15.078 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:04:04.182 | INFO     | __main__:train:119 - Train Accuracies: All 0.7726 | Old 0.8169 | New 0.7507
2023-11-10 18:04:12.019 | INFO     | __main__:train:108 - Epoch: [196][0/63]	 loss 3.87415	 cls_loss: 0.2015 cluster_loss: 1.0935 sup_con_loss: 0.3573 contrastive_loss: 4.5658 
2023-11-10 18:04:31.223 | INFO     | __main__:train:108 - Epoch: [196][10/63]	 loss 4.05583	 cls_loss: 0.2108 cluster_loss: 1.1980 sup_con_loss: 0.6696 contrastive_loss: 4.5677 
2023-11-10 18:04:50.102 | INFO     | __main__:train:108 - Epoch: [196][20/63]	 loss 3.92628	 cls_loss: 0.2013 cluster_loss: 1.0912 sup_con_loss: 0.5165 contrastive_loss: 4.5627 
2023-11-10 18:05:09.027 | INFO     | __main__:train:108 - Epoch: [196][30/63]	 loss 4.00220	 cls_loss: 0.2056 cluster_loss: 1.1503 sup_con_loss: 0.6132 contrastive_loss: 4.5660 
2023-11-10 18:05:28.030 | INFO     | __main__:train:108 - Epoch: [196][40/63]	 loss 4.03164	 cls_loss: 0.2027 cluster_loss: 1.1886 sup_con_loss: 0.6231 contrastive_loss: 4.5692 
2023-11-10 18:05:46.927 | INFO     | __main__:train:108 - Epoch: [196][50/63]	 loss 4.03569	 cls_loss: 0.2073 cluster_loss: 1.1650 sup_con_loss: 0.6822 contrastive_loss: 4.5648 
2023-11-10 18:06:05.633 | INFO     | __main__:train:108 - Epoch: [196][60/63]	 loss 3.91217	 cls_loss: 0.1997 cluster_loss: 1.0932 sup_con_loss: 0.4751 contrastive_loss: 4.5622 
2023-11-10 18:06:09.430 | INFO     | __main__:train:111 - Train Epoch: 196 Avg Loss: 3.9861 
2023-11-10 18:06:09.431 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:06:59.058 | INFO     | __main__:train:119 - Train Accuracies: All 0.7725 | Old 0.8164 | New 0.7507
2023-11-10 18:07:07.984 | INFO     | __main__:train:108 - Epoch: [197][0/63]	 loss 3.92732	 cls_loss: 0.2268 cluster_loss: 1.0918 sup_con_loss: 0.4921 contrastive_loss: 4.5631 
2023-11-10 18:07:27.062 | INFO     | __main__:train:108 - Epoch: [197][10/63]	 loss 3.92386	 cls_loss: 0.2007 cluster_loss: 1.0944 sup_con_loss: 0.4998 contrastive_loss: 4.5651 
2023-11-10 18:07:45.962 | INFO     | __main__:train:108 - Epoch: [197][20/63]	 loss 4.02755	 cls_loss: 0.2041 cluster_loss: 1.1375 sup_con_loss: 0.7163 contrastive_loss: 4.5631 
2023-11-10 18:08:04.876 | INFO     | __main__:train:108 - Epoch: [197][30/63]	 loss 3.88998	 cls_loss: 0.2032 cluster_loss: 1.0420 sup_con_loss: 0.5069 contrastive_loss: 4.5603 
2023-11-10 18:08:23.827 | INFO     | __main__:train:108 - Epoch: [197][40/63]	 loss 4.06391	 cls_loss: 0.2054 cluster_loss: 1.2052 sup_con_loss: 0.6910 contrastive_loss: 4.5643 
2023-11-10 18:08:42.710 | INFO     | __main__:train:108 - Epoch: [197][50/63]	 loss 4.09264	 cls_loss: 0.2039 cluster_loss: 1.2462 sup_con_loss: 0.6943 contrastive_loss: 4.5665 
2023-11-10 18:09:01.529 | INFO     | __main__:train:108 - Epoch: [197][60/63]	 loss 3.97206	 cls_loss: 0.1944 cluster_loss: 1.1629 sup_con_loss: 0.5169 contrastive_loss: 4.5650 
2023-11-10 18:09:05.335 | INFO     | __main__:train:111 - Train Epoch: 197 Avg Loss: 3.9987 
2023-11-10 18:09:05.335 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:09:54.680 | INFO     | __main__:train:119 - Train Accuracies: All 0.7726 | Old 0.8169 | New 0.7507
2023-11-10 18:10:02.940 | INFO     | __main__:train:108 - Epoch: [198][0/63]	 loss 4.01835	 cls_loss: 0.2188 cluster_loss: 1.1095 sup_con_loss: 0.7296 contrastive_loss: 4.5619 
2023-11-10 18:10:21.966 | INFO     | __main__:train:108 - Epoch: [198][10/63]	 loss 4.05305	 cls_loss: 0.2003 cluster_loss: 1.1681 sup_con_loss: 0.7328 contrastive_loss: 4.5649 
2023-11-10 18:10:40.862 | INFO     | __main__:train:108 - Epoch: [198][20/63]	 loss 4.05150	 cls_loss: 0.2227 cluster_loss: 1.2138 sup_con_loss: 0.6135 contrastive_loss: 4.5690 
2023-11-10 18:10:59.776 | INFO     | __main__:train:108 - Epoch: [198][30/63]	 loss 4.00696	 cls_loss: 0.2117 cluster_loss: 1.1501 sup_con_loss: 0.6265 contrastive_loss: 4.5632 
2023-11-10 18:11:18.671 | INFO     | __main__:train:108 - Epoch: [198][40/63]	 loss 4.15783	 cls_loss: 0.1988 cluster_loss: 1.2988 sup_con_loss: 0.7792 contrastive_loss: 4.5712 
2023-11-10 18:11:37.548 | INFO     | __main__:train:108 - Epoch: [198][50/63]	 loss 3.97021	 cls_loss: 0.2067 cluster_loss: 1.1201 sup_con_loss: 0.5780 contrastive_loss: 4.5653 
2023-11-10 18:11:56.279 | INFO     | __main__:train:108 - Epoch: [198][60/63]	 loss 4.11869	 cls_loss: 0.2300 cluster_loss: 1.2193 sup_con_loss: 0.7952 contrastive_loss: 4.5652 
2023-11-10 18:12:00.046 | INFO     | __main__:train:111 - Train Epoch: 198 Avg Loss: 4.0048 
2023-11-10 18:12:00.047 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:12:49.078 | INFO     | __main__:train:119 - Train Accuracies: All 0.7730 | Old 0.8169 | New 0.7512
2023-11-10 18:12:58.921 | INFO     | __main__:train:108 - Epoch: [199][0/63]	 loss 4.13407	 cls_loss: 0.2008 cluster_loss: 1.2471 sup_con_loss: 0.8154 contrastive_loss: 4.5658 
2023-11-10 18:13:17.950 | INFO     | __main__:train:108 - Epoch: [199][10/63]	 loss 3.87022	 cls_loss: 0.2045 cluster_loss: 1.1013 sup_con_loss: 0.3320 contrastive_loss: 4.5640 
2023-11-10 18:13:36.832 | INFO     | __main__:train:108 - Epoch: [199][20/63]	 loss 4.04663	 cls_loss: 0.2122 cluster_loss: 1.1701 sup_con_loss: 0.7002 contrastive_loss: 4.5642 
2023-11-10 18:13:55.717 | INFO     | __main__:train:108 - Epoch: [199][30/63]	 loss 4.08978	 cls_loss: 0.2040 cluster_loss: 1.2190 sup_con_loss: 0.7378 contrastive_loss: 4.5659 
2023-11-10 18:14:14.643 | INFO     | __main__:train:108 - Epoch: [199][40/63]	 loss 3.99157	 cls_loss: 0.1927 cluster_loss: 1.1524 sup_con_loss: 0.5888 contrastive_loss: 4.5677 
2023-11-10 18:14:33.515 | INFO     | __main__:train:108 - Epoch: [199][50/63]	 loss 4.05295	 cls_loss: 0.2055 cluster_loss: 1.1900 sup_con_loss: 0.6856 contrastive_loss: 4.5655 
2023-11-10 18:14:52.231 | INFO     | __main__:train:108 - Epoch: [199][60/63]	 loss 4.06008	 cls_loss: 0.2051 cluster_loss: 1.2214 sup_con_loss: 0.6401 contrastive_loss: 4.5698 
2023-11-10 18:14:55.996 | INFO     | __main__:train:111 - Train Epoch: 199 Avg Loss: 4.0129 
2023-11-10 18:14:55.996 | INFO     | __main__:train:113 - Testing on unlabelled examples in the training data...
2023-11-10 18:15:45.957 | INFO     | __main__:train:119 - Train Accuracies: All 0.7730 | Old 0.8169 | New 0.7512
