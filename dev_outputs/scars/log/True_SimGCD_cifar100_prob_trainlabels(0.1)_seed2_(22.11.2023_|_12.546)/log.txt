2023-11-22 16:30:12.563 | INFO     | __main__:<module>:247 - Using evaluation function v2 to print results
2023-11-22 16:30:15.273 | INFO     | __main__:<module>:305 - model build
2023-11-22 16:30:31.001 | INFO     | __main__:train:109 - Epoch: [0][0/390]	 loss 8.64070	 cls_loss: 4.6641 cluster_loss: 4.5385 sup_con_loss: 2.2415 contrastive_loss: 5.0365 
2023-11-22 16:30:45.938 | INFO     | __main__:train:109 - Epoch: [0][20/390]	 loss 6.26685	 cls_loss: 1.7220 cluster_loss: 2.7652 sup_con_loss: 2.3237 contrastive_loss: 4.6976 
2023-11-22 16:31:00.027 | INFO     | __main__:train:109 - Epoch: [0][40/390]	 loss 5.36864	 cls_loss: 1.1564 cluster_loss: 2.0235 sup_con_loss: 1.6943 contrastive_loss: 4.7010 
2023-11-22 16:31:14.177 | INFO     | __main__:train:109 - Epoch: [0][60/390]	 loss 5.34521	 cls_loss: 1.1218 cluster_loss: 1.9202 sup_con_loss: 1.8576 contrastive_loss: 4.6989 
2023-11-22 16:31:28.197 | INFO     | __main__:train:109 - Epoch: [0][80/390]	 loss 5.12770	 cls_loss: 1.0597 cluster_loss: 1.7763 sup_con_loss: 1.6258 contrastive_loss: 4.6664 
2023-11-22 16:31:42.454 | INFO     | __main__:train:109 - Epoch: [0][100/390]	 loss 5.03348	 cls_loss: 1.0924 cluster_loss: 1.6054 sup_con_loss: 1.6834 contrastive_loss: 4.6437 
2023-11-22 16:31:56.881 | INFO     | __main__:train:109 - Epoch: [0][120/390]	 loss 4.76688	 cls_loss: 0.8325 cluster_loss: 1.6330 sup_con_loss: 1.1337 contrastive_loss: 4.6420 
2023-11-22 16:32:11.226 | INFO     | __main__:train:109 - Epoch: [0][140/390]	 loss 4.94161	 cls_loss: 1.0391 cluster_loss: 1.6356 sup_con_loss: 1.3763 contrastive_loss: 4.6663 
2023-11-22 16:32:25.719 | INFO     | __main__:train:109 - Epoch: [0][160/390]	 loss 4.89309	 cls_loss: 0.7268 cluster_loss: 1.5614 sup_con_loss: 1.7276 contrastive_loss: 4.6449 
2023-11-22 16:32:40.130 | INFO     | __main__:train:109 - Epoch: [0][180/390]	 loss 4.69621	 cls_loss: 0.5773 cluster_loss: 1.5160 sup_con_loss: 1.4392 contrastive_loss: 4.6231 
2023-11-22 16:32:54.705 | INFO     | __main__:train:109 - Epoch: [0][200/390]	 loss 4.61722	 cls_loss: 0.4879 cluster_loss: 1.5065 sup_con_loss: 1.3002 contrastive_loss: 4.6341 
2023-11-22 16:33:09.124 | INFO     | __main__:train:109 - Epoch: [0][220/390]	 loss 4.63685	 cls_loss: 0.5316 cluster_loss: 1.4996 sup_con_loss: 1.3564 contrastive_loss: 4.6175 
2023-11-22 16:33:23.661 | INFO     | __main__:train:109 - Epoch: [0][240/390]	 loss 4.50772	 cls_loss: 0.5607 cluster_loss: 1.4439 sup_con_loss: 1.0390 contrastive_loss: 4.6297 
2023-11-22 16:33:38.040 | INFO     | __main__:train:109 - Epoch: [0][260/390]	 loss 4.40602	 cls_loss: 0.4666 cluster_loss: 1.4351 sup_con_loss: 0.8542 contrastive_loss: 4.6322 
2023-11-22 16:33:52.620 | INFO     | __main__:train:109 - Epoch: [0][280/390]	 loss 4.35377	 cls_loss: 0.4063 cluster_loss: 1.3666 sup_con_loss: 0.8898 contrastive_loss: 4.6336 
2023-11-22 16:34:07.044 | INFO     | __main__:train:109 - Epoch: [0][300/390]	 loss 4.48363	 cls_loss: 0.3613 cluster_loss: 1.3598 sup_con_loss: 1.3434 contrastive_loss: 4.6202 
2023-11-22 16:34:21.403 | INFO     | __main__:train:109 - Epoch: [0][320/390]	 loss 4.26104	 cls_loss: 0.3830 cluster_loss: 1.2672 sup_con_loss: 0.8907 contrastive_loss: 4.6024 
2023-11-22 16:34:35.732 | INFO     | __main__:train:109 - Epoch: [0][340/390]	 loss 4.19828	 cls_loss: 0.3103 cluster_loss: 1.1958 sup_con_loss: 0.8916 contrastive_loss: 4.6159 
2023-11-22 16:34:50.259 | INFO     | __main__:train:109 - Epoch: [0][360/390]	 loss 4.21045	 cls_loss: 0.3685 cluster_loss: 1.1292 sup_con_loss: 1.0067 contrastive_loss: 4.6079 
2023-11-22 16:35:04.292 | INFO     | __main__:train:109 - Epoch: [0][380/390]	 loss 4.17633	 cls_loss: 0.2614 cluster_loss: 1.1785 sup_con_loss: 0.9372 contrastive_loss: 4.6013 
2023-11-22 16:35:10.605 | INFO     | __main__:train:112 - Train Epoch: 0 Avg Loss: 4.8624 
2023-11-22 16:35:10.606 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
2023-11-22 16:37:07.762 | INFO     | __main__:train:120 - Train Accuracies: All 0.6475 | Old 0.7546 | New 0.2620
2023-11-22 16:37:11.740 | INFO     | __main__:train:109 - Epoch: [1][0/390]	 loss 4.24409	 cls_loss: 0.3771 cluster_loss: 1.2070 sup_con_loss: 0.9712 contrastive_loss: 4.5963 
2023-11-22 16:37:26.301 | INFO     | __main__:train:109 - Epoch: [1][20/390]	 loss 4.24616	 cls_loss: 0.3040 cluster_loss: 1.2785 sup_con_loss: 0.8565 contrastive_loss: 4.6292 
2023-11-22 16:37:40.763 | INFO     | __main__:train:109 - Epoch: [1][40/390]	 loss 4.18119	 cls_loss: 0.2928 cluster_loss: 1.1818 sup_con_loss: 0.9334 contrastive_loss: 4.5905 
2023-11-22 16:37:55.239 | INFO     | __main__:train:109 - Epoch: [1][60/390]	 loss 4.14504	 cls_loss: 0.2671 cluster_loss: 1.1791 sup_con_loss: 0.8350 contrastive_loss: 4.6044 
2023-11-22 16:38:09.610 | INFO     | __main__:train:109 - Epoch: [1][80/390]	 loss 4.18792	 cls_loss: 0.2638 cluster_loss: 1.1888 sup_con_loss: 0.9474 contrastive_loss: 4.6019 
2023-11-22 16:38:23.968 | INFO     | __main__:train:109 - Epoch: [1][100/390]	 loss 4.05404	 cls_loss: 0.2188 cluster_loss: 1.1139 sup_con_loss: 0.7626 contrastive_loss: 4.5946 
2023-11-22 16:38:38.360 | INFO     | __main__:train:109 - Epoch: [1][120/390]	 loss 4.16153	 cls_loss: 0.2366 cluster_loss: 1.2458 sup_con_loss: 0.7902 contrastive_loss: 4.6036 
2023-11-22 16:38:53.001 | INFO     | __main__:train:109 - Epoch: [1][140/390]	 loss 4.02616	 cls_loss: 0.2143 cluster_loss: 1.0435 sup_con_loss: 0.8315 contrastive_loss: 4.5874 
2023-11-22 16:39:07.609 | INFO     | __main__:train:109 - Epoch: [1][160/390]	 loss 3.88897	 cls_loss: 0.1201 cluster_loss: 1.0034 sup_con_loss: 0.6014 contrastive_loss: 4.5911 
2023-11-22 16:39:22.063 | INFO     | __main__:train:109 - Epoch: [1][180/390]	 loss 3.96992	 cls_loss: 0.1595 cluster_loss: 1.0263 sup_con_loss: 0.7426 contrastive_loss: 4.5956 
2023-11-22 16:39:36.547 | INFO     | __main__:train:109 - Epoch: [1][200/390]	 loss 4.16000	 cls_loss: 0.2607 cluster_loss: 1.1871 sup_con_loss: 0.8823 contrastive_loss: 4.5975 
2023-11-22 16:39:51.021 | INFO     | __main__:train:109 - Epoch: [1][220/390]	 loss 3.99642	 cls_loss: 0.1750 cluster_loss: 1.0544 sup_con_loss: 0.7501 contrastive_loss: 4.5958 
2023-11-22 16:40:05.548 | INFO     | __main__:train:109 - Epoch: [1][240/390]	 loss 3.98696	 cls_loss: 0.1848 cluster_loss: 1.1304 sup_con_loss: 0.5728 contrastive_loss: 4.5954 
2023-11-22 16:40:19.982 | INFO     | __main__:train:109 - Epoch: [1][260/390]	 loss 4.12625	 cls_loss: 0.1580 cluster_loss: 1.1944 sup_con_loss: 0.8814 contrastive_loss: 4.5941 
2023-11-22 16:40:34.441 | INFO     | __main__:train:109 - Epoch: [1][280/390]	 loss 4.11872	 cls_loss: 0.1385 cluster_loss: 1.2274 sup_con_loss: 0.8124 contrastive_loss: 4.5971 
2023-11-22 16:40:48.894 | INFO     | __main__:train:109 - Epoch: [1][300/390]	 loss 4.12464	 cls_loss: 0.1325 cluster_loss: 1.1595 sup_con_loss: 0.9842 contrastive_loss: 4.5848 
2023-11-22 16:41:03.354 | INFO     | __main__:train:109 - Epoch: [1][320/390]	 loss 3.99465	 cls_loss: 0.1471 cluster_loss: 1.0557 sup_con_loss: 0.7898 contrastive_loss: 4.5854 
2023-11-22 16:41:17.846 | INFO     | __main__:train:109 - Epoch: [1][340/390]	 loss 3.98074	 cls_loss: 0.1875 cluster_loss: 1.0571 sup_con_loss: 0.7042 contrastive_loss: 4.5870 
2023-11-22 16:41:32.396 | INFO     | __main__:train:109 - Epoch: [1][360/390]	 loss 4.09921	 cls_loss: 0.1656 cluster_loss: 1.1982 sup_con_loss: 0.7765 contrastive_loss: 4.6009 
2023-11-22 16:41:46.597 | INFO     | __main__:train:109 - Epoch: [1][380/390]	 loss 4.02370	 cls_loss: 0.1003 cluster_loss: 1.1251 sup_con_loss: 0.7899 contrastive_loss: 4.5859 
2023-11-22 16:41:52.792 | INFO     | __main__:train:112 - Train Epoch: 1 Avg Loss: 4.0826 
2023-11-22 16:41:52.793 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
2023-11-22 16:43:50.216 | INFO     | __main__:train:120 - Train Accuracies: All 0.6575 | Old 0.7405 | New 0.3588
2023-11-22 16:43:54.393 | INFO     | __main__:train:109 - Epoch: [2][0/390]	 loss 4.01286	 cls_loss: 0.1485 cluster_loss: 1.1450 sup_con_loss: 0.6737 contrastive_loss: 4.5859 
2023-11-22 16:44:08.908 | INFO     | __main__:train:109 - Epoch: [2][20/390]	 loss 4.07544	 cls_loss: 0.1114 cluster_loss: 1.1735 sup_con_loss: 0.8341 contrastive_loss: 4.5873 
2023-11-22 16:44:23.615 | INFO     | __main__:train:109 - Epoch: [2][40/390]	 loss 4.03348	 cls_loss: 0.1689 cluster_loss: 1.1472 sup_con_loss: 0.6937 contrastive_loss: 4.5936 
2023-11-22 16:44:38.043 | INFO     | __main__:train:109 - Epoch: [2][60/390]	 loss 3.95830	 cls_loss: 0.1492 cluster_loss: 1.0225 sup_con_loss: 0.7473 contrastive_loss: 4.5845 
2023-11-22 16:44:52.547 | INFO     | __main__:train:109 - Epoch: [2][80/390]	 loss 3.99394	 cls_loss: 0.1145 cluster_loss: 1.0071 sup_con_loss: 0.9204 contrastive_loss: 4.5802 
2023-11-22 16:45:06.855 | INFO     | __main__:train:109 - Epoch: [2][100/390]	 loss 3.97798	 cls_loss: 0.1223 cluster_loss: 1.1738 sup_con_loss: 0.5372 contrastive_loss: 4.5911 
2023-11-22 16:45:21.196 | INFO     | __main__:train:109 - Epoch: [2][120/390]	 loss 4.02376	 cls_loss: 0.1070 cluster_loss: 1.1122 sup_con_loss: 0.8117 contrastive_loss: 4.5835 
2023-11-22 16:45:35.864 | INFO     | __main__:train:109 - Epoch: [2][140/390]	 loss 3.97707	 cls_loss: 0.1314 cluster_loss: 1.1311 sup_con_loss: 0.6034 contrastive_loss: 4.5918 
2023-11-22 16:45:50.259 | INFO     | __main__:train:109 - Epoch: [2][160/390]	 loss 4.01725	 cls_loss: 0.0976 cluster_loss: 1.1500 sup_con_loss: 0.7214 contrastive_loss: 4.5894 
2023-11-22 16:46:04.997 | INFO     | __main__:train:109 - Epoch: [2][180/390]	 loss 3.99704	 cls_loss: 0.1176 cluster_loss: 1.0725 sup_con_loss: 0.8048 contrastive_loss: 4.5801 
2023-11-22 16:46:19.561 | INFO     | __main__:train:109 - Epoch: [2][200/390]	 loss 4.16082	 cls_loss: 0.1493 cluster_loss: 1.1715 sup_con_loss: 1.0587 contrastive_loss: 4.5793 
2023-11-22 16:46:34.031 | INFO     | __main__:train:109 - Epoch: [2][220/390]	 loss 3.94037	 cls_loss: 0.1379 cluster_loss: 1.0773 sup_con_loss: 0.6078 contrastive_loss: 4.5833 
2023-11-22 16:46:48.743 | INFO     | __main__:train:109 - Epoch: [2][240/390]	 loss 4.05870	 cls_loss: 0.1388 cluster_loss: 1.1668 sup_con_loss: 0.7575 contrastive_loss: 4.5947 
2023-11-22 16:47:03.298 | INFO     | __main__:train:109 - Epoch: [2][260/390]	 loss 4.06894	 cls_loss: 0.1387 cluster_loss: 1.1836 sup_con_loss: 0.7711 contrastive_loss: 4.5864 
2023-11-22 16:47:17.976 | INFO     | __main__:train:109 - Epoch: [2][280/390]	 loss 4.03241	 cls_loss: 0.1605 cluster_loss: 1.1261 sup_con_loss: 0.7647 contrastive_loss: 4.5795 
2023-11-22 16:47:32.213 | INFO     | __main__:train:109 - Epoch: [2][300/390]	 loss 3.89479	 cls_loss: 0.1128 cluster_loss: 1.0483 sup_con_loss: 0.5552 contrastive_loss: 4.5840 
2023-11-22 16:47:46.738 | INFO     | __main__:train:109 - Epoch: [2][320/390]	 loss 4.08194	 cls_loss: 0.1299 cluster_loss: 1.1156 sup_con_loss: 0.9543 contrastive_loss: 4.5805 
2023-11-22 16:48:01.198 | INFO     | __main__:train:109 - Epoch: [2][340/390]	 loss 3.80883	 cls_loss: 0.1094 cluster_loss: 0.9269 sup_con_loss: 0.5597 contrastive_loss: 4.5725 
2023-11-22 16:48:15.789 | INFO     | __main__:train:109 - Epoch: [2][360/390]	 loss 3.94579	 cls_loss: 0.1467 cluster_loss: 1.0782 sup_con_loss: 0.6124 contrastive_loss: 4.5835 
2023-11-22 16:48:29.825 | INFO     | __main__:train:109 - Epoch: [2][380/390]	 loss 3.94687	 cls_loss: 0.1136 cluster_loss: 0.9949 sup_con_loss: 0.8207 contrastive_loss: 4.5742 
2023-11-22 16:48:36.125 | INFO     | __main__:train:112 - Train Epoch: 2 Avg Loss: 3.9895 
2023-11-22 16:48:36.125 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
2023-11-22 16:50:33.521 | INFO     | __main__:train:120 - Train Accuracies: All 0.6666 | Old 0.7355 | New 0.4185
2023-11-22 16:50:37.305 | INFO     | __main__:train:109 - Epoch: [3][0/390]	 loss 4.10548	 cls_loss: 0.1213 cluster_loss: 1.2251 sup_con_loss: 0.8086 contrastive_loss: 4.5903 
2023-11-22 16:50:51.908 | INFO     | __main__:train:109 - Epoch: [3][20/390]	 loss 3.92766	 cls_loss: 0.1277 cluster_loss: 1.0656 sup_con_loss: 0.6034 contrastive_loss: 4.5832 
2023-11-22 16:51:06.352 | INFO     | __main__:train:109 - Epoch: [3][40/390]	 loss 3.96564	 cls_loss: 0.1596 cluster_loss: 1.0152 sup_con_loss: 0.7838 contrastive_loss: 4.5778 
2023-11-22 16:51:20.645 | INFO     | __main__:train:109 - Epoch: [3][60/390]	 loss 3.99477	 cls_loss: 0.1030 cluster_loss: 1.0987 sup_con_loss: 0.7595 contrastive_loss: 4.5827 
2023-11-22 16:51:35.191 | INFO     | __main__:train:109 - Epoch: [3][80/390]	 loss 3.95761	 cls_loss: 0.1362 cluster_loss: 1.0069 sup_con_loss: 0.7955 contrastive_loss: 4.5801 
2023-11-22 16:51:49.604 | INFO     | __main__:train:109 - Epoch: [3][100/390]	 loss 4.05834	 cls_loss: 0.1363 cluster_loss: 1.0838 sup_con_loss: 0.9387 contrastive_loss: 4.5810 
2023-11-22 16:52:03.764 | INFO     | __main__:train:109 - Epoch: [3][120/390]	 loss 4.04502	 cls_loss: 0.1108 cluster_loss: 1.1482 sup_con_loss: 0.7980 contrastive_loss: 4.5855 
2023-11-22 16:52:18.038 | INFO     | __main__:train:109 - Epoch: [3][140/390]	 loss 3.87684	 cls_loss: 0.1279 cluster_loss: 0.9591 sup_con_loss: 0.6643 contrastive_loss: 4.5787 
2023-11-22 16:52:32.657 | INFO     | __main__:train:109 - Epoch: [3][160/390]	 loss 3.90681	 cls_loss: 0.1238 cluster_loss: 1.0427 sup_con_loss: 0.6074 contrastive_loss: 4.5740 
2023-11-22 16:52:47.333 | INFO     | __main__:train:109 - Epoch: [3][180/390]	 loss 3.94202	 cls_loss: 0.1092 cluster_loss: 1.0145 sup_con_loss: 0.7651 contrastive_loss: 4.5794 
2023-11-22 16:53:01.842 | INFO     | __main__:train:109 - Epoch: [3][200/390]	 loss 3.82718	 cls_loss: 0.1041 cluster_loss: 1.0108 sup_con_loss: 0.4507 contrastive_loss: 4.5785 
2023-11-22 16:53:16.211 | INFO     | __main__:train:109 - Epoch: [3][220/390]	 loss 3.94693	 cls_loss: 0.1013 cluster_loss: 0.9918 sup_con_loss: 0.8287 contrastive_loss: 4.5796 
2023-11-22 16:53:30.557 | INFO     | __main__:train:109 - Epoch: [3][240/390]	 loss 4.01611	 cls_loss: 0.1075 cluster_loss: 1.1948 sup_con_loss: 0.6240 contrastive_loss: 4.5900 
2023-11-22 16:53:44.797 | INFO     | __main__:train:109 - Epoch: [3][260/390]	 loss 4.04762	 cls_loss: 0.1141 cluster_loss: 1.1383 sup_con_loss: 0.8316 contrastive_loss: 4.5797 
2023-11-22 16:53:58.899 | INFO     | __main__:train:109 - Epoch: [3][280/390]	 loss 3.88140	 cls_loss: 0.1131 cluster_loss: 0.9359 sup_con_loss: 0.7405 contrastive_loss: 4.5758 
2023-11-22 16:54:12.991 | INFO     | __main__:train:109 - Epoch: [3][300/390]	 loss 3.97933	 cls_loss: 0.1315 cluster_loss: 1.0939 sup_con_loss: 0.6951 contrastive_loss: 4.5831 
2023-11-22 16:54:27.511 | INFO     | __main__:train:109 - Epoch: [3][320/390]	 loss 3.94346	 cls_loss: 0.1057 cluster_loss: 1.0663 sup_con_loss: 0.6665 contrastive_loss: 4.5847 
2023-11-22 16:54:42.005 | INFO     | __main__:train:109 - Epoch: [3][340/390]	 loss 3.91499	 cls_loss: 0.1233 cluster_loss: 1.0571 sup_con_loss: 0.5803 contrastive_loss: 4.5871 
2023-11-22 16:54:56.376 | INFO     | __main__:train:109 - Epoch: [3][360/390]	 loss 3.95408	 cls_loss: 0.1162 cluster_loss: 1.0718 sup_con_loss: 0.6931 contrastive_loss: 4.5757 
2023-11-22 16:55:10.308 | INFO     | __main__:train:109 - Epoch: [3][380/390]	 loss 3.94606	 cls_loss: 0.1179 cluster_loss: 0.9731 sup_con_loss: 0.8543 contrastive_loss: 4.5743 
2023-11-22 16:55:16.517 | INFO     | __main__:train:112 - Train Epoch: 3 Avg Loss: 3.9609 
2023-11-22 16:55:16.517 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
2023-11-22 16:57:13.163 | INFO     | __main__:train:120 - Train Accuracies: All 0.6829 | Old 0.7423 | New 0.4691
2023-11-22 16:57:16.721 | INFO     | __main__:train:109 - Epoch: [4][0/390]	 loss 4.08510	 cls_loss: 0.0985 cluster_loss: 1.1369 sup_con_loss: 0.9468 contrastive_loss: 4.5851 
2023-11-22 16:57:31.256 | INFO     | __main__:train:109 - Epoch: [4][20/390]	 loss 3.94566	 cls_loss: 0.1063 cluster_loss: 1.0597 sup_con_loss: 0.6921 contrastive_loss: 4.5806 
2023-11-22 16:57:45.598 | INFO     | __main__:train:109 - Epoch: [4][40/390]	 loss 3.93620	 cls_loss: 0.1121 cluster_loss: 1.0290 sup_con_loss: 0.7179 contrastive_loss: 4.5798 
2023-11-22 16:57:59.901 | INFO     | __main__:train:109 - Epoch: [4][60/390]	 loss 3.83191	 cls_loss: 0.1041 cluster_loss: 0.9553 sup_con_loss: 0.5674 contrastive_loss: 4.5784 
2023-11-22 16:58:14.422 | INFO     | __main__:train:109 - Epoch: [4][80/390]	 loss 3.91131	 cls_loss: 0.1104 cluster_loss: 1.0584 sup_con_loss: 0.5964 contrastive_loss: 4.5784 
2023-11-22 16:58:28.830 | INFO     | __main__:train:109 - Epoch: [4][100/390]	 loss 3.87018	 cls_loss: 0.1149 cluster_loss: 0.9207 sup_con_loss: 0.7370 contrastive_loss: 4.5747 
2023-11-22 16:58:43.134 | INFO     | __main__:train:109 - Epoch: [4][120/390]	 loss 3.97022	 cls_loss: 0.1045 cluster_loss: 1.0546 sup_con_loss: 0.7730 contrastive_loss: 4.5809 
2023-11-22 16:58:57.481 | INFO     | __main__:train:109 - Epoch: [4][140/390]	 loss 3.88270	 cls_loss: 0.1069 cluster_loss: 0.9681 sup_con_loss: 0.6967 contrastive_loss: 4.5725 
2023-11-22 16:59:11.956 | INFO     | __main__:train:109 - Epoch: [4][160/390]	 loss 3.95349	 cls_loss: 0.0892 cluster_loss: 0.9819 sup_con_loss: 0.8864 contrastive_loss: 4.5751 
2023-11-22 16:59:26.386 | INFO     | __main__:train:109 - Epoch: [4][180/390]	 loss 3.84996	 cls_loss: 0.1060 cluster_loss: 0.9895 sup_con_loss: 0.5646 contrastive_loss: 4.5724 
2023-11-22 16:59:40.899 | INFO     | __main__:train:109 - Epoch: [4][200/390]	 loss 4.01449	 cls_loss: 0.1343 cluster_loss: 1.1268 sup_con_loss: 0.7440 contrastive_loss: 4.5764 
2023-11-22 16:59:55.350 | INFO     | __main__:train:109 - Epoch: [4][220/390]	 loss 3.87292	 cls_loss: 0.1299 cluster_loss: 0.9717 sup_con_loss: 0.6379 contrastive_loss: 4.5733 
2023-11-22 17:00:09.943 | INFO     | __main__:train:109 - Epoch: [4][240/390]	 loss 3.87735	 cls_loss: 0.1221 cluster_loss: 0.9560 sup_con_loss: 0.6680 contrastive_loss: 4.5837 
2023-11-22 17:00:24.292 | INFO     | __main__:train:109 - Epoch: [4][260/390]	 loss 3.81929	 cls_loss: 0.1012 cluster_loss: 0.9353 sup_con_loss: 0.5799 contrastive_loss: 4.5738 
2023-11-22 17:00:38.542 | INFO     | __main__:train:109 - Epoch: [4][280/390]	 loss 3.99811	 cls_loss: 0.1052 cluster_loss: 1.0684 sup_con_loss: 0.8194 contrastive_loss: 4.5847 
2023-11-22 17:00:52.815 | INFO     | __main__:train:109 - Epoch: [4][300/390]	 loss 4.06563	 cls_loss: 0.0864 cluster_loss: 1.1645 sup_con_loss: 0.8660 contrastive_loss: 4.5774 
2023-11-22 17:01:07.248 | INFO     | __main__:train:109 - Epoch: [4][320/390]	 loss 4.08999	 cls_loss: 0.1687 cluster_loss: 1.0834 sup_con_loss: 0.9992 contrastive_loss: 4.5800 
2023-11-22 17:01:21.669 | INFO     | __main__:train:109 - Epoch: [4][340/390]	 loss 3.99414	 cls_loss: 0.1246 cluster_loss: 1.1574 sup_con_loss: 0.6318 contrastive_loss: 4.5801 
2023-11-22 17:01:36.164 | INFO     | __main__:train:109 - Epoch: [4][360/390]	 loss 3.84487	 cls_loss: 0.1358 cluster_loss: 1.0479 sup_con_loss: 0.4059 contrastive_loss: 4.5756 
2023-11-22 17:01:50.090 | INFO     | __main__:train:109 - Epoch: [4][380/390]	 loss 3.81345	 cls_loss: 0.1071 cluster_loss: 0.9216 sup_con_loss: 0.5754 contrastive_loss: 4.5777 
2023-11-22 17:01:56.341 | INFO     | __main__:train:112 - Train Epoch: 4 Avg Loss: 3.9396 
2023-11-22 17:01:56.342 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
2023-11-22 17:03:52.754 | INFO     | __main__:train:120 - Train Accuracies: All 0.6767 | Old 0.7187 | New 0.5256
2023-11-22 17:03:56.473 | INFO     | __main__:train:109 - Epoch: [5][0/390]	 loss 3.96255	 cls_loss: 0.1111 cluster_loss: 1.0315 sup_con_loss: 0.7877 contrastive_loss: 4.5808 
2023-11-22 17:04:10.906 | INFO     | __main__:train:109 - Epoch: [5][20/390]	 loss 3.81415	 cls_loss: 0.0838 cluster_loss: 0.9131 sup_con_loss: 0.6296 contrastive_loss: 4.5706 
2023-11-22 17:04:25.222 | INFO     | __main__:train:109 - Epoch: [5][40/390]	 loss 3.90562	 cls_loss: 0.0865 cluster_loss: 1.0066 sup_con_loss: 0.7078 contrastive_loss: 4.5743 
2023-11-22 17:04:39.599 | INFO     | __main__:train:109 - Epoch: [5][60/390]	 loss 3.97212	 cls_loss: 0.1055 cluster_loss: 1.0354 sup_con_loss: 0.8269 contrastive_loss: 4.5734 
2023-11-22 17:04:53.767 | INFO     | __main__:train:109 - Epoch: [5][80/390]	 loss 3.98075	 cls_loss: 0.1049 cluster_loss: 1.0707 sup_con_loss: 0.7796 contrastive_loss: 4.5772 
2023-11-22 17:05:08.001 | INFO     | __main__:train:109 - Epoch: [5][100/390]	 loss 4.00417	 cls_loss: 0.1104 cluster_loss: 1.1029 sup_con_loss: 0.7756 contrastive_loss: 4.5804 
2023-11-22 17:05:22.641 | INFO     | __main__:train:109 - Epoch: [5][120/390]	 loss 3.88531	 cls_loss: 0.1000 cluster_loss: 0.9451 sup_con_loss: 0.7564 contrastive_loss: 4.5712 
2023-11-22 17:05:37.141 | INFO     | __main__:train:109 - Epoch: [5][140/390]	 loss 3.99602	 cls_loss: 0.1252 cluster_loss: 1.0990 sup_con_loss: 0.7503 contrastive_loss: 4.5773 
2023-11-22 17:05:51.476 | INFO     | __main__:train:109 - Epoch: [5][160/390]	 loss 3.94263	 cls_loss: 0.1386 cluster_loss: 1.0119 sup_con_loss: 0.7540 contrastive_loss: 4.5730 
2023-11-22 17:06:06.001 | INFO     | __main__:train:109 - Epoch: [5][180/390]	 loss 3.88334	 cls_loss: 0.1078 cluster_loss: 0.9615 sup_con_loss: 0.7060 contrastive_loss: 4.5747 
2023-11-22 17:06:20.339 | INFO     | __main__:train:109 - Epoch: [5][200/390]	 loss 4.08914	 cls_loss: 0.1040 cluster_loss: 1.1339 sup_con_loss: 0.9717 contrastive_loss: 4.5778 
2023-11-22 17:06:34.707 | INFO     | __main__:train:109 - Epoch: [5][220/390]	 loss 3.98990	 cls_loss: 0.1153 cluster_loss: 1.0615 sup_con_loss: 0.8003 contrastive_loss: 4.5838 
2023-11-22 17:06:49.120 | INFO     | __main__:train:109 - Epoch: [5][240/390]	 loss 3.88122	 cls_loss: 0.0893 cluster_loss: 0.9491 sup_con_loss: 0.7427 contrastive_loss: 4.5741 
2023-11-22 17:07:03.686 | INFO     | __main__:train:109 - Epoch: [5][260/390]	 loss 3.92399	 cls_loss: 0.1063 cluster_loss: 0.9529 sup_con_loss: 0.8417 contrastive_loss: 4.5735 
2023-11-22 17:07:18.065 | INFO     | __main__:train:109 - Epoch: [5][280/390]	 loss 4.09886	 cls_loss: 0.0894 cluster_loss: 1.1692 sup_con_loss: 0.9402 contrastive_loss: 4.5823 
2023-11-22 17:07:32.535 | INFO     | __main__:train:109 - Epoch: [5][300/390]	 loss 3.92809	 cls_loss: 0.0884 cluster_loss: 0.9858 sup_con_loss: 0.8044 contrastive_loss: 4.5767 
2023-11-22 17:07:46.925 | INFO     | __main__:train:109 - Epoch: [5][320/390]	 loss 3.75685	 cls_loss: 0.1031 cluster_loss: 0.8760 sup_con_loss: 0.5073 contrastive_loss: 4.5751 
2023-11-22 17:08:01.239 | INFO     | __main__:train:109 - Epoch: [5][340/390]	 loss 3.89088	 cls_loss: 0.0932 cluster_loss: 0.9887 sup_con_loss: 0.6940 contrastive_loss: 4.5734 
2023-11-22 17:08:15.495 | INFO     | __main__:train:109 - Epoch: [5][360/390]	 loss 3.80722	 cls_loss: 0.1068 cluster_loss: 0.8721 sup_con_loss: 0.6598 contrastive_loss: 4.5724 
2023-11-22 17:08:29.469 | INFO     | __main__:train:109 - Epoch: [5][380/390]	 loss 3.90319	 cls_loss: 0.0818 cluster_loss: 1.0652 sup_con_loss: 0.5863 contrastive_loss: 4.5799 
2023-11-22 17:08:35.753 | INFO     | __main__:train:112 - Train Epoch: 5 Avg Loss: 3.9325 
2023-11-22 17:08:35.753 | INFO     | __main__:train:114 - Testing on unlabelled examples in the training data...
